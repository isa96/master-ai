2023-03-19 17:13:47,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:13:47,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:13:47,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:13:47,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:13:48,738:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-19 17:15:03,478:INFO:PyCaret ClassificationExperiment
2023-03-19 17:15:03,478:INFO:Logging name: clf-default-name
2023-03-19 17:15:03,478:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:15:03,478:INFO:version 3.0.0
2023-03-19 17:15:03,478:INFO:Initializing setup()
2023-03-19 17:15:03,478:INFO:self.USI: 6dd1
2023-03-19 17:15:03,478:INFO:self._variable_keys: {'idx', 'X_train', 'log_plots_param', 'fold_generator', 'is_multiclass', 'X_test', 'fix_imbalance', 'memory', 'seed', 'n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'data', 'y', 'exp_name_log', 'USI', 'fold_groups_param', 'y_train', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'html_param', 'exp_id', 'X', 'target_param'}
2023-03-19 17:15:03,478:INFO:Checking environment
2023-03-19 17:15:03,478:INFO:python_version: 3.10.0
2023-03-19 17:15:03,478:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:15:03,478:INFO:machine: AMD64
2023-03-19 17:15:03,478:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:15:03,495:INFO:Memory: svmem(total=16969424896, available=5873188864, percent=65.4, used=11096236032, free=5873188864)
2023-03-19 17:15:03,495:INFO:Physical Core: 4
2023-03-19 17:15:03,495:INFO:Logical Core: 8
2023-03-19 17:15:03,495:INFO:Checking libraries
2023-03-19 17:15:03,495:INFO:System:
2023-03-19 17:15:03,495:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:15:03,495:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:15:03,495:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:15:03,495:INFO:PyCaret required dependencies:
2023-03-19 17:15:03,495:INFO:                 pip: 23.0.1
2023-03-19 17:15:03,495:INFO:          setuptools: 65.6.3
2023-03-19 17:15:03,495:INFO:             pycaret: 3.0.0
2023-03-19 17:15:03,495:INFO:             IPython: 8.11.0
2023-03-19 17:15:03,495:INFO:          ipywidgets: 8.0.4
2023-03-19 17:15:03,495:INFO:                tqdm: 4.65.0
2023-03-19 17:15:03,495:INFO:               numpy: 1.23.5
2023-03-19 17:15:03,495:INFO:              pandas: 1.5.3
2023-03-19 17:15:03,495:INFO:              jinja2: 3.1.2
2023-03-19 17:15:03,495:INFO:               scipy: 1.10.1
2023-03-19 17:15:03,495:INFO:              joblib: 1.2.0
2023-03-19 17:15:03,495:INFO:             sklearn: 1.2.2
2023-03-19 17:15:03,495:INFO:                pyod: 1.0.8
2023-03-19 17:15:03,495:INFO:            imblearn: 0.10.1
2023-03-19 17:15:03,495:INFO:   category_encoders: 2.6.0
2023-03-19 17:15:03,495:INFO:            lightgbm: 3.3.5
2023-03-19 17:15:03,495:INFO:               numba: 0.56.4
2023-03-19 17:15:03,495:INFO:            requests: 2.28.2
2023-03-19 17:15:03,495:INFO:          matplotlib: 3.7.1
2023-03-19 17:15:03,495:INFO:          scikitplot: 0.3.7
2023-03-19 17:15:03,495:INFO:         yellowbrick: 1.5
2023-03-19 17:15:03,495:INFO:              plotly: 5.13.1
2023-03-19 17:15:03,495:INFO:             kaleido: 0.2.1
2023-03-19 17:15:03,495:INFO:         statsmodels: 0.13.5
2023-03-19 17:15:03,495:INFO:              sktime: 0.16.1
2023-03-19 17:15:03,495:INFO:               tbats: 1.1.2
2023-03-19 17:15:03,495:INFO:            pmdarima: 2.0.3
2023-03-19 17:15:03,495:INFO:              psutil: 5.9.4
2023-03-19 17:15:03,495:INFO:PyCaret optional dependencies:
2023-03-19 17:15:03,511:INFO:                shap: Not installed
2023-03-19 17:15:03,511:INFO:           interpret: Not installed
2023-03-19 17:15:03,511:INFO:                umap: Not installed
2023-03-19 17:15:03,511:INFO:    pandas_profiling: Not installed
2023-03-19 17:15:03,511:INFO:  explainerdashboard: Not installed
2023-03-19 17:15:03,511:INFO:             autoviz: Not installed
2023-03-19 17:15:03,511:INFO:           fairlearn: Not installed
2023-03-19 17:15:03,511:INFO:             xgboost: Not installed
2023-03-19 17:15:03,511:INFO:            catboost: Not installed
2023-03-19 17:15:03,511:INFO:              kmodes: Not installed
2023-03-19 17:15:03,511:INFO:             mlxtend: Not installed
2023-03-19 17:15:03,511:INFO:       statsforecast: Not installed
2023-03-19 17:15:03,511:INFO:        tune_sklearn: Not installed
2023-03-19 17:15:03,511:INFO:                 ray: Not installed
2023-03-19 17:15:03,511:INFO:            hyperopt: Not installed
2023-03-19 17:15:03,511:INFO:              optuna: Not installed
2023-03-19 17:15:03,511:INFO:               skopt: Not installed
2023-03-19 17:15:03,511:INFO:              mlflow: Not installed
2023-03-19 17:15:03,511:INFO:              gradio: Not installed
2023-03-19 17:15:03,511:INFO:             fastapi: Not installed
2023-03-19 17:15:03,511:INFO:             uvicorn: Not installed
2023-03-19 17:15:03,511:INFO:              m2cgen: Not installed
2023-03-19 17:15:03,511:INFO:           evidently: Not installed
2023-03-19 17:15:03,511:INFO:               fugue: Not installed
2023-03-19 17:15:03,511:INFO:           streamlit: Not installed
2023-03-19 17:15:03,511:INFO:             prophet: Not installed
2023-03-19 17:15:03,511:INFO:None
2023-03-19 17:15:03,511:INFO:Set up data.
2023-03-19 17:15:03,535:INFO:Set up train/test split.
2023-03-19 17:15:03,551:INFO:Set up index.
2023-03-19 17:15:03,551:INFO:Set up folding strategy.
2023-03-19 17:15:03,551:INFO:Assigning column types.
2023-03-19 17:15:03,551:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:15:03,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:15:03,615:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:15:03,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:15:03,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:15:03,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,752:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:15:03,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:15:03,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:15:03,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,890:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:15:03,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:03,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:04,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:04,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:04,044:INFO:Preparing preprocessing pipeline...
2023-03-19 17:15:04,044:INFO:Set up simple imputation.
2023-03-19 17:15:04,052:INFO:Set up encoding of ordinal features.
2023-03-19 17:15:04,052:INFO:Set up encoding of categorical features.
2023-03-19 17:15:04,052:INFO:Set up column name cleaning.
2023-03-19 17:15:04,719:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:15:04,736:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:15:04,736:INFO:Creating final display dataframe.
2023-03-19 17:15:05,439:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape       (32561, 15)
4        Transformed data shape       (32561, 65)
5   Transformed train set shape       (22792, 65)
6    Transformed test set shape        (9769, 65)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 8
10     Rows with missing values              7.4%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              6dd1
2023-03-19 17:15:05,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:05,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:05,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:05,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:15:05,599:INFO:setup() successfully completed in 2.12s...............
2023-03-19 17:16:47,182:INFO:PyCaret ClassificationExperiment
2023-03-19 17:16:47,182:INFO:Logging name: clf-default-name
2023-03-19 17:16:47,182:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:16:47,182:INFO:version 3.0.0
2023-03-19 17:16:47,182:INFO:Initializing setup()
2023-03-19 17:16:47,182:INFO:self.USI: 526c
2023-03-19 17:16:47,182:INFO:self._variable_keys: {'idx', 'X_train', 'log_plots_param', 'fold_generator', 'is_multiclass', 'X_test', 'fix_imbalance', 'memory', 'seed', 'n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'data', 'y', 'exp_name_log', 'USI', 'fold_groups_param', 'y_train', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'html_param', 'exp_id', 'X', 'target_param'}
2023-03-19 17:16:47,182:INFO:Checking environment
2023-03-19 17:16:47,182:INFO:python_version: 3.10.0
2023-03-19 17:16:47,182:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:16:47,182:INFO:machine: AMD64
2023-03-19 17:16:47,182:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:16:47,198:INFO:Memory: svmem(total=16969424896, available=5789196288, percent=65.9, used=11180228608, free=5789196288)
2023-03-19 17:16:47,198:INFO:Physical Core: 4
2023-03-19 17:16:47,198:INFO:Logical Core: 8
2023-03-19 17:16:47,198:INFO:Checking libraries
2023-03-19 17:16:47,198:INFO:System:
2023-03-19 17:16:47,198:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:16:47,198:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:16:47,198:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:16:47,198:INFO:PyCaret required dependencies:
2023-03-19 17:16:47,198:INFO:                 pip: 23.0.1
2023-03-19 17:16:47,198:INFO:          setuptools: 65.6.3
2023-03-19 17:16:47,198:INFO:             pycaret: 3.0.0
2023-03-19 17:16:47,198:INFO:             IPython: 8.11.0
2023-03-19 17:16:47,198:INFO:          ipywidgets: 8.0.4
2023-03-19 17:16:47,198:INFO:                tqdm: 4.65.0
2023-03-19 17:16:47,198:INFO:               numpy: 1.23.5
2023-03-19 17:16:47,198:INFO:              pandas: 1.5.3
2023-03-19 17:16:47,198:INFO:              jinja2: 3.1.2
2023-03-19 17:16:47,198:INFO:               scipy: 1.10.1
2023-03-19 17:16:47,198:INFO:              joblib: 1.2.0
2023-03-19 17:16:47,198:INFO:             sklearn: 1.2.2
2023-03-19 17:16:47,198:INFO:                pyod: 1.0.8
2023-03-19 17:16:47,198:INFO:            imblearn: 0.10.1
2023-03-19 17:16:47,198:INFO:   category_encoders: 2.6.0
2023-03-19 17:16:47,198:INFO:            lightgbm: 3.3.5
2023-03-19 17:16:47,198:INFO:               numba: 0.56.4
2023-03-19 17:16:47,198:INFO:            requests: 2.28.2
2023-03-19 17:16:47,198:INFO:          matplotlib: 3.7.1
2023-03-19 17:16:47,214:INFO:          scikitplot: 0.3.7
2023-03-19 17:16:47,214:INFO:         yellowbrick: 1.5
2023-03-19 17:16:47,214:INFO:              plotly: 5.13.1
2023-03-19 17:16:47,214:INFO:             kaleido: 0.2.1
2023-03-19 17:16:47,214:INFO:         statsmodels: 0.13.5
2023-03-19 17:16:47,214:INFO:              sktime: 0.16.1
2023-03-19 17:16:47,214:INFO:               tbats: 1.1.2
2023-03-19 17:16:47,214:INFO:            pmdarima: 2.0.3
2023-03-19 17:16:47,214:INFO:              psutil: 5.9.4
2023-03-19 17:16:47,214:INFO:PyCaret optional dependencies:
2023-03-19 17:16:47,214:INFO:                shap: Not installed
2023-03-19 17:16:47,214:INFO:           interpret: Not installed
2023-03-19 17:16:47,214:INFO:                umap: Not installed
2023-03-19 17:16:47,214:INFO:    pandas_profiling: Not installed
2023-03-19 17:16:47,214:INFO:  explainerdashboard: Not installed
2023-03-19 17:16:47,214:INFO:             autoviz: Not installed
2023-03-19 17:16:47,214:INFO:           fairlearn: Not installed
2023-03-19 17:16:47,214:INFO:             xgboost: Not installed
2023-03-19 17:16:47,214:INFO:            catboost: Not installed
2023-03-19 17:16:47,214:INFO:              kmodes: Not installed
2023-03-19 17:16:47,214:INFO:             mlxtend: Not installed
2023-03-19 17:16:47,214:INFO:       statsforecast: Not installed
2023-03-19 17:16:47,214:INFO:        tune_sklearn: Not installed
2023-03-19 17:16:47,214:INFO:                 ray: Not installed
2023-03-19 17:16:47,214:INFO:            hyperopt: Not installed
2023-03-19 17:16:47,214:INFO:              optuna: Not installed
2023-03-19 17:16:47,214:INFO:               skopt: Not installed
2023-03-19 17:16:47,214:INFO:              mlflow: Not installed
2023-03-19 17:16:47,214:INFO:              gradio: Not installed
2023-03-19 17:16:47,214:INFO:             fastapi: Not installed
2023-03-19 17:16:47,214:INFO:             uvicorn: Not installed
2023-03-19 17:16:47,214:INFO:              m2cgen: Not installed
2023-03-19 17:16:47,214:INFO:           evidently: Not installed
2023-03-19 17:16:47,214:INFO:               fugue: Not installed
2023-03-19 17:16:47,214:INFO:           streamlit: Not installed
2023-03-19 17:16:47,214:INFO:             prophet: Not installed
2023-03-19 17:16:47,214:INFO:None
2023-03-19 17:16:47,214:INFO:Set up data.
2023-03-19 17:16:47,338:INFO:Set up train/test split.
2023-03-19 17:16:47,389:INFO:Set up index.
2023-03-19 17:16:47,389:INFO:Set up folding strategy.
2023-03-19 17:16:47,389:INFO:Assigning column types.
2023-03-19 17:16:47,404:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:16:47,601:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:16:47,601:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:16:47,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:47,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:47,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:16:47,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:16:48,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,015:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:16:48,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:16:48,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:16:48,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,563:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:16:48,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:48,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:49,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:49,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:49,102:INFO:Preparing preprocessing pipeline...
2023-03-19 17:16:49,102:INFO:Set up simple imputation.
2023-03-19 17:16:49,120:INFO:Set up encoding of ordinal features.
2023-03-19 17:16:49,130:INFO:Set up encoding of categorical features.
2023-03-19 17:16:49,130:INFO:Set up column name cleaning.
2023-03-19 17:16:50,247:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:16:50,271:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:16:50,272:INFO:Creating final display dataframe.
2023-03-19 17:16:51,008:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape       (32561, 15)
4        Transformed data shape       (32561, 65)
5   Transformed train set shape       (22792, 65)
6    Transformed test set shape        (9769, 65)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 8
10     Rows with missing values              7.4%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              526c
2023-03-19 17:16:51,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:51,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:51,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:51,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:16:51,236:INFO:setup() successfully completed in 4.07s...............
2023-03-19 17:17:18,596:INFO:PyCaret ClassificationExperiment
2023-03-19 17:17:18,596:INFO:Logging name: clf-default-name
2023-03-19 17:17:18,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:17:18,596:INFO:version 3.0.0
2023-03-19 17:17:18,596:INFO:Initializing setup()
2023-03-19 17:17:18,596:INFO:self.USI: 2a9f
2023-03-19 17:17:18,596:INFO:self._variable_keys: {'idx', 'X_train', 'log_plots_param', 'fold_generator', 'is_multiclass', 'X_test', 'fix_imbalance', 'memory', 'seed', 'n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'data', 'y', 'exp_name_log', 'USI', 'fold_groups_param', 'y_train', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'html_param', 'exp_id', 'X', 'target_param'}
2023-03-19 17:17:18,596:INFO:Checking environment
2023-03-19 17:17:18,596:INFO:python_version: 3.10.0
2023-03-19 17:17:18,596:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:17:18,596:INFO:machine: AMD64
2023-03-19 17:17:18,596:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:17:18,604:INFO:Memory: svmem(total=16969424896, available=5901668352, percent=65.2, used=11067756544, free=5901668352)
2023-03-19 17:17:18,604:INFO:Physical Core: 4
2023-03-19 17:17:18,604:INFO:Logical Core: 8
2023-03-19 17:17:18,604:INFO:Checking libraries
2023-03-19 17:17:18,604:INFO:System:
2023-03-19 17:17:18,604:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:17:18,604:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:17:18,604:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:17:18,604:INFO:PyCaret required dependencies:
2023-03-19 17:17:18,604:INFO:                 pip: 23.0.1
2023-03-19 17:17:18,604:INFO:          setuptools: 65.6.3
2023-03-19 17:17:18,604:INFO:             pycaret: 3.0.0
2023-03-19 17:17:18,604:INFO:             IPython: 8.11.0
2023-03-19 17:17:18,604:INFO:          ipywidgets: 8.0.4
2023-03-19 17:17:18,604:INFO:                tqdm: 4.65.0
2023-03-19 17:17:18,604:INFO:               numpy: 1.23.5
2023-03-19 17:17:18,604:INFO:              pandas: 1.5.3
2023-03-19 17:17:18,604:INFO:              jinja2: 3.1.2
2023-03-19 17:17:18,604:INFO:               scipy: 1.10.1
2023-03-19 17:17:18,604:INFO:              joblib: 1.2.0
2023-03-19 17:17:18,604:INFO:             sklearn: 1.2.2
2023-03-19 17:17:18,604:INFO:                pyod: 1.0.8
2023-03-19 17:17:18,604:INFO:            imblearn: 0.10.1
2023-03-19 17:17:18,604:INFO:   category_encoders: 2.6.0
2023-03-19 17:17:18,604:INFO:            lightgbm: 3.3.5
2023-03-19 17:17:18,604:INFO:               numba: 0.56.4
2023-03-19 17:17:18,604:INFO:            requests: 2.28.2
2023-03-19 17:17:18,604:INFO:          matplotlib: 3.7.1
2023-03-19 17:17:18,604:INFO:          scikitplot: 0.3.7
2023-03-19 17:17:18,604:INFO:         yellowbrick: 1.5
2023-03-19 17:17:18,604:INFO:              plotly: 5.13.1
2023-03-19 17:17:18,604:INFO:             kaleido: 0.2.1
2023-03-19 17:17:18,604:INFO:         statsmodels: 0.13.5
2023-03-19 17:17:18,604:INFO:              sktime: 0.16.1
2023-03-19 17:17:18,604:INFO:               tbats: 1.1.2
2023-03-19 17:17:18,604:INFO:            pmdarima: 2.0.3
2023-03-19 17:17:18,604:INFO:              psutil: 5.9.4
2023-03-19 17:17:18,604:INFO:PyCaret optional dependencies:
2023-03-19 17:17:18,604:INFO:                shap: Not installed
2023-03-19 17:17:18,604:INFO:           interpret: Not installed
2023-03-19 17:17:18,604:INFO:                umap: Not installed
2023-03-19 17:17:18,604:INFO:    pandas_profiling: Not installed
2023-03-19 17:17:18,604:INFO:  explainerdashboard: Not installed
2023-03-19 17:17:18,612:INFO:             autoviz: Not installed
2023-03-19 17:17:18,612:INFO:           fairlearn: Not installed
2023-03-19 17:17:18,612:INFO:             xgboost: Not installed
2023-03-19 17:17:18,612:INFO:            catboost: Not installed
2023-03-19 17:17:18,612:INFO:              kmodes: Not installed
2023-03-19 17:17:18,612:INFO:             mlxtend: Not installed
2023-03-19 17:17:18,612:INFO:       statsforecast: Not installed
2023-03-19 17:17:18,612:INFO:        tune_sklearn: Not installed
2023-03-19 17:17:18,612:INFO:                 ray: Not installed
2023-03-19 17:17:18,612:INFO:            hyperopt: Not installed
2023-03-19 17:17:18,612:INFO:              optuna: Not installed
2023-03-19 17:17:18,612:INFO:               skopt: Not installed
2023-03-19 17:17:18,612:INFO:              mlflow: Not installed
2023-03-19 17:17:18,612:INFO:              gradio: Not installed
2023-03-19 17:17:18,612:INFO:             fastapi: Not installed
2023-03-19 17:17:18,612:INFO:             uvicorn: Not installed
2023-03-19 17:17:18,612:INFO:              m2cgen: Not installed
2023-03-19 17:17:18,612:INFO:           evidently: Not installed
2023-03-19 17:17:18,612:INFO:               fugue: Not installed
2023-03-19 17:17:18,612:INFO:           streamlit: Not installed
2023-03-19 17:17:18,612:INFO:             prophet: Not installed
2023-03-19 17:17:18,612:INFO:None
2023-03-19 17:17:18,612:INFO:Set up data.
2023-03-19 17:17:18,636:INFO:Set up train/test split.
2023-03-19 17:17:18,652:INFO:Set up index.
2023-03-19 17:17:18,652:INFO:Set up folding strategy.
2023-03-19 17:17:18,652:INFO:Assigning column types.
2023-03-19 17:17:18,660:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:17:18,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:17:18,700:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:17:18,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:17:18,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:17:18,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:17:18,836:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:17:18,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,918:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:17:18,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:18,942:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:17:19,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,088:INFO:Preparing preprocessing pipeline...
2023-03-19 17:17:19,096:INFO:Set up simple imputation.
2023-03-19 17:17:19,096:INFO:Set up encoding of ordinal features.
2023-03-19 17:17:19,096:INFO:Set up encoding of categorical features.
2023-03-19 17:17:19,104:INFO:Set up column name cleaning.
2023-03-19 17:17:19,351:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:17:19,379:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:17:19,379:INFO:Creating final display dataframe.
2023-03-19 17:17:19,541:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 y
2                   Target type            Binary
3           Original data shape       (32561, 15)
4        Transformed data shape       (32561, 65)
5   Transformed train set shape       (22792, 65)
6    Transformed test set shape        (9769, 65)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 8
10     Rows with missing values              7.4%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              2a9f
2023-03-19 17:17:19,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:17:19,694:INFO:setup() successfully completed in 1.11s...............
2023-03-19 17:17:34,750:INFO:Initializing compare_models()
2023-03-19 17:17:34,750:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:17:34,750:INFO:Checking exceptions
2023-03-19 17:17:34,758:INFO:Preparing display monitor
2023-03-19 17:17:34,790:INFO:Initializing Logistic Regression
2023-03-19 17:17:34,790:INFO:Total runtime is 0.0 minutes
2023-03-19 17:17:34,798:INFO:SubProcess create_model() called ==================================
2023-03-19 17:17:34,798:INFO:Initializing create_model()
2023-03-19 17:17:34,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:17:34,798:INFO:Checking exceptions
2023-03-19 17:17:34,798:INFO:Importing libraries
2023-03-19 17:17:34,798:INFO:Copying training dataset
2023-03-19 17:17:34,814:INFO:Defining folds
2023-03-19 17:17:34,814:INFO:Declaring metric variables
2023-03-19 17:17:34,814:INFO:Importing untrained model
2023-03-19 17:17:34,822:INFO:Logistic Regression Imported successfully
2023-03-19 17:17:34,830:INFO:Starting cross validation
2023-03-19 17:17:34,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:17:44,956:INFO:Calculating mean and std
2023-03-19 17:17:44,956:INFO:Creating metrics dataframe
2023-03-19 17:17:44,995:INFO:Uploading results into container
2023-03-19 17:17:44,995:INFO:Uploading model into container now
2023-03-19 17:17:44,995:INFO:_master_model_container: 1
2023-03-19 17:17:44,995:INFO:_display_container: 2
2023-03-19 17:17:44,995:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:17:44,995:INFO:create_model() successfully completed......................................
2023-03-19 17:17:45,076:INFO:SubProcess create_model() end ==================================
2023-03-19 17:17:45,076:INFO:Creating metrics dataframe
2023-03-19 17:17:45,084:INFO:Initializing K Neighbors Classifier
2023-03-19 17:17:45,084:INFO:Total runtime is 0.17155303955078124 minutes
2023-03-19 17:17:45,084:INFO:SubProcess create_model() called ==================================
2023-03-19 17:17:45,084:INFO:Initializing create_model()
2023-03-19 17:17:45,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:17:45,084:INFO:Checking exceptions
2023-03-19 17:17:45,084:INFO:Importing libraries
2023-03-19 17:17:45,084:INFO:Copying training dataset
2023-03-19 17:17:45,092:INFO:Defining folds
2023-03-19 17:17:45,092:INFO:Declaring metric variables
2023-03-19 17:17:45,100:INFO:Importing untrained model
2023-03-19 17:17:45,105:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:17:45,108:INFO:Starting cross validation
2023-03-19 17:17:45,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:17:50,352:INFO:Calculating mean and std
2023-03-19 17:17:50,352:INFO:Creating metrics dataframe
2023-03-19 17:17:50,384:INFO:Uploading results into container
2023-03-19 17:17:50,384:INFO:Uploading model into container now
2023-03-19 17:17:50,384:INFO:_master_model_container: 2
2023-03-19 17:17:50,384:INFO:_display_container: 2
2023-03-19 17:17:50,384:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:17:50,384:INFO:create_model() successfully completed......................................
2023-03-19 17:17:50,456:INFO:SubProcess create_model() end ==================================
2023-03-19 17:17:50,456:INFO:Creating metrics dataframe
2023-03-19 17:17:50,472:INFO:Initializing Naive Bayes
2023-03-19 17:17:50,472:INFO:Total runtime is 0.26135708491007487 minutes
2023-03-19 17:17:50,472:INFO:SubProcess create_model() called ==================================
2023-03-19 17:17:50,472:INFO:Initializing create_model()
2023-03-19 17:17:50,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:17:50,472:INFO:Checking exceptions
2023-03-19 17:17:50,472:INFO:Importing libraries
2023-03-19 17:17:50,472:INFO:Copying training dataset
2023-03-19 17:17:50,489:INFO:Defining folds
2023-03-19 17:17:50,489:INFO:Declaring metric variables
2023-03-19 17:17:50,489:INFO:Importing untrained model
2023-03-19 17:17:50,497:INFO:Naive Bayes Imported successfully
2023-03-19 17:17:50,505:INFO:Starting cross validation
2023-03-19 17:17:50,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:17:53,120:INFO:Calculating mean and std
2023-03-19 17:17:53,120:INFO:Creating metrics dataframe
2023-03-19 17:17:53,160:INFO:Uploading results into container
2023-03-19 17:17:53,160:INFO:Uploading model into container now
2023-03-19 17:17:53,160:INFO:_master_model_container: 3
2023-03-19 17:17:53,160:INFO:_display_container: 2
2023-03-19 17:17:53,160:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:17:53,160:INFO:create_model() successfully completed......................................
2023-03-19 17:17:53,225:INFO:SubProcess create_model() end ==================================
2023-03-19 17:17:53,225:INFO:Creating metrics dataframe
2023-03-19 17:17:53,241:INFO:Initializing Decision Tree Classifier
2023-03-19 17:17:53,241:INFO:Total runtime is 0.30750343402226765 minutes
2023-03-19 17:17:53,241:INFO:SubProcess create_model() called ==================================
2023-03-19 17:17:53,241:INFO:Initializing create_model()
2023-03-19 17:17:53,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:17:53,241:INFO:Checking exceptions
2023-03-19 17:17:53,241:INFO:Importing libraries
2023-03-19 17:17:53,241:INFO:Copying training dataset
2023-03-19 17:17:53,257:INFO:Defining folds
2023-03-19 17:17:53,257:INFO:Declaring metric variables
2023-03-19 17:17:53,257:INFO:Importing untrained model
2023-03-19 17:17:53,265:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:17:53,273:INFO:Starting cross validation
2023-03-19 17:17:53,273:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:17:55,367:INFO:Calculating mean and std
2023-03-19 17:17:55,375:INFO:Creating metrics dataframe
2023-03-19 17:17:55,415:INFO:Uploading results into container
2023-03-19 17:17:55,415:INFO:Uploading model into container now
2023-03-19 17:17:55,415:INFO:_master_model_container: 4
2023-03-19 17:17:55,415:INFO:_display_container: 2
2023-03-19 17:17:55,415:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-03-19 17:17:55,415:INFO:create_model() successfully completed......................................
2023-03-19 17:17:55,487:INFO:SubProcess create_model() end ==================================
2023-03-19 17:17:55,487:INFO:Creating metrics dataframe
2023-03-19 17:17:55,495:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:17:55,495:INFO:Total runtime is 0.3450835108757019 minutes
2023-03-19 17:17:55,503:INFO:SubProcess create_model() called ==================================
2023-03-19 17:17:55,503:INFO:Initializing create_model()
2023-03-19 17:17:55,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:17:55,503:INFO:Checking exceptions
2023-03-19 17:17:55,503:INFO:Importing libraries
2023-03-19 17:17:55,503:INFO:Copying training dataset
2023-03-19 17:17:55,518:INFO:Defining folds
2023-03-19 17:17:55,518:INFO:Declaring metric variables
2023-03-19 17:17:55,520:INFO:Importing untrained model
2023-03-19 17:17:55,531:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:17:55,536:INFO:Starting cross validation
2023-03-19 17:17:55,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:17:58,309:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:58,417:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:58,616:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:58,829:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:58,882:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:58,890:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:58,970:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:17:59,091:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:18:00,271:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:18:00,319:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:18:00,328:INFO:Calculating mean and std
2023-03-19 17:18:00,336:INFO:Creating metrics dataframe
2023-03-19 17:18:00,391:INFO:Uploading results into container
2023-03-19 17:18:00,391:INFO:Uploading model into container now
2023-03-19 17:18:00,393:INFO:_master_model_container: 5
2023-03-19 17:18:00,393:INFO:_display_container: 2
2023-03-19 17:18:00,393:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:18:00,393:INFO:create_model() successfully completed......................................
2023-03-19 17:18:00,465:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:00,465:INFO:Creating metrics dataframe
2023-03-19 17:18:00,494:INFO:Initializing Ridge Classifier
2023-03-19 17:18:00,494:INFO:Total runtime is 0.4283953428268432 minutes
2023-03-19 17:18:00,498:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:00,498:INFO:Initializing create_model()
2023-03-19 17:18:00,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:00,498:INFO:Checking exceptions
2023-03-19 17:18:00,498:INFO:Importing libraries
2023-03-19 17:18:00,498:INFO:Copying training dataset
2023-03-19 17:18:00,508:INFO:Defining folds
2023-03-19 17:18:00,508:INFO:Declaring metric variables
2023-03-19 17:18:00,508:INFO:Importing untrained model
2023-03-19 17:18:00,514:INFO:Ridge Classifier Imported successfully
2023-03-19 17:18:00,525:INFO:Starting cross validation
2023-03-19 17:18:00,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:01,467:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,467:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,499:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,536:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,539:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,571:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,614:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:01,732:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:02,077:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:02,077:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:18:02,125:INFO:Calculating mean and std
2023-03-19 17:18:02,133:INFO:Creating metrics dataframe
2023-03-19 17:18:02,190:INFO:Uploading results into container
2023-03-19 17:18:02,198:INFO:Uploading model into container now
2023-03-19 17:18:02,198:INFO:_master_model_container: 6
2023-03-19 17:18:02,198:INFO:_display_container: 2
2023-03-19 17:18:02,198:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-03-19 17:18:02,198:INFO:create_model() successfully completed......................................
2023-03-19 17:18:02,262:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:02,262:INFO:Creating metrics dataframe
2023-03-19 17:18:02,278:INFO:Initializing Random Forest Classifier
2023-03-19 17:18:02,278:INFO:Total runtime is 0.45813229878743483 minutes
2023-03-19 17:18:02,278:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:02,278:INFO:Initializing create_model()
2023-03-19 17:18:02,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:02,278:INFO:Checking exceptions
2023-03-19 17:18:02,278:INFO:Importing libraries
2023-03-19 17:18:02,278:INFO:Copying training dataset
2023-03-19 17:18:02,295:INFO:Defining folds
2023-03-19 17:18:02,295:INFO:Declaring metric variables
2023-03-19 17:18:02,301:INFO:Importing untrained model
2023-03-19 17:18:02,303:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:18:02,318:INFO:Starting cross validation
2023-03-19 17:18:02,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:05,281:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:18:05,502:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:18:08,533:INFO:Calculating mean and std
2023-03-19 17:18:08,533:INFO:Creating metrics dataframe
2023-03-19 17:18:08,597:INFO:Uploading results into container
2023-03-19 17:18:08,597:INFO:Uploading model into container now
2023-03-19 17:18:08,605:INFO:_master_model_container: 7
2023-03-19 17:18:08,605:INFO:_display_container: 2
2023-03-19 17:18:08,605:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-03-19 17:18:08,605:INFO:create_model() successfully completed......................................
2023-03-19 17:18:08,678:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:08,678:INFO:Creating metrics dataframe
2023-03-19 17:18:08,686:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:18:08,686:INFO:Total runtime is 0.5649199883143107 minutes
2023-03-19 17:18:08,694:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:08,694:INFO:Initializing create_model()
2023-03-19 17:18:08,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:08,694:INFO:Checking exceptions
2023-03-19 17:18:08,694:INFO:Importing libraries
2023-03-19 17:18:08,694:INFO:Copying training dataset
2023-03-19 17:18:08,702:INFO:Defining folds
2023-03-19 17:18:08,702:INFO:Declaring metric variables
2023-03-19 17:18:08,710:INFO:Importing untrained model
2023-03-19 17:18:08,710:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:18:08,718:INFO:Starting cross validation
2023-03-19 17:18:08,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:09,561:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:09,633:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:09,666:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:09,672:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:09,785:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:09,817:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:09,890:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:10,004:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:10,959:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:10,967:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:18:11,452:INFO:Calculating mean and std
2023-03-19 17:18:11,452:INFO:Creating metrics dataframe
2023-03-19 17:18:11,524:INFO:Uploading results into container
2023-03-19 17:18:11,524:INFO:Uploading model into container now
2023-03-19 17:18:11,524:INFO:_master_model_container: 8
2023-03-19 17:18:11,524:INFO:_display_container: 2
2023-03-19 17:18:11,524:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:18:11,524:INFO:create_model() successfully completed......................................
2023-03-19 17:18:11,597:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:11,597:INFO:Creating metrics dataframe
2023-03-19 17:18:11,613:INFO:Initializing Ada Boost Classifier
2023-03-19 17:18:11,613:INFO:Total runtime is 0.6137106617291768 minutes
2023-03-19 17:18:11,613:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:11,613:INFO:Initializing create_model()
2023-03-19 17:18:11,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:11,613:INFO:Checking exceptions
2023-03-19 17:18:11,613:INFO:Importing libraries
2023-03-19 17:18:11,613:INFO:Copying training dataset
2023-03-19 17:18:11,629:INFO:Defining folds
2023-03-19 17:18:11,629:INFO:Declaring metric variables
2023-03-19 17:18:11,629:INFO:Importing untrained model
2023-03-19 17:18:11,637:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:18:11,648:INFO:Starting cross validation
2023-03-19 17:18:11,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:17,340:INFO:Calculating mean and std
2023-03-19 17:18:17,340:INFO:Creating metrics dataframe
2023-03-19 17:18:17,429:INFO:Uploading results into container
2023-03-19 17:18:17,429:INFO:Uploading model into container now
2023-03-19 17:18:17,429:INFO:_master_model_container: 9
2023-03-19 17:18:17,429:INFO:_display_container: 2
2023-03-19 17:18:17,429:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-03-19 17:18:17,429:INFO:create_model() successfully completed......................................
2023-03-19 17:18:17,501:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:17,501:INFO:Creating metrics dataframe
2023-03-19 17:18:17,514:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:18:17,514:INFO:Total runtime is 0.7120567162831624 minutes
2023-03-19 17:18:17,518:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:17,518:INFO:Initializing create_model()
2023-03-19 17:18:17,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:17,518:INFO:Checking exceptions
2023-03-19 17:18:17,518:INFO:Importing libraries
2023-03-19 17:18:17,518:INFO:Copying training dataset
2023-03-19 17:18:17,525:INFO:Defining folds
2023-03-19 17:18:17,525:INFO:Declaring metric variables
2023-03-19 17:18:17,536:INFO:Importing untrained model
2023-03-19 17:18:17,541:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:18:17,550:INFO:Starting cross validation
2023-03-19 17:18:17,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:29,233:INFO:Calculating mean and std
2023-03-19 17:18:29,233:INFO:Creating metrics dataframe
2023-03-19 17:18:29,322:INFO:Uploading results into container
2023-03-19 17:18:29,322:INFO:Uploading model into container now
2023-03-19 17:18:29,322:INFO:_master_model_container: 10
2023-03-19 17:18:29,322:INFO:_display_container: 2
2023-03-19 17:18:29,322:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:18:29,322:INFO:create_model() successfully completed......................................
2023-03-19 17:18:29,395:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:29,395:INFO:Creating metrics dataframe
2023-03-19 17:18:29,411:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:18:29,411:INFO:Total runtime is 0.9103429555892943 minutes
2023-03-19 17:18:29,411:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:29,411:INFO:Initializing create_model()
2023-03-19 17:18:29,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:29,411:INFO:Checking exceptions
2023-03-19 17:18:29,411:INFO:Importing libraries
2023-03-19 17:18:29,411:INFO:Copying training dataset
2023-03-19 17:18:29,427:INFO:Defining folds
2023-03-19 17:18:29,427:INFO:Declaring metric variables
2023-03-19 17:18:29,427:INFO:Importing untrained model
2023-03-19 17:18:29,435:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:18:29,443:INFO:Starting cross validation
2023-03-19 17:18:29,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:32,757:INFO:Calculating mean and std
2023-03-19 17:18:32,757:INFO:Creating metrics dataframe
2023-03-19 17:18:32,862:INFO:Uploading results into container
2023-03-19 17:18:32,870:INFO:Uploading model into container now
2023-03-19 17:18:32,870:INFO:_master_model_container: 11
2023-03-19 17:18:32,870:INFO:_display_container: 2
2023-03-19 17:18:32,871:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:18:32,871:INFO:create_model() successfully completed......................................
2023-03-19 17:18:32,951:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:32,951:INFO:Creating metrics dataframe
2023-03-19 17:18:32,959:INFO:Initializing Extra Trees Classifier
2023-03-19 17:18:32,959:INFO:Total runtime is 0.9694750666618346 minutes
2023-03-19 17:18:32,971:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:32,971:INFO:Initializing create_model()
2023-03-19 17:18:32,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:32,971:INFO:Checking exceptions
2023-03-19 17:18:32,971:INFO:Importing libraries
2023-03-19 17:18:32,971:INFO:Copying training dataset
2023-03-19 17:18:32,983:INFO:Defining folds
2023-03-19 17:18:32,983:INFO:Declaring metric variables
2023-03-19 17:18:32,995:INFO:Importing untrained model
2023-03-19 17:18:33,000:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:18:33,008:INFO:Starting cross validation
2023-03-19 17:18:33,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:37,160:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:18:37,667:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:18:38,032:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:18:38,520:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:18:42,519:INFO:Calculating mean and std
2023-03-19 17:18:42,519:INFO:Creating metrics dataframe
2023-03-19 17:18:42,639:INFO:Uploading results into container
2023-03-19 17:18:42,639:INFO:Uploading model into container now
2023-03-19 17:18:42,639:INFO:_master_model_container: 12
2023-03-19 17:18:42,639:INFO:_display_container: 2
2023-03-19 17:18:42,639:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-03-19 17:18:42,639:INFO:create_model() successfully completed......................................
2023-03-19 17:18:42,712:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:42,712:INFO:Creating metrics dataframe
2023-03-19 17:18:42,728:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:18:42,728:INFO:Total runtime is 1.1322947978973388 minutes
2023-03-19 17:18:42,729:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:42,729:INFO:Initializing create_model()
2023-03-19 17:18:42,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:42,729:INFO:Checking exceptions
2023-03-19 17:18:42,729:INFO:Importing libraries
2023-03-19 17:18:42,729:INFO:Copying training dataset
2023-03-19 17:18:42,744:INFO:Defining folds
2023-03-19 17:18:42,744:INFO:Declaring metric variables
2023-03-19 17:18:42,752:INFO:Importing untrained model
2023-03-19 17:18:42,760:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:18:42,776:INFO:Starting cross validation
2023-03-19 17:18:42,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:46,154:INFO:Calculating mean and std
2023-03-19 17:18:46,154:INFO:Creating metrics dataframe
2023-03-19 17:18:46,276:INFO:Uploading results into container
2023-03-19 17:18:46,276:INFO:Uploading model into container now
2023-03-19 17:18:46,276:INFO:_master_model_container: 13
2023-03-19 17:18:46,276:INFO:_display_container: 2
2023-03-19 17:18:46,276:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:18:46,276:INFO:create_model() successfully completed......................................
2023-03-19 17:18:46,356:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:46,356:INFO:Creating metrics dataframe
2023-03-19 17:18:46,364:INFO:Initializing Dummy Classifier
2023-03-19 17:18:46,364:INFO:Total runtime is 1.1929005304972329 minutes
2023-03-19 17:18:46,372:INFO:SubProcess create_model() called ==================================
2023-03-19 17:18:46,372:INFO:Initializing create_model()
2023-03-19 17:18:46,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805EDDF60>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:46,372:INFO:Checking exceptions
2023-03-19 17:18:46,372:INFO:Importing libraries
2023-03-19 17:18:46,372:INFO:Copying training dataset
2023-03-19 17:18:46,383:INFO:Defining folds
2023-03-19 17:18:46,383:INFO:Declaring metric variables
2023-03-19 17:18:46,388:INFO:Importing untrained model
2023-03-19 17:18:46,391:INFO:Dummy Classifier Imported successfully
2023-03-19 17:18:46,405:INFO:Starting cross validation
2023-03-19 17:18:46,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:18:47,323:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,331:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,452:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,460:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,566:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,584:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,598:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:47,636:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:48,277:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:48,284:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:18:48,527:INFO:Calculating mean and std
2023-03-19 17:18:48,527:INFO:Creating metrics dataframe
2023-03-19 17:18:48,654:INFO:Uploading results into container
2023-03-19 17:18:48,662:INFO:Uploading model into container now
2023-03-19 17:18:48,662:INFO:_master_model_container: 14
2023-03-19 17:18:48,662:INFO:_display_container: 2
2023-03-19 17:18:48,662:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-03-19 17:18:48,662:INFO:create_model() successfully completed......................................
2023-03-19 17:18:48,744:INFO:SubProcess create_model() end ==================================
2023-03-19 17:18:48,744:INFO:Creating metrics dataframe
2023-03-19 17:18:48,785:INFO:Initializing create_model()
2023-03-19 17:18:48,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A805EDDA50>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:18:48,785:INFO:Checking exceptions
2023-03-19 17:18:48,793:INFO:Importing libraries
2023-03-19 17:18:48,793:INFO:Copying training dataset
2023-03-19 17:18:48,816:INFO:Defining folds
2023-03-19 17:18:48,816:INFO:Declaring metric variables
2023-03-19 17:18:48,816:INFO:Importing untrained model
2023-03-19 17:18:48,816:INFO:Declaring custom model
2023-03-19 17:18:48,816:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:18:48,824:INFO:Cross validation set to False
2023-03-19 17:18:48,824:INFO:Fitting Model
2023-03-19 17:18:49,456:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:18:49,456:INFO:create_model() successfully completed......................................
2023-03-19 17:18:49,594:INFO:_master_model_container: 14
2023-03-19 17:18:49,594:INFO:_display_container: 2
2023-03-19 17:18:49,594:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:18:49,594:INFO:compare_models() successfully completed......................................
2023-03-19 17:26:34,573:INFO:PyCaret ClassificationExperiment
2023-03-19 17:26:34,573:INFO:Logging name: test
2023-03-19 17:26:34,573:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:26:34,573:INFO:version 3.0.0
2023-03-19 17:26:34,573:INFO:Initializing setup()
2023-03-19 17:26:34,573:INFO:self.USI: 8b07
2023-03-19 17:26:34,573:INFO:self._variable_keys: {'idx', 'X_train', 'log_plots_param', 'fold_generator', 'is_multiclass', 'X_test', 'fix_imbalance', 'memory', 'seed', 'n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'data', 'y', 'exp_name_log', 'USI', 'fold_groups_param', 'y_train', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'html_param', 'exp_id', 'X', 'target_param'}
2023-03-19 17:26:34,573:INFO:Checking environment
2023-03-19 17:26:34,573:INFO:python_version: 3.10.0
2023-03-19 17:26:34,573:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:26:34,573:INFO:machine: AMD64
2023-03-19 17:26:34,573:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:26:34,581:INFO:Memory: svmem(total=16969424896, available=5650227200, percent=66.7, used=11319197696, free=5650227200)
2023-03-19 17:26:34,581:INFO:Physical Core: 4
2023-03-19 17:26:34,581:INFO:Logical Core: 8
2023-03-19 17:26:34,581:INFO:Checking libraries
2023-03-19 17:26:34,581:INFO:System:
2023-03-19 17:26:34,581:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:26:34,581:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:26:34,581:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:26:34,581:INFO:PyCaret required dependencies:
2023-03-19 17:26:34,581:INFO:                 pip: 23.0.1
2023-03-19 17:26:34,581:INFO:          setuptools: 65.6.3
2023-03-19 17:26:34,581:INFO:             pycaret: 3.0.0
2023-03-19 17:26:34,581:INFO:             IPython: 8.11.0
2023-03-19 17:26:34,581:INFO:          ipywidgets: 8.0.4
2023-03-19 17:26:34,581:INFO:                tqdm: 4.65.0
2023-03-19 17:26:34,581:INFO:               numpy: 1.23.5
2023-03-19 17:26:34,581:INFO:              pandas: 1.5.3
2023-03-19 17:26:34,581:INFO:              jinja2: 3.1.2
2023-03-19 17:26:34,581:INFO:               scipy: 1.10.1
2023-03-19 17:26:34,581:INFO:              joblib: 1.2.0
2023-03-19 17:26:34,581:INFO:             sklearn: 1.2.2
2023-03-19 17:26:34,581:INFO:                pyod: 1.0.8
2023-03-19 17:26:34,581:INFO:            imblearn: 0.10.1
2023-03-19 17:26:34,581:INFO:   category_encoders: 2.6.0
2023-03-19 17:26:34,581:INFO:            lightgbm: 3.3.5
2023-03-19 17:26:34,581:INFO:               numba: 0.56.4
2023-03-19 17:26:34,581:INFO:            requests: 2.28.2
2023-03-19 17:26:34,581:INFO:          matplotlib: 3.7.1
2023-03-19 17:26:34,581:INFO:          scikitplot: 0.3.7
2023-03-19 17:26:34,581:INFO:         yellowbrick: 1.5
2023-03-19 17:26:34,581:INFO:              plotly: 5.13.1
2023-03-19 17:26:34,581:INFO:             kaleido: 0.2.1
2023-03-19 17:26:34,581:INFO:         statsmodels: 0.13.5
2023-03-19 17:26:34,581:INFO:              sktime: 0.16.1
2023-03-19 17:26:34,581:INFO:               tbats: 1.1.2
2023-03-19 17:26:34,581:INFO:            pmdarima: 2.0.3
2023-03-19 17:26:34,581:INFO:              psutil: 5.9.4
2023-03-19 17:26:34,581:INFO:PyCaret optional dependencies:
2023-03-19 17:26:34,581:INFO:                shap: Not installed
2023-03-19 17:26:34,581:INFO:           interpret: Not installed
2023-03-19 17:26:34,581:INFO:                umap: Not installed
2023-03-19 17:26:34,581:INFO:    pandas_profiling: Not installed
2023-03-19 17:26:34,581:INFO:  explainerdashboard: Not installed
2023-03-19 17:26:34,581:INFO:             autoviz: Not installed
2023-03-19 17:26:34,581:INFO:           fairlearn: Not installed
2023-03-19 17:26:34,581:INFO:             xgboost: Not installed
2023-03-19 17:26:34,581:INFO:            catboost: Not installed
2023-03-19 17:26:34,581:INFO:              kmodes: Not installed
2023-03-19 17:26:34,581:INFO:             mlxtend: Not installed
2023-03-19 17:26:34,581:INFO:       statsforecast: Not installed
2023-03-19 17:26:34,581:INFO:        tune_sklearn: Not installed
2023-03-19 17:26:34,581:INFO:                 ray: Not installed
2023-03-19 17:26:34,581:INFO:            hyperopt: Not installed
2023-03-19 17:26:34,581:INFO:              optuna: Not installed
2023-03-19 17:26:34,581:INFO:               skopt: Not installed
2023-03-19 17:26:34,581:INFO:              mlflow: Not installed
2023-03-19 17:26:34,581:INFO:              gradio: Not installed
2023-03-19 17:26:34,581:INFO:             fastapi: Not installed
2023-03-19 17:26:34,581:INFO:             uvicorn: Not installed
2023-03-19 17:26:34,581:INFO:              m2cgen: Not installed
2023-03-19 17:26:34,581:INFO:           evidently: Not installed
2023-03-19 17:26:34,581:INFO:               fugue: Not installed
2023-03-19 17:26:34,581:INFO:           streamlit: Not installed
2023-03-19 17:26:34,581:INFO:             prophet: Not installed
2023-03-19 17:26:34,581:INFO:None
2023-03-19 17:26:34,581:INFO:Set up data.
2023-03-19 17:26:34,621:INFO:Set up train/test split.
2023-03-19 17:26:34,635:INFO:Set up index.
2023-03-19 17:26:34,635:INFO:Set up folding strategy.
2023-03-19 17:26:34,635:INFO:Assigning column types.
2023-03-19 17:26:34,637:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:26:34,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:26:34,686:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:26:34,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:26:34,783:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:26:34,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,808:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:26:34,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:26:34,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,921:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:26:34,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:34,945:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:26:35,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,107:INFO:Preparing preprocessing pipeline...
2023-03-19 17:26:35,107:INFO:Set up simple imputation.
2023-03-19 17:26:35,115:INFO:Set up encoding of ordinal features.
2023-03-19 17:26:35,115:INFO:Set up encoding of categorical features.
2023-03-19 17:26:35,122:INFO:Set up column name cleaning.
2023-03-19 17:26:35,357:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:26:35,373:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:26:35,373:INFO:Creating final display dataframe.
2023-03-19 17:26:35,511:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment            False
22              Experiment Name             test
23                          USI             8b07
2023-03-19 17:26:35,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:26:35,736:INFO:setup() successfully completed in 1.27s...............
2023-03-19 17:27:47,787:INFO:PyCaret ClassificationExperiment
2023-03-19 17:27:47,787:INFO:Logging name: default
2023-03-19 17:27:47,787:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:27:47,787:INFO:version 3.0.0
2023-03-19 17:27:47,787:INFO:Initializing setup()
2023-03-19 17:27:47,787:INFO:self.USI: d930
2023-03-19 17:27:47,787:INFO:self._variable_keys: {'idx', 'X_train', 'log_plots_param', 'fold_generator', 'is_multiclass', 'X_test', 'fix_imbalance', 'memory', 'seed', 'n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'data', 'y', 'exp_name_log', 'USI', 'fold_groups_param', 'y_train', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'html_param', 'exp_id', 'X', 'target_param'}
2023-03-19 17:27:47,787:INFO:Checking environment
2023-03-19 17:27:47,787:INFO:python_version: 3.10.0
2023-03-19 17:27:47,787:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:27:47,787:INFO:machine: AMD64
2023-03-19 17:27:47,787:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:27:47,795:INFO:Memory: svmem(total=16969424896, available=5603913728, percent=67.0, used=11365511168, free=5603913728)
2023-03-19 17:27:47,795:INFO:Physical Core: 4
2023-03-19 17:27:47,795:INFO:Logical Core: 8
2023-03-19 17:27:47,795:INFO:Checking libraries
2023-03-19 17:27:47,795:INFO:System:
2023-03-19 17:27:47,795:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:27:47,795:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:27:47,795:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:27:47,795:INFO:PyCaret required dependencies:
2023-03-19 17:27:47,795:INFO:                 pip: 23.0.1
2023-03-19 17:27:47,795:INFO:          setuptools: 65.6.3
2023-03-19 17:27:47,795:INFO:             pycaret: 3.0.0
2023-03-19 17:27:47,795:INFO:             IPython: 8.11.0
2023-03-19 17:27:47,795:INFO:          ipywidgets: 8.0.4
2023-03-19 17:27:47,795:INFO:                tqdm: 4.65.0
2023-03-19 17:27:47,795:INFO:               numpy: 1.23.5
2023-03-19 17:27:47,795:INFO:              pandas: 1.5.3
2023-03-19 17:27:47,795:INFO:              jinja2: 3.1.2
2023-03-19 17:27:47,795:INFO:               scipy: 1.10.1
2023-03-19 17:27:47,801:INFO:              joblib: 1.2.0
2023-03-19 17:27:47,801:INFO:             sklearn: 1.2.2
2023-03-19 17:27:47,801:INFO:                pyod: 1.0.8
2023-03-19 17:27:47,801:INFO:            imblearn: 0.10.1
2023-03-19 17:27:47,801:INFO:   category_encoders: 2.6.0
2023-03-19 17:27:47,801:INFO:            lightgbm: 3.3.5
2023-03-19 17:27:47,801:INFO:               numba: 0.56.4
2023-03-19 17:27:47,801:INFO:            requests: 2.28.2
2023-03-19 17:27:47,801:INFO:          matplotlib: 3.7.1
2023-03-19 17:27:47,801:INFO:          scikitplot: 0.3.7
2023-03-19 17:27:47,801:INFO:         yellowbrick: 1.5
2023-03-19 17:27:47,801:INFO:              plotly: 5.13.1
2023-03-19 17:27:47,801:INFO:             kaleido: 0.2.1
2023-03-19 17:27:47,801:INFO:         statsmodels: 0.13.5
2023-03-19 17:27:47,801:INFO:              sktime: 0.16.1
2023-03-19 17:27:47,801:INFO:               tbats: 1.1.2
2023-03-19 17:27:47,801:INFO:            pmdarima: 2.0.3
2023-03-19 17:27:47,801:INFO:              psutil: 5.9.4
2023-03-19 17:27:47,801:INFO:PyCaret optional dependencies:
2023-03-19 17:27:47,801:INFO:                shap: Not installed
2023-03-19 17:27:47,801:INFO:           interpret: Not installed
2023-03-19 17:27:47,801:INFO:                umap: Not installed
2023-03-19 17:27:47,802:INFO:    pandas_profiling: Not installed
2023-03-19 17:27:47,802:INFO:  explainerdashboard: Not installed
2023-03-19 17:27:47,802:INFO:             autoviz: Not installed
2023-03-19 17:27:47,802:INFO:           fairlearn: Not installed
2023-03-19 17:27:47,802:INFO:             xgboost: Not installed
2023-03-19 17:27:47,802:INFO:            catboost: Not installed
2023-03-19 17:27:47,802:INFO:              kmodes: Not installed
2023-03-19 17:27:47,802:INFO:             mlxtend: Not installed
2023-03-19 17:27:47,802:INFO:       statsforecast: Not installed
2023-03-19 17:27:47,802:INFO:        tune_sklearn: Not installed
2023-03-19 17:27:47,802:INFO:                 ray: Not installed
2023-03-19 17:27:47,802:INFO:            hyperopt: Not installed
2023-03-19 17:27:47,802:INFO:              optuna: Not installed
2023-03-19 17:27:47,802:INFO:               skopt: Not installed
2023-03-19 17:27:47,802:INFO:              mlflow: Not installed
2023-03-19 17:27:47,802:INFO:              gradio: Not installed
2023-03-19 17:27:47,802:INFO:             fastapi: Not installed
2023-03-19 17:27:47,802:INFO:             uvicorn: Not installed
2023-03-19 17:27:47,802:INFO:              m2cgen: Not installed
2023-03-19 17:27:47,803:INFO:           evidently: Not installed
2023-03-19 17:27:47,803:INFO:               fugue: Not installed
2023-03-19 17:27:47,803:INFO:           streamlit: Not installed
2023-03-19 17:27:47,803:INFO:             prophet: Not installed
2023-03-19 17:27:47,803:INFO:None
2023-03-19 17:27:47,803:INFO:Set up data.
2023-03-19 17:27:47,827:INFO:Set up train/test split.
2023-03-19 17:27:47,843:INFO:Set up index.
2023-03-19 17:27:47,843:INFO:Set up folding strategy.
2023-03-19 17:27:47,843:INFO:Assigning column types.
2023-03-19 17:27:47,843:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:27:47,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:27:47,891:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:27:47,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:47,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:47,956:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:27:47,956:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:27:47,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:47,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:47,989:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:27:48,029:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:27:48,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:27:48,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,125:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:27:48,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,271:INFO:Preparing preprocessing pipeline...
2023-03-19 17:27:48,271:INFO:Set up simple imputation.
2023-03-19 17:27:48,271:INFO:Set up encoding of ordinal features.
2023-03-19 17:27:48,279:INFO:Set up encoding of categorical features.
2023-03-19 17:27:48,279:INFO:Set up column name cleaning.
2023-03-19 17:27:48,537:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:27:48,559:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:27:48,559:INFO:Creating final display dataframe.
2023-03-19 17:27:48,723:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment            False
22              Experiment Name          default
23                          USI             d930
2023-03-19 17:27:48,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:27:48,952:INFO:setup() successfully completed in 1.25s...............
2023-03-19 17:28:05,344:INFO:PyCaret ClassificationExperiment
2023-03-19 17:28:05,344:INFO:Logging name: default
2023-03-19 17:28:05,344:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:28:05,344:INFO:version 3.0.0
2023-03-19 17:28:05,344:INFO:Initializing setup()
2023-03-19 17:28:05,344:INFO:self.USI: 0e0e
2023-03-19 17:28:05,344:INFO:self._variable_keys: {'idx', 'X_train', 'log_plots_param', 'fold_generator', 'is_multiclass', 'X_test', 'fix_imbalance', 'memory', 'seed', 'n_jobs_param', 'y_test', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'data', 'y', 'exp_name_log', 'USI', 'fold_groups_param', 'y_train', 'logging_param', '_available_plots', 'gpu_n_jobs_param', 'gpu_param', 'html_param', 'exp_id', 'X', 'target_param'}
2023-03-19 17:28:05,344:INFO:Checking environment
2023-03-19 17:28:05,344:INFO:python_version: 3.10.0
2023-03-19 17:28:05,344:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:28:05,344:INFO:machine: AMD64
2023-03-19 17:28:05,344:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:28:05,355:INFO:Memory: svmem(total=16969424896, available=5691097088, percent=66.5, used=11278327808, free=5691097088)
2023-03-19 17:28:05,355:INFO:Physical Core: 4
2023-03-19 17:28:05,355:INFO:Logical Core: 8
2023-03-19 17:28:05,355:INFO:Checking libraries
2023-03-19 17:28:05,355:INFO:System:
2023-03-19 17:28:05,355:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:28:05,355:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:28:05,355:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:28:05,355:INFO:PyCaret required dependencies:
2023-03-19 17:28:05,355:INFO:                 pip: 23.0.1
2023-03-19 17:28:05,355:INFO:          setuptools: 65.6.3
2023-03-19 17:28:05,355:INFO:             pycaret: 3.0.0
2023-03-19 17:28:05,355:INFO:             IPython: 8.11.0
2023-03-19 17:28:05,355:INFO:          ipywidgets: 8.0.4
2023-03-19 17:28:05,355:INFO:                tqdm: 4.65.0
2023-03-19 17:28:05,355:INFO:               numpy: 1.23.5
2023-03-19 17:28:05,355:INFO:              pandas: 1.5.3
2023-03-19 17:28:05,355:INFO:              jinja2: 3.1.2
2023-03-19 17:28:05,355:INFO:               scipy: 1.10.1
2023-03-19 17:28:05,355:INFO:              joblib: 1.2.0
2023-03-19 17:28:05,355:INFO:             sklearn: 1.2.2
2023-03-19 17:28:05,355:INFO:                pyod: 1.0.8
2023-03-19 17:28:05,355:INFO:            imblearn: 0.10.1
2023-03-19 17:28:05,355:INFO:   category_encoders: 2.6.0
2023-03-19 17:28:05,355:INFO:            lightgbm: 3.3.5
2023-03-19 17:28:05,355:INFO:               numba: 0.56.4
2023-03-19 17:28:05,355:INFO:            requests: 2.28.2
2023-03-19 17:28:05,355:INFO:          matplotlib: 3.7.1
2023-03-19 17:28:05,355:INFO:          scikitplot: 0.3.7
2023-03-19 17:28:05,355:INFO:         yellowbrick: 1.5
2023-03-19 17:28:05,355:INFO:              plotly: 5.13.1
2023-03-19 17:28:05,355:INFO:             kaleido: 0.2.1
2023-03-19 17:28:05,355:INFO:         statsmodels: 0.13.5
2023-03-19 17:28:05,355:INFO:              sktime: 0.16.1
2023-03-19 17:28:05,355:INFO:               tbats: 1.1.2
2023-03-19 17:28:05,355:INFO:            pmdarima: 2.0.3
2023-03-19 17:28:05,355:INFO:              psutil: 5.9.4
2023-03-19 17:28:05,355:INFO:PyCaret optional dependencies:
2023-03-19 17:28:05,355:INFO:                shap: Not installed
2023-03-19 17:28:05,355:INFO:           interpret: Not installed
2023-03-19 17:28:05,355:INFO:                umap: Not installed
2023-03-19 17:28:05,355:INFO:    pandas_profiling: Not installed
2023-03-19 17:28:05,355:INFO:  explainerdashboard: Not installed
2023-03-19 17:28:05,355:INFO:             autoviz: Not installed
2023-03-19 17:28:05,355:INFO:           fairlearn: Not installed
2023-03-19 17:28:05,355:INFO:             xgboost: Not installed
2023-03-19 17:28:05,355:INFO:            catboost: Not installed
2023-03-19 17:28:05,355:INFO:              kmodes: Not installed
2023-03-19 17:28:05,355:INFO:             mlxtend: Not installed
2023-03-19 17:28:05,355:INFO:       statsforecast: Not installed
2023-03-19 17:28:05,355:INFO:        tune_sklearn: Not installed
2023-03-19 17:28:05,355:INFO:                 ray: Not installed
2023-03-19 17:28:05,359:INFO:            hyperopt: Not installed
2023-03-19 17:28:05,359:INFO:              optuna: Not installed
2023-03-19 17:28:05,359:INFO:               skopt: Not installed
2023-03-19 17:28:05,359:INFO:              mlflow: Not installed
2023-03-19 17:28:05,359:INFO:              gradio: Not installed
2023-03-19 17:28:05,359:INFO:             fastapi: Not installed
2023-03-19 17:28:05,359:INFO:             uvicorn: Not installed
2023-03-19 17:28:05,359:INFO:              m2cgen: Not installed
2023-03-19 17:28:05,359:INFO:           evidently: Not installed
2023-03-19 17:28:05,359:INFO:               fugue: Not installed
2023-03-19 17:28:05,359:INFO:           streamlit: Not installed
2023-03-19 17:28:05,359:INFO:             prophet: Not installed
2023-03-19 17:28:05,359:INFO:None
2023-03-19 17:28:05,359:INFO:Set up data.
2023-03-19 17:28:05,385:INFO:Set up train/test split.
2023-03-19 17:28:05,401:INFO:Set up index.
2023-03-19 17:28:05,401:INFO:Set up folding strategy.
2023-03-19 17:28:05,401:INFO:Assigning column types.
2023-03-19 17:28:05,409:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:28:05,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:28:05,454:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:28:05,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:28:05,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:28:05,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,563:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:28:05,603:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:28:05,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:28:05,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,700:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:28:05,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:05,844:INFO:Preparing preprocessing pipeline...
2023-03-19 17:28:05,844:INFO:Set up simple imputation.
2023-03-19 17:28:05,852:INFO:Set up encoding of ordinal features.
2023-03-19 17:28:05,852:INFO:Set up encoding of categorical features.
2023-03-19 17:28:05,852:INFO:Set up column name cleaning.
2023-03-19 17:28:06,118:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:28:06,134:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:28:06,134:INFO:Creating final display dataframe.
2023-03-19 17:28:06,286:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment            False
22              Experiment Name          default
23                          USI             0e0e
2023-03-19 17:28:06,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:06,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:06,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:06,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:28:06,448:INFO:setup() successfully completed in 1.18s...............
2023-03-19 17:28:22,152:INFO:Initializing compare_models()
2023-03-19 17:28:22,152:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:28:22,152:INFO:Checking exceptions
2023-03-19 17:28:22,160:INFO:Preparing display monitor
2023-03-19 17:28:22,200:INFO:Initializing Logistic Regression
2023-03-19 17:28:22,200:INFO:Total runtime is 0.0 minutes
2023-03-19 17:28:22,200:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:22,200:INFO:Initializing create_model()
2023-03-19 17:28:22,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:22,200:INFO:Checking exceptions
2023-03-19 17:28:22,200:INFO:Importing libraries
2023-03-19 17:28:22,200:INFO:Copying training dataset
2023-03-19 17:28:22,208:INFO:Defining folds
2023-03-19 17:28:22,208:INFO:Declaring metric variables
2023-03-19 17:28:22,216:INFO:Importing untrained model
2023-03-19 17:28:22,224:INFO:Logistic Regression Imported successfully
2023-03-19 17:28:22,232:INFO:Starting cross validation
2023-03-19 17:28:22,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:30,536:INFO:Calculating mean and std
2023-03-19 17:28:30,536:INFO:Creating metrics dataframe
2023-03-19 17:28:30,665:INFO:Uploading results into container
2023-03-19 17:28:30,665:INFO:Uploading model into container now
2023-03-19 17:28:30,665:INFO:_master_model_container: 1
2023-03-19 17:28:30,665:INFO:_display_container: 2
2023-03-19 17:28:30,665:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:28:30,665:INFO:create_model() successfully completed......................................
2023-03-19 17:28:30,778:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:30,778:INFO:Creating metrics dataframe
2023-03-19 17:28:30,793:INFO:Initializing K Neighbors Classifier
2023-03-19 17:28:30,793:INFO:Total runtime is 0.14321082433064777 minutes
2023-03-19 17:28:30,793:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:30,793:INFO:Initializing create_model()
2023-03-19 17:28:30,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:30,793:INFO:Checking exceptions
2023-03-19 17:28:30,801:INFO:Importing libraries
2023-03-19 17:28:30,801:INFO:Copying training dataset
2023-03-19 17:28:30,817:INFO:Defining folds
2023-03-19 17:28:30,817:INFO:Declaring metric variables
2023-03-19 17:28:30,817:INFO:Importing untrained model
2023-03-19 17:28:30,828:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:28:30,834:INFO:Starting cross validation
2023-03-19 17:28:30,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:35,853:INFO:Calculating mean and std
2023-03-19 17:28:35,853:INFO:Creating metrics dataframe
2023-03-19 17:28:35,991:INFO:Uploading results into container
2023-03-19 17:28:35,991:INFO:Uploading model into container now
2023-03-19 17:28:35,991:INFO:_master_model_container: 2
2023-03-19 17:28:35,991:INFO:_display_container: 2
2023-03-19 17:28:35,993:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:28:35,993:INFO:create_model() successfully completed......................................
2023-03-19 17:28:36,079:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:36,079:INFO:Creating metrics dataframe
2023-03-19 17:28:36,095:INFO:Initializing Naive Bayes
2023-03-19 17:28:36,095:INFO:Total runtime is 0.23157980839411418 minutes
2023-03-19 17:28:36,103:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:36,103:INFO:Initializing create_model()
2023-03-19 17:28:36,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:36,103:INFO:Checking exceptions
2023-03-19 17:28:36,103:INFO:Importing libraries
2023-03-19 17:28:36,103:INFO:Copying training dataset
2023-03-19 17:28:36,112:INFO:Defining folds
2023-03-19 17:28:36,112:INFO:Declaring metric variables
2023-03-19 17:28:36,120:INFO:Importing untrained model
2023-03-19 17:28:36,128:INFO:Naive Bayes Imported successfully
2023-03-19 17:28:36,136:INFO:Starting cross validation
2023-03-19 17:28:36,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:38,216:INFO:Calculating mean and std
2023-03-19 17:28:38,216:INFO:Creating metrics dataframe
2023-03-19 17:28:38,354:INFO:Uploading results into container
2023-03-19 17:28:38,354:INFO:Uploading model into container now
2023-03-19 17:28:38,354:INFO:_master_model_container: 3
2023-03-19 17:28:38,354:INFO:_display_container: 2
2023-03-19 17:28:38,354:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:28:38,354:INFO:create_model() successfully completed......................................
2023-03-19 17:28:38,426:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:38,426:INFO:Creating metrics dataframe
2023-03-19 17:28:38,442:INFO:Initializing Decision Tree Classifier
2023-03-19 17:28:38,442:INFO:Total runtime is 0.2706876754760742 minutes
2023-03-19 17:28:38,442:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:38,442:INFO:Initializing create_model()
2023-03-19 17:28:38,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:38,442:INFO:Checking exceptions
2023-03-19 17:28:38,442:INFO:Importing libraries
2023-03-19 17:28:38,442:INFO:Copying training dataset
2023-03-19 17:28:38,458:INFO:Defining folds
2023-03-19 17:28:38,458:INFO:Declaring metric variables
2023-03-19 17:28:38,458:INFO:Importing untrained model
2023-03-19 17:28:38,466:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:28:38,482:INFO:Starting cross validation
2023-03-19 17:28:38,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:40,271:INFO:Calculating mean and std
2023-03-19 17:28:40,271:INFO:Creating metrics dataframe
2023-03-19 17:28:40,399:INFO:Uploading results into container
2023-03-19 17:28:40,399:INFO:Uploading model into container now
2023-03-19 17:28:40,399:INFO:_master_model_container: 4
2023-03-19 17:28:40,399:INFO:_display_container: 2
2023-03-19 17:28:40,399:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-03-19 17:28:40,399:INFO:create_model() successfully completed......................................
2023-03-19 17:28:40,472:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:40,472:INFO:Creating metrics dataframe
2023-03-19 17:28:40,488:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:28:40,488:INFO:Total runtime is 0.30479789972305293 minutes
2023-03-19 17:28:40,488:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:40,488:INFO:Initializing create_model()
2023-03-19 17:28:40,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:40,488:INFO:Checking exceptions
2023-03-19 17:28:40,488:INFO:Importing libraries
2023-03-19 17:28:40,488:INFO:Copying training dataset
2023-03-19 17:28:40,504:INFO:Defining folds
2023-03-19 17:28:40,504:INFO:Declaring metric variables
2023-03-19 17:28:40,504:INFO:Importing untrained model
2023-03-19 17:28:40,515:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:28:40,520:INFO:Starting cross validation
2023-03-19 17:28:40,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:41,125:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,132:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,132:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,142:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,150:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,166:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,181:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,210:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,779:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:41,795:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:28:42,225:INFO:Calculating mean and std
2023-03-19 17:28:42,228:INFO:Creating metrics dataframe
2023-03-19 17:28:42,378:INFO:Uploading results into container
2023-03-19 17:28:42,378:INFO:Uploading model into container now
2023-03-19 17:28:42,378:INFO:_master_model_container: 5
2023-03-19 17:28:42,378:INFO:_display_container: 2
2023-03-19 17:28:42,378:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:28:42,378:INFO:create_model() successfully completed......................................
2023-03-19 17:28:42,466:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:42,466:INFO:Creating metrics dataframe
2023-03-19 17:28:42,474:INFO:Initializing Ridge Classifier
2023-03-19 17:28:42,474:INFO:Total runtime is 0.3378951907157898 minutes
2023-03-19 17:28:42,482:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:42,482:INFO:Initializing create_model()
2023-03-19 17:28:42,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:42,482:INFO:Checking exceptions
2023-03-19 17:28:42,482:INFO:Importing libraries
2023-03-19 17:28:42,482:INFO:Copying training dataset
2023-03-19 17:28:42,490:INFO:Defining folds
2023-03-19 17:28:42,490:INFO:Declaring metric variables
2023-03-19 17:28:42,498:INFO:Importing untrained model
2023-03-19 17:28:42,498:INFO:Ridge Classifier Imported successfully
2023-03-19 17:28:42,506:INFO:Starting cross validation
2023-03-19 17:28:42,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:43,168:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,201:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,233:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,257:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,282:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,350:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,355:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,379:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:43,944:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:44,056:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:28:44,297:INFO:Calculating mean and std
2023-03-19 17:28:44,298:INFO:Creating metrics dataframe
2023-03-19 17:28:44,429:INFO:Uploading results into container
2023-03-19 17:28:44,429:INFO:Uploading model into container now
2023-03-19 17:28:44,429:INFO:_master_model_container: 6
2023-03-19 17:28:44,429:INFO:_display_container: 2
2023-03-19 17:28:44,429:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-03-19 17:28:44,429:INFO:create_model() successfully completed......................................
2023-03-19 17:28:44,517:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:44,517:INFO:Creating metrics dataframe
2023-03-19 17:28:44,525:INFO:Initializing Random Forest Classifier
2023-03-19 17:28:44,525:INFO:Total runtime is 0.37208352883656814 minutes
2023-03-19 17:28:44,533:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:44,533:INFO:Initializing create_model()
2023-03-19 17:28:44,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:44,533:INFO:Checking exceptions
2023-03-19 17:28:44,533:INFO:Importing libraries
2023-03-19 17:28:44,533:INFO:Copying training dataset
2023-03-19 17:28:44,541:INFO:Defining folds
2023-03-19 17:28:44,541:INFO:Declaring metric variables
2023-03-19 17:28:44,541:INFO:Importing untrained model
2023-03-19 17:28:44,553:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:28:44,564:INFO:Starting cross validation
2023-03-19 17:28:44,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:46,941:INFO:Calculating mean and std
2023-03-19 17:28:46,941:INFO:Creating metrics dataframe
2023-03-19 17:28:47,071:INFO:Uploading results into container
2023-03-19 17:28:47,071:INFO:Uploading model into container now
2023-03-19 17:28:47,071:INFO:_master_model_container: 7
2023-03-19 17:28:47,071:INFO:_display_container: 2
2023-03-19 17:28:47,079:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-03-19 17:28:47,079:INFO:create_model() successfully completed......................................
2023-03-19 17:28:47,160:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:47,160:INFO:Creating metrics dataframe
2023-03-19 17:28:47,175:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:28:47,175:INFO:Total runtime is 0.41624835729598997 minutes
2023-03-19 17:28:47,183:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:47,183:INFO:Initializing create_model()
2023-03-19 17:28:47,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:47,183:INFO:Checking exceptions
2023-03-19 17:28:47,183:INFO:Importing libraries
2023-03-19 17:28:47,183:INFO:Copying training dataset
2023-03-19 17:28:47,200:INFO:Defining folds
2023-03-19 17:28:47,203:INFO:Declaring metric variables
2023-03-19 17:28:47,208:INFO:Importing untrained model
2023-03-19 17:28:47,214:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:28:47,224:INFO:Starting cross validation
2023-03-19 17:28:47,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:49,021:INFO:Calculating mean and std
2023-03-19 17:28:49,023:INFO:Creating metrics dataframe
2023-03-19 17:28:49,150:INFO:Uploading results into container
2023-03-19 17:28:49,156:INFO:Uploading model into container now
2023-03-19 17:28:49,157:INFO:_master_model_container: 8
2023-03-19 17:28:49,157:INFO:_display_container: 2
2023-03-19 17:28:49,157:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:28:49,157:INFO:create_model() successfully completed......................................
2023-03-19 17:28:49,231:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:49,231:INFO:Creating metrics dataframe
2023-03-19 17:28:49,247:INFO:Initializing Ada Boost Classifier
2023-03-19 17:28:49,247:INFO:Total runtime is 0.45078205267588295 minutes
2023-03-19 17:28:49,247:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:49,252:INFO:Initializing create_model()
2023-03-19 17:28:49,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:49,252:INFO:Checking exceptions
2023-03-19 17:28:49,253:INFO:Importing libraries
2023-03-19 17:28:49,253:INFO:Copying training dataset
2023-03-19 17:28:49,264:INFO:Defining folds
2023-03-19 17:28:49,264:INFO:Declaring metric variables
2023-03-19 17:28:49,264:INFO:Importing untrained model
2023-03-19 17:28:49,272:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:28:49,280:INFO:Starting cross validation
2023-03-19 17:28:49,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:51,266:INFO:Calculating mean and std
2023-03-19 17:28:51,266:INFO:Creating metrics dataframe
2023-03-19 17:28:51,395:INFO:Uploading results into container
2023-03-19 17:28:51,395:INFO:Uploading model into container now
2023-03-19 17:28:51,395:INFO:_master_model_container: 9
2023-03-19 17:28:51,395:INFO:_display_container: 2
2023-03-19 17:28:51,395:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-03-19 17:28:51,395:INFO:create_model() successfully completed......................................
2023-03-19 17:28:51,467:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:51,475:INFO:Creating metrics dataframe
2023-03-19 17:28:51,491:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:28:51,491:INFO:Total runtime is 0.48817706902821856 minutes
2023-03-19 17:28:51,502:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:51,502:INFO:Initializing create_model()
2023-03-19 17:28:51,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:51,502:INFO:Checking exceptions
2023-03-19 17:28:51,502:INFO:Importing libraries
2023-03-19 17:28:51,502:INFO:Copying training dataset
2023-03-19 17:28:51,515:INFO:Defining folds
2023-03-19 17:28:51,515:INFO:Declaring metric variables
2023-03-19 17:28:51,523:INFO:Importing untrained model
2023-03-19 17:28:51,526:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:28:51,536:INFO:Starting cross validation
2023-03-19 17:28:51,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:53,933:INFO:Calculating mean and std
2023-03-19 17:28:53,933:INFO:Creating metrics dataframe
2023-03-19 17:28:54,061:INFO:Uploading results into container
2023-03-19 17:28:54,069:INFO:Uploading model into container now
2023-03-19 17:28:54,069:INFO:_master_model_container: 10
2023-03-19 17:28:54,069:INFO:_display_container: 2
2023-03-19 17:28:54,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:28:54,069:INFO:create_model() successfully completed......................................
2023-03-19 17:28:54,142:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:54,142:INFO:Creating metrics dataframe
2023-03-19 17:28:54,159:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:28:54,159:INFO:Total runtime is 0.5326339960098266 minutes
2023-03-19 17:28:54,167:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:54,167:INFO:Initializing create_model()
2023-03-19 17:28:54,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:54,167:INFO:Checking exceptions
2023-03-19 17:28:54,167:INFO:Importing libraries
2023-03-19 17:28:54,167:INFO:Copying training dataset
2023-03-19 17:28:54,176:INFO:Defining folds
2023-03-19 17:28:54,176:INFO:Declaring metric variables
2023-03-19 17:28:54,185:INFO:Importing untrained model
2023-03-19 17:28:54,191:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:28:54,202:INFO:Starting cross validation
2023-03-19 17:28:54,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:56,047:INFO:Calculating mean and std
2023-03-19 17:28:56,047:INFO:Creating metrics dataframe
2023-03-19 17:28:56,184:INFO:Uploading results into container
2023-03-19 17:28:56,184:INFO:Uploading model into container now
2023-03-19 17:28:56,184:INFO:_master_model_container: 11
2023-03-19 17:28:56,184:INFO:_display_container: 2
2023-03-19 17:28:56,184:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:28:56,184:INFO:create_model() successfully completed......................................
2023-03-19 17:28:56,265:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:56,265:INFO:Creating metrics dataframe
2023-03-19 17:28:56,273:INFO:Initializing Extra Trees Classifier
2023-03-19 17:28:56,273:INFO:Total runtime is 0.5678729176521301 minutes
2023-03-19 17:28:56,273:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:56,281:INFO:Initializing create_model()
2023-03-19 17:28:56,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:56,281:INFO:Checking exceptions
2023-03-19 17:28:56,281:INFO:Importing libraries
2023-03-19 17:28:56,281:INFO:Copying training dataset
2023-03-19 17:28:56,289:INFO:Defining folds
2023-03-19 17:28:56,289:INFO:Declaring metric variables
2023-03-19 17:28:56,289:INFO:Importing untrained model
2023-03-19 17:28:56,289:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:28:56,297:INFO:Starting cross validation
2023-03-19 17:28:56,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:28:59,065:INFO:Calculating mean and std
2023-03-19 17:28:59,065:INFO:Creating metrics dataframe
2023-03-19 17:28:59,202:INFO:Uploading results into container
2023-03-19 17:28:59,202:INFO:Uploading model into container now
2023-03-19 17:28:59,202:INFO:_master_model_container: 12
2023-03-19 17:28:59,202:INFO:_display_container: 2
2023-03-19 17:28:59,202:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-03-19 17:28:59,202:INFO:create_model() successfully completed......................................
2023-03-19 17:28:59,274:INFO:SubProcess create_model() end ==================================
2023-03-19 17:28:59,274:INFO:Creating metrics dataframe
2023-03-19 17:28:59,290:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:28:59,290:INFO:Total runtime is 0.6181644678115844 minutes
2023-03-19 17:28:59,296:INFO:SubProcess create_model() called ==================================
2023-03-19 17:28:59,296:INFO:Initializing create_model()
2023-03-19 17:28:59,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:28:59,296:INFO:Checking exceptions
2023-03-19 17:28:59,296:INFO:Importing libraries
2023-03-19 17:28:59,296:INFO:Copying training dataset
2023-03-19 17:28:59,306:INFO:Defining folds
2023-03-19 17:28:59,306:INFO:Declaring metric variables
2023-03-19 17:28:59,313:INFO:Importing untrained model
2023-03-19 17:28:59,315:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:28:59,326:INFO:Starting cross validation
2023-03-19 17:28:59,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:29:01,239:INFO:Calculating mean and std
2023-03-19 17:29:01,239:INFO:Creating metrics dataframe
2023-03-19 17:29:01,384:INFO:Uploading results into container
2023-03-19 17:29:01,384:INFO:Uploading model into container now
2023-03-19 17:29:01,384:INFO:_master_model_container: 13
2023-03-19 17:29:01,384:INFO:_display_container: 2
2023-03-19 17:29:01,384:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:29:01,384:INFO:create_model() successfully completed......................................
2023-03-19 17:29:01,472:INFO:SubProcess create_model() end ==================================
2023-03-19 17:29:01,472:INFO:Creating metrics dataframe
2023-03-19 17:29:01,512:INFO:Initializing Dummy Classifier
2023-03-19 17:29:01,512:INFO:Total runtime is 0.6551940957705179 minutes
2023-03-19 17:29:01,512:INFO:SubProcess create_model() called ==================================
2023-03-19 17:29:01,512:INFO:Initializing create_model()
2023-03-19 17:29:01,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A8072221A0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:29:01,512:INFO:Checking exceptions
2023-03-19 17:29:01,512:INFO:Importing libraries
2023-03-19 17:29:01,512:INFO:Copying training dataset
2023-03-19 17:29:01,528:INFO:Defining folds
2023-03-19 17:29:01,528:INFO:Declaring metric variables
2023-03-19 17:29:01,538:INFO:Importing untrained model
2023-03-19 17:29:01,545:INFO:Dummy Classifier Imported successfully
2023-03-19 17:29:01,553:INFO:Starting cross validation
2023-03-19 17:29:01,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:29:02,166:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,175:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,182:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,303:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,319:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,344:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,368:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,385:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,863:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:02,887:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:29:03,397:INFO:Calculating mean and std
2023-03-19 17:29:03,397:INFO:Creating metrics dataframe
2023-03-19 17:29:03,531:INFO:Uploading results into container
2023-03-19 17:29:03,531:INFO:Uploading model into container now
2023-03-19 17:29:03,531:INFO:_master_model_container: 14
2023-03-19 17:29:03,531:INFO:_display_container: 2
2023-03-19 17:29:03,531:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-03-19 17:29:03,531:INFO:create_model() successfully completed......................................
2023-03-19 17:29:03,607:INFO:SubProcess create_model() end ==================================
2023-03-19 17:29:03,607:INFO:Creating metrics dataframe
2023-03-19 17:29:03,631:INFO:Initializing create_model()
2023-03-19 17:29:03,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A807221F90>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:29:03,631:INFO:Checking exceptions
2023-03-19 17:29:03,631:INFO:Importing libraries
2023-03-19 17:29:03,631:INFO:Copying training dataset
2023-03-19 17:29:03,639:INFO:Defining folds
2023-03-19 17:29:03,639:INFO:Declaring metric variables
2023-03-19 17:29:03,639:INFO:Importing untrained model
2023-03-19 17:29:03,639:INFO:Declaring custom model
2023-03-19 17:29:03,639:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:29:03,647:INFO:Cross validation set to False
2023-03-19 17:29:03,647:INFO:Fitting Model
2023-03-19 17:29:04,026:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:29:04,026:INFO:create_model() successfully completed......................................
2023-03-19 17:29:04,136:INFO:_master_model_container: 14
2023-03-19 17:29:04,136:INFO:_display_container: 2
2023-03-19 17:29:04,136:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:29:04,136:INFO:compare_models() successfully completed......................................
2023-03-19 17:36:53,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:36:53,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:36:53,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:36:53,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:36:54,402:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-19 17:37:08,254:INFO:PyCaret ClassificationExperiment
2023-03-19 17:37:08,254:INFO:Logging name: adult-dataset
2023-03-19 17:37:08,254:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:37:08,254:INFO:version 3.0.0
2023-03-19 17:37:08,254:INFO:Initializing setup()
2023-03-19 17:37:08,254:INFO:self.USI: 61eb
2023-03-19 17:37:08,254:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_train', 'y', 'log_plots_param', 'n_jobs_param', 'X_train', 'fix_imbalance', '_ml_usecase', 'X_test', 'exp_name_log', '_available_plots', 'USI', 'pipeline', 'y_test', 'data', 'idx', 'gpu_param', 'is_multiclass', 'seed', 'target_param', 'memory', 'html_param', 'exp_id', 'X', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'logging_param'}
2023-03-19 17:37:08,254:INFO:Checking environment
2023-03-19 17:37:08,254:INFO:python_version: 3.10.0
2023-03-19 17:37:08,254:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:37:08,254:INFO:machine: AMD64
2023-03-19 17:37:08,254:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:37:08,262:INFO:Memory: svmem(total=16969424896, available=5819310080, percent=65.7, used=11150114816, free=5819310080)
2023-03-19 17:37:08,262:INFO:Physical Core: 4
2023-03-19 17:37:08,262:INFO:Logical Core: 8
2023-03-19 17:37:08,262:INFO:Checking libraries
2023-03-19 17:37:08,262:INFO:System:
2023-03-19 17:37:08,262:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:37:08,262:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:37:08,262:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:37:08,262:INFO:PyCaret required dependencies:
2023-03-19 17:37:08,262:INFO:                 pip: 23.0.1
2023-03-19 17:37:08,262:INFO:          setuptools: 65.6.3
2023-03-19 17:37:08,262:INFO:             pycaret: 3.0.0
2023-03-19 17:37:08,262:INFO:             IPython: 8.11.0
2023-03-19 17:37:08,262:INFO:          ipywidgets: 8.0.4
2023-03-19 17:37:08,262:INFO:                tqdm: 4.65.0
2023-03-19 17:37:08,262:INFO:               numpy: 1.23.5
2023-03-19 17:37:08,262:INFO:              pandas: 1.5.3
2023-03-19 17:37:08,262:INFO:              jinja2: 3.1.2
2023-03-19 17:37:08,262:INFO:               scipy: 1.10.1
2023-03-19 17:37:08,262:INFO:              joblib: 1.2.0
2023-03-19 17:37:08,262:INFO:             sklearn: 1.2.2
2023-03-19 17:37:08,262:INFO:                pyod: 1.0.8
2023-03-19 17:37:08,262:INFO:            imblearn: 0.10.1
2023-03-19 17:37:08,262:INFO:   category_encoders: 2.6.0
2023-03-19 17:37:08,262:INFO:            lightgbm: 3.3.5
2023-03-19 17:37:08,262:INFO:               numba: 0.56.4
2023-03-19 17:37:08,262:INFO:            requests: 2.28.2
2023-03-19 17:37:08,262:INFO:          matplotlib: 3.7.1
2023-03-19 17:37:08,262:INFO:          scikitplot: 0.3.7
2023-03-19 17:37:08,262:INFO:         yellowbrick: 1.5
2023-03-19 17:37:08,262:INFO:              plotly: 5.13.1
2023-03-19 17:37:08,262:INFO:             kaleido: 0.2.1
2023-03-19 17:37:08,262:INFO:         statsmodels: 0.13.5
2023-03-19 17:37:08,262:INFO:              sktime: 0.16.1
2023-03-19 17:37:08,262:INFO:               tbats: 1.1.2
2023-03-19 17:37:08,262:INFO:            pmdarima: 2.0.3
2023-03-19 17:37:08,262:INFO:              psutil: 5.9.4
2023-03-19 17:37:08,262:INFO:PyCaret optional dependencies:
2023-03-19 17:37:08,278:INFO:                shap: 0.41.0
2023-03-19 17:37:08,278:INFO:           interpret: Not installed
2023-03-19 17:37:08,278:INFO:                umap: Not installed
2023-03-19 17:37:08,278:INFO:    pandas_profiling: Not installed
2023-03-19 17:37:08,278:INFO:  explainerdashboard: Not installed
2023-03-19 17:37:08,278:INFO:             autoviz: Not installed
2023-03-19 17:37:08,278:INFO:           fairlearn: Not installed
2023-03-19 17:37:08,278:INFO:             xgboost: Not installed
2023-03-19 17:37:08,278:INFO:            catboost: Not installed
2023-03-19 17:37:08,278:INFO:              kmodes: Not installed
2023-03-19 17:37:08,278:INFO:             mlxtend: Not installed
2023-03-19 17:37:08,278:INFO:       statsforecast: Not installed
2023-03-19 17:37:08,278:INFO:        tune_sklearn: Not installed
2023-03-19 17:37:08,278:INFO:                 ray: Not installed
2023-03-19 17:37:08,278:INFO:            hyperopt: Not installed
2023-03-19 17:37:08,278:INFO:              optuna: Not installed
2023-03-19 17:37:08,278:INFO:               skopt: Not installed
2023-03-19 17:37:08,278:INFO:              mlflow: 2.2.2
2023-03-19 17:37:08,278:INFO:              gradio: Not installed
2023-03-19 17:37:08,278:INFO:             fastapi: Not installed
2023-03-19 17:37:08,278:INFO:             uvicorn: Not installed
2023-03-19 17:37:08,278:INFO:              m2cgen: Not installed
2023-03-19 17:37:08,278:INFO:           evidently: Not installed
2023-03-19 17:37:08,278:INFO:               fugue: Not installed
2023-03-19 17:37:08,278:INFO:           streamlit: Not installed
2023-03-19 17:37:08,278:INFO:             prophet: Not installed
2023-03-19 17:37:08,278:INFO:None
2023-03-19 17:37:08,278:INFO:Set up data.
2023-03-19 17:37:08,318:INFO:Set up train/test split.
2023-03-19 17:37:08,334:INFO:Set up index.
2023-03-19 17:37:08,334:INFO:Set up folding strategy.
2023-03-19 17:37:08,334:INFO:Assigning column types.
2023-03-19 17:37:08,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:37:08,406:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:37:08,415:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:37:08,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:37:08,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:37:08,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,591:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:37:08,648:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:37:08,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,760:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:37:08,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:37:08,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:08,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,016:INFO:Preparing preprocessing pipeline...
2023-03-19 17:37:09,016:INFO:Set up simple imputation.
2023-03-19 17:37:09,025:INFO:Set up encoding of ordinal features.
2023-03-19 17:37:09,025:INFO:Set up encoding of categorical features.
2023-03-19 17:37:09,025:INFO:Set up column name cleaning.
2023-03-19 17:37:09,404:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:37:09,436:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:37:09,436:INFO:Creating final display dataframe.
2023-03-19 17:37:09,606:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name    adult-dataset
23                          USI             61eb
2023-03-19 17:37:09,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:37:09,822:INFO:Logging experiment in loggers
2023-03-19 17:37:10,166:INFO:SubProcess save_model() called ==================================
2023-03-19 17:37:10,215:INFO:Initializing save_model()
2023-03-19 17:37:10,223:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmper0b5rjx\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:37:10,223:INFO:Adding model into prep_pipe
2023-03-19 17:37:10,223:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:37:10,239:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmper0b5rjx\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:37:10,265:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:37:10,265:INFO:save_model() successfully completed......................................
2023-03-19 17:37:10,483:INFO:SubProcess save_model() end ==================================
2023-03-19 17:37:10,581:INFO:setup() successfully completed in 1.7s...............
2023-03-19 17:37:14,777:INFO:Initializing compare_models()
2023-03-19 17:37:14,777:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:37:14,777:INFO:Checking exceptions
2023-03-19 17:37:14,785:INFO:Preparing display monitor
2023-03-19 17:37:14,825:INFO:Initializing Logistic Regression
2023-03-19 17:37:14,825:INFO:Total runtime is 0.0 minutes
2023-03-19 17:37:14,833:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:14,833:INFO:Initializing create_model()
2023-03-19 17:37:14,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:14,833:INFO:Checking exceptions
2023-03-19 17:37:14,833:INFO:Importing libraries
2023-03-19 17:37:14,833:INFO:Copying training dataset
2023-03-19 17:37:14,849:INFO:Defining folds
2023-03-19 17:37:14,849:INFO:Declaring metric variables
2023-03-19 17:37:14,857:INFO:Importing untrained model
2023-03-19 17:37:14,865:INFO:Logistic Regression Imported successfully
2023-03-19 17:37:14,873:INFO:Starting cross validation
2023-03-19 17:37:14,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:22,919:INFO:Calculating mean and std
2023-03-19 17:37:22,919:INFO:Creating metrics dataframe
2023-03-19 17:37:23,080:INFO:Uploading results into container
2023-03-19 17:37:23,080:INFO:Uploading model into container now
2023-03-19 17:37:23,080:INFO:_master_model_container: 1
2023-03-19 17:37:23,080:INFO:_display_container: 2
2023-03-19 17:37:23,080:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:37:23,080:INFO:create_model() successfully completed......................................
2023-03-19 17:37:23,168:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:23,168:INFO:Creating metrics dataframe
2023-03-19 17:37:23,176:INFO:Initializing K Neighbors Classifier
2023-03-19 17:37:23,176:INFO:Total runtime is 0.13918588956197103 minutes
2023-03-19 17:37:23,176:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:23,176:INFO:Initializing create_model()
2023-03-19 17:37:23,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:23,176:INFO:Checking exceptions
2023-03-19 17:37:23,176:INFO:Importing libraries
2023-03-19 17:37:23,176:INFO:Copying training dataset
2023-03-19 17:37:23,192:INFO:Defining folds
2023-03-19 17:37:23,192:INFO:Declaring metric variables
2023-03-19 17:37:23,200:INFO:Importing untrained model
2023-03-19 17:37:23,200:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:37:23,208:INFO:Starting cross validation
2023-03-19 17:37:23,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:26,685:INFO:Calculating mean and std
2023-03-19 17:37:26,685:INFO:Creating metrics dataframe
2023-03-19 17:37:26,870:INFO:Uploading results into container
2023-03-19 17:37:26,870:INFO:Uploading model into container now
2023-03-19 17:37:26,870:INFO:_master_model_container: 2
2023-03-19 17:37:26,870:INFO:_display_container: 2
2023-03-19 17:37:26,870:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:37:26,870:INFO:create_model() successfully completed......................................
2023-03-19 17:37:26,977:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:26,977:INFO:Creating metrics dataframe
2023-03-19 17:37:26,991:INFO:Initializing Naive Bayes
2023-03-19 17:37:26,991:INFO:Total runtime is 0.20275688966115316 minutes
2023-03-19 17:37:26,999:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:26,999:INFO:Initializing create_model()
2023-03-19 17:37:26,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:26,999:INFO:Checking exceptions
2023-03-19 17:37:26,999:INFO:Importing libraries
2023-03-19 17:37:26,999:INFO:Copying training dataset
2023-03-19 17:37:27,016:INFO:Defining folds
2023-03-19 17:37:27,016:INFO:Declaring metric variables
2023-03-19 17:37:27,023:INFO:Importing untrained model
2023-03-19 17:37:27,023:INFO:Naive Bayes Imported successfully
2023-03-19 17:37:27,039:INFO:Starting cross validation
2023-03-19 17:37:27,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:29,057:INFO:Calculating mean and std
2023-03-19 17:37:29,065:INFO:Creating metrics dataframe
2023-03-19 17:37:29,217:INFO:Uploading results into container
2023-03-19 17:37:29,217:INFO:Uploading model into container now
2023-03-19 17:37:29,217:INFO:_master_model_container: 3
2023-03-19 17:37:29,217:INFO:_display_container: 2
2023-03-19 17:37:29,217:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:37:29,217:INFO:create_model() successfully completed......................................
2023-03-19 17:37:29,308:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:29,308:INFO:Creating metrics dataframe
2023-03-19 17:37:29,322:INFO:Initializing Decision Tree Classifier
2023-03-19 17:37:29,322:INFO:Total runtime is 0.24161152442296346 minutes
2023-03-19 17:37:29,330:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:29,330:INFO:Initializing create_model()
2023-03-19 17:37:29,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:29,330:INFO:Checking exceptions
2023-03-19 17:37:29,330:INFO:Importing libraries
2023-03-19 17:37:29,330:INFO:Copying training dataset
2023-03-19 17:37:29,338:INFO:Defining folds
2023-03-19 17:37:29,338:INFO:Declaring metric variables
2023-03-19 17:37:29,346:INFO:Importing untrained model
2023-03-19 17:37:29,354:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:37:29,370:INFO:Starting cross validation
2023-03-19 17:37:29,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:31,308:INFO:Calculating mean and std
2023-03-19 17:37:31,310:INFO:Creating metrics dataframe
2023-03-19 17:37:31,461:INFO:Uploading results into container
2023-03-19 17:37:31,461:INFO:Uploading model into container now
2023-03-19 17:37:31,461:INFO:_master_model_container: 4
2023-03-19 17:37:31,461:INFO:_display_container: 2
2023-03-19 17:37:31,461:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-03-19 17:37:31,461:INFO:create_model() successfully completed......................................
2023-03-19 17:37:31,544:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:31,544:INFO:Creating metrics dataframe
2023-03-19 17:37:31,550:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:37:31,558:INFO:Total runtime is 0.2788794994354248 minutes
2023-03-19 17:37:31,561:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:31,561:INFO:Initializing create_model()
2023-03-19 17:37:31,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:31,561:INFO:Checking exceptions
2023-03-19 17:37:31,561:INFO:Importing libraries
2023-03-19 17:37:31,561:INFO:Copying training dataset
2023-03-19 17:37:31,566:INFO:Defining folds
2023-03-19 17:37:31,566:INFO:Declaring metric variables
2023-03-19 17:37:31,574:INFO:Importing untrained model
2023-03-19 17:37:31,583:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:37:31,591:INFO:Starting cross validation
2023-03-19 17:37:31,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:32,125:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,148:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,165:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,197:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,216:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,232:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,246:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,254:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,817:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:32,826:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:37:33,400:INFO:Calculating mean and std
2023-03-19 17:37:33,400:INFO:Creating metrics dataframe
2023-03-19 17:37:33,552:INFO:Uploading results into container
2023-03-19 17:37:33,552:INFO:Uploading model into container now
2023-03-19 17:37:33,552:INFO:_master_model_container: 5
2023-03-19 17:37:33,552:INFO:_display_container: 2
2023-03-19 17:37:33,552:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:37:33,552:INFO:create_model() successfully completed......................................
2023-03-19 17:37:33,641:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:33,641:INFO:Creating metrics dataframe
2023-03-19 17:37:33,649:INFO:Initializing Ridge Classifier
2023-03-19 17:37:33,649:INFO:Total runtime is 0.31372687419255574 minutes
2023-03-19 17:37:33,659:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:33,659:INFO:Initializing create_model()
2023-03-19 17:37:33,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:33,659:INFO:Checking exceptions
2023-03-19 17:37:33,659:INFO:Importing libraries
2023-03-19 17:37:33,659:INFO:Copying training dataset
2023-03-19 17:37:33,665:INFO:Defining folds
2023-03-19 17:37:33,665:INFO:Declaring metric variables
2023-03-19 17:37:33,675:INFO:Importing untrained model
2023-03-19 17:37:33,675:INFO:Ridge Classifier Imported successfully
2023-03-19 17:37:33,690:INFO:Starting cross validation
2023-03-19 17:37:33,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:34,324:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,340:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,348:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,384:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,391:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,391:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,412:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:34,414:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:35,065:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:35,315:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:37:35,695:INFO:Calculating mean and std
2023-03-19 17:37:35,703:INFO:Creating metrics dataframe
2023-03-19 17:37:35,871:INFO:Uploading results into container
2023-03-19 17:37:35,874:INFO:Uploading model into container now
2023-03-19 17:37:35,874:INFO:_master_model_container: 6
2023-03-19 17:37:35,874:INFO:_display_container: 2
2023-03-19 17:37:35,875:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-03-19 17:37:35,875:INFO:create_model() successfully completed......................................
2023-03-19 17:37:35,961:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:35,961:INFO:Creating metrics dataframe
2023-03-19 17:37:35,977:INFO:Initializing Random Forest Classifier
2023-03-19 17:37:35,977:INFO:Total runtime is 0.35253034432729086 minutes
2023-03-19 17:37:35,977:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:35,977:INFO:Initializing create_model()
2023-03-19 17:37:35,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:35,977:INFO:Checking exceptions
2023-03-19 17:37:35,977:INFO:Importing libraries
2023-03-19 17:37:35,977:INFO:Copying training dataset
2023-03-19 17:37:35,993:INFO:Defining folds
2023-03-19 17:37:35,993:INFO:Declaring metric variables
2023-03-19 17:37:36,001:INFO:Importing untrained model
2023-03-19 17:37:36,009:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:37:36,017:INFO:Starting cross validation
2023-03-19 17:37:36,025:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:38,684:INFO:Calculating mean and std
2023-03-19 17:37:38,684:INFO:Creating metrics dataframe
2023-03-19 17:37:38,853:INFO:Uploading results into container
2023-03-19 17:37:38,853:INFO:Uploading model into container now
2023-03-19 17:37:38,861:INFO:_master_model_container: 7
2023-03-19 17:37:38,861:INFO:_display_container: 2
2023-03-19 17:37:38,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-03-19 17:37:38,861:INFO:create_model() successfully completed......................................
2023-03-19 17:37:38,966:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:38,966:INFO:Creating metrics dataframe
2023-03-19 17:37:38,991:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:37:38,993:INFO:Total runtime is 0.4027708411216736 minutes
2023-03-19 17:37:38,993:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:38,993:INFO:Initializing create_model()
2023-03-19 17:37:38,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:38,993:INFO:Checking exceptions
2023-03-19 17:37:38,998:INFO:Importing libraries
2023-03-19 17:37:38,998:INFO:Copying training dataset
2023-03-19 17:37:39,010:INFO:Defining folds
2023-03-19 17:37:39,010:INFO:Declaring metric variables
2023-03-19 17:37:39,015:INFO:Importing untrained model
2023-03-19 17:37:39,024:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:37:39,036:INFO:Starting cross validation
2023-03-19 17:37:39,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:41,162:INFO:Calculating mean and std
2023-03-19 17:37:41,171:INFO:Creating metrics dataframe
2023-03-19 17:37:41,323:INFO:Uploading results into container
2023-03-19 17:37:41,323:INFO:Uploading model into container now
2023-03-19 17:37:41,323:INFO:_master_model_container: 8
2023-03-19 17:37:41,323:INFO:_display_container: 2
2023-03-19 17:37:41,323:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:37:41,323:INFO:create_model() successfully completed......................................
2023-03-19 17:37:41,420:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:41,421:INFO:Creating metrics dataframe
2023-03-19 17:37:41,436:INFO:Initializing Ada Boost Classifier
2023-03-19 17:37:41,436:INFO:Total runtime is 0.44351577361424765 minutes
2023-03-19 17:37:41,444:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:41,444:INFO:Initializing create_model()
2023-03-19 17:37:41,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:41,444:INFO:Checking exceptions
2023-03-19 17:37:41,444:INFO:Importing libraries
2023-03-19 17:37:41,444:INFO:Copying training dataset
2023-03-19 17:37:41,452:INFO:Defining folds
2023-03-19 17:37:41,452:INFO:Declaring metric variables
2023-03-19 17:37:41,460:INFO:Importing untrained model
2023-03-19 17:37:41,469:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:37:41,486:INFO:Starting cross validation
2023-03-19 17:37:41,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:43,639:INFO:Calculating mean and std
2023-03-19 17:37:43,639:INFO:Creating metrics dataframe
2023-03-19 17:37:43,808:INFO:Uploading results into container
2023-03-19 17:37:43,808:INFO:Uploading model into container now
2023-03-19 17:37:43,808:INFO:_master_model_container: 9
2023-03-19 17:37:43,808:INFO:_display_container: 2
2023-03-19 17:37:43,808:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-03-19 17:37:43,808:INFO:create_model() successfully completed......................................
2023-03-19 17:37:43,898:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:43,898:INFO:Creating metrics dataframe
2023-03-19 17:37:43,914:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:37:43,914:INFO:Total runtime is 0.48481194575627645 minutes
2023-03-19 17:37:43,914:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:43,914:INFO:Initializing create_model()
2023-03-19 17:37:43,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:43,914:INFO:Checking exceptions
2023-03-19 17:37:43,914:INFO:Importing libraries
2023-03-19 17:37:43,921:INFO:Copying training dataset
2023-03-19 17:37:43,932:INFO:Defining folds
2023-03-19 17:37:43,932:INFO:Declaring metric variables
2023-03-19 17:37:43,938:INFO:Importing untrained model
2023-03-19 17:37:43,946:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:37:43,962:INFO:Starting cross validation
2023-03-19 17:37:43,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:45,996:INFO:Calculating mean and std
2023-03-19 17:37:45,996:INFO:Creating metrics dataframe
2023-03-19 17:37:46,173:INFO:Uploading results into container
2023-03-19 17:37:46,178:INFO:Uploading model into container now
2023-03-19 17:37:46,178:INFO:_master_model_container: 10
2023-03-19 17:37:46,178:INFO:_display_container: 2
2023-03-19 17:37:46,181:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:37:46,181:INFO:create_model() successfully completed......................................
2023-03-19 17:37:46,297:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:46,297:INFO:Creating metrics dataframe
2023-03-19 17:37:46,314:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:37:46,314:INFO:Total runtime is 0.524813199043274 minutes
2023-03-19 17:37:46,319:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:46,327:INFO:Initializing create_model()
2023-03-19 17:37:46,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:46,328:INFO:Checking exceptions
2023-03-19 17:37:46,328:INFO:Importing libraries
2023-03-19 17:37:46,329:INFO:Copying training dataset
2023-03-19 17:37:46,351:INFO:Defining folds
2023-03-19 17:37:46,351:INFO:Declaring metric variables
2023-03-19 17:37:46,360:INFO:Importing untrained model
2023-03-19 17:37:46,368:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:37:46,376:INFO:Starting cross validation
2023-03-19 17:37:46,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:48,415:INFO:Calculating mean and std
2023-03-19 17:37:48,415:INFO:Creating metrics dataframe
2023-03-19 17:37:48,616:INFO:Uploading results into container
2023-03-19 17:37:48,624:INFO:Uploading model into container now
2023-03-19 17:37:48,624:INFO:_master_model_container: 11
2023-03-19 17:37:48,624:INFO:_display_container: 2
2023-03-19 17:37:48,624:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:37:48,624:INFO:create_model() successfully completed......................................
2023-03-19 17:37:48,729:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:48,729:INFO:Creating metrics dataframe
2023-03-19 17:37:48,745:INFO:Initializing Extra Trees Classifier
2023-03-19 17:37:48,745:INFO:Total runtime is 0.5653367280960083 minutes
2023-03-19 17:37:48,745:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:48,745:INFO:Initializing create_model()
2023-03-19 17:37:48,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:48,745:INFO:Checking exceptions
2023-03-19 17:37:48,745:INFO:Importing libraries
2023-03-19 17:37:48,745:INFO:Copying training dataset
2023-03-19 17:37:48,770:INFO:Defining folds
2023-03-19 17:37:48,771:INFO:Declaring metric variables
2023-03-19 17:37:48,777:INFO:Importing untrained model
2023-03-19 17:37:48,785:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:37:48,802:INFO:Starting cross validation
2023-03-19 17:37:48,802:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:52,326:INFO:Calculating mean and std
2023-03-19 17:37:52,326:INFO:Creating metrics dataframe
2023-03-19 17:37:52,787:INFO:Uploading results into container
2023-03-19 17:37:52,787:INFO:Uploading model into container now
2023-03-19 17:37:52,787:INFO:_master_model_container: 12
2023-03-19 17:37:52,787:INFO:_display_container: 2
2023-03-19 17:37:52,787:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-03-19 17:37:52,787:INFO:create_model() successfully completed......................................
2023-03-19 17:37:52,977:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:52,977:INFO:Creating metrics dataframe
2023-03-19 17:37:53,019:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:37:53,019:INFO:Total runtime is 0.6365705927213033 minutes
2023-03-19 17:37:53,024:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:53,024:INFO:Initializing create_model()
2023-03-19 17:37:53,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:53,024:INFO:Checking exceptions
2023-03-19 17:37:53,024:INFO:Importing libraries
2023-03-19 17:37:53,024:INFO:Copying training dataset
2023-03-19 17:37:53,055:INFO:Defining folds
2023-03-19 17:37:53,055:INFO:Declaring metric variables
2023-03-19 17:37:53,073:INFO:Importing untrained model
2023-03-19 17:37:53,087:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:37:53,119:INFO:Starting cross validation
2023-03-19 17:37:53,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:57,870:INFO:Calculating mean and std
2023-03-19 17:37:57,870:INFO:Creating metrics dataframe
2023-03-19 17:37:58,302:INFO:Uploading results into container
2023-03-19 17:37:58,306:INFO:Uploading model into container now
2023-03-19 17:37:58,306:INFO:_master_model_container: 13
2023-03-19 17:37:58,306:INFO:_display_container: 2
2023-03-19 17:37:58,306:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:37:58,306:INFO:create_model() successfully completed......................................
2023-03-19 17:37:58,468:INFO:SubProcess create_model() end ==================================
2023-03-19 17:37:58,468:INFO:Creating metrics dataframe
2023-03-19 17:37:58,507:INFO:Initializing Dummy Classifier
2023-03-19 17:37:58,507:INFO:Total runtime is 0.7280217965443929 minutes
2023-03-19 17:37:58,516:INFO:SubProcess create_model() called ==================================
2023-03-19 17:37:58,516:INFO:Initializing create_model()
2023-03-19 17:37:58,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017139D38940>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:37:58,516:INFO:Checking exceptions
2023-03-19 17:37:58,516:INFO:Importing libraries
2023-03-19 17:37:58,516:INFO:Copying training dataset
2023-03-19 17:37:58,551:INFO:Defining folds
2023-03-19 17:37:58,551:INFO:Declaring metric variables
2023-03-19 17:37:58,564:INFO:Importing untrained model
2023-03-19 17:37:58,581:INFO:Dummy Classifier Imported successfully
2023-03-19 17:37:58,606:INFO:Starting cross validation
2023-03-19 17:37:58,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:37:59,937:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:37:59,968:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:00,007:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:00,064:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:00,095:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:00,111:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:00,191:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:00,222:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:01,902:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:01,908:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:38:03,205:INFO:Calculating mean and std
2023-03-19 17:38:03,205:INFO:Creating metrics dataframe
2023-03-19 17:38:03,360:INFO:Uploading results into container
2023-03-19 17:38:03,360:INFO:Uploading model into container now
2023-03-19 17:38:03,360:INFO:_master_model_container: 14
2023-03-19 17:38:03,360:INFO:_display_container: 2
2023-03-19 17:38:03,360:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-03-19 17:38:03,360:INFO:create_model() successfully completed......................................
2023-03-19 17:38:03,456:INFO:SubProcess create_model() end ==================================
2023-03-19 17:38:03,456:INFO:Creating metrics dataframe
2023-03-19 17:38:03,497:INFO:Initializing create_model()
2023-03-19 17:38:03,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:38:03,505:INFO:Checking exceptions
2023-03-19 17:38:03,505:INFO:Importing libraries
2023-03-19 17:38:03,505:INFO:Copying training dataset
2023-03-19 17:38:03,513:INFO:Defining folds
2023-03-19 17:38:03,513:INFO:Declaring metric variables
2023-03-19 17:38:03,513:INFO:Importing untrained model
2023-03-19 17:38:03,513:INFO:Declaring custom model
2023-03-19 17:38:03,513:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:38:03,521:INFO:Cross validation set to False
2023-03-19 17:38:03,521:INFO:Fitting Model
2023-03-19 17:38:04,013:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:38:04,013:INFO:create_model() successfully completed......................................
2023-03-19 17:38:04,110:INFO:Creating Dashboard logs
2023-03-19 17:38:04,118:INFO:Model: Linear Discriminant Analysis
2023-03-19 17:38:04,192:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:38:04,328:INFO:Initializing predict_model()
2023-03-19 17:38:04,328:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715F96C640>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001715FD58280>)
2023-03-19 17:38:04,328:INFO:Checking exceptions
2023-03-19 17:38:04,328:INFO:Preloading libraries
2023-03-19 17:38:04,582:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-03-19 17:38:04,875:INFO:Creating Dashboard logs
2023-03-19 17:38:04,883:INFO:Model: Ridge Classifier
2023-03-19 17:38:04,948:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 17:38:05,377:INFO:Creating Dashboard logs
2023-03-19 17:38:05,386:INFO:Model: Extra Trees Classifier
2023-03-19 17:38:05,469:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-03-19 17:38:05,890:INFO:Creating Dashboard logs
2023-03-19 17:38:05,890:INFO:Model: Logistic Regression
2023-03-19 17:38:05,963:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 17:38:06,376:INFO:Creating Dashboard logs
2023-03-19 17:38:06,384:INFO:Model: Naive Bayes
2023-03-19 17:38:06,477:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 17:38:06,862:INFO:Creating Dashboard logs
2023-03-19 17:38:06,872:INFO:Model: Random Forest Classifier
2023-03-19 17:38:06,950:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-03-19 17:38:07,332:INFO:Creating Dashboard logs
2023-03-19 17:38:07,342:INFO:Model: K Neighbors Classifier
2023-03-19 17:38:07,408:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 17:38:07,796:INFO:Creating Dashboard logs
2023-03-19 17:38:07,804:INFO:Model: str
2023-03-19 17:38:07,879:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2023-03-19 17:38:08,269:INFO:Creating Dashboard logs
2023-03-19 17:38:08,269:INFO:Model: Decision Tree Classifier
2023-03-19 17:38:08,334:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-03-19 17:38:08,729:INFO:Creating Dashboard logs
2023-03-19 17:38:08,741:INFO:Model: Gradient Boosting Classifier
2023-03-19 17:38:08,810:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:38:09,329:INFO:Creating Dashboard logs
2023-03-19 17:38:09,337:INFO:Model: Dummy Classifier
2023-03-19 17:38:09,418:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2023-03-19 17:38:09,775:INFO:Creating Dashboard logs
2023-03-19 17:38:09,775:INFO:Model: Light Gradient Boosting Machine
2023-03-19 17:38:09,841:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 17:38:10,246:INFO:Creating Dashboard logs
2023-03-19 17:38:10,254:INFO:Model: SVM - Linear Kernel
2023-03-19 17:38:10,320:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:38:10,731:INFO:Creating Dashboard logs
2023-03-19 17:38:10,731:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 17:38:10,805:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:38:11,205:INFO:_master_model_container: 14
2023-03-19 17:38:11,205:INFO:_display_container: 2
2023-03-19 17:38:11,205:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:38:11,205:INFO:compare_models() successfully completed......................................
2023-03-19 17:39:14,532:INFO:PyCaret ClassificationExperiment
2023-03-19 17:39:14,532:INFO:Logging name: adult-dataset
2023-03-19 17:39:14,532:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:39:14,532:INFO:version 3.0.0
2023-03-19 17:39:14,532:INFO:Initializing setup()
2023-03-19 17:39:14,532:INFO:self.USI: 4478
2023-03-19 17:39:14,532:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_train', 'y', 'log_plots_param', 'n_jobs_param', 'X_train', 'fix_imbalance', '_ml_usecase', 'X_test', 'exp_name_log', '_available_plots', 'USI', 'pipeline', 'y_test', 'data', 'idx', 'gpu_param', 'is_multiclass', 'seed', 'target_param', 'memory', 'html_param', 'exp_id', 'X', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'logging_param'}
2023-03-19 17:39:14,532:INFO:Checking environment
2023-03-19 17:39:14,532:INFO:python_version: 3.10.0
2023-03-19 17:39:14,532:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:39:14,532:INFO:machine: AMD64
2023-03-19 17:39:14,532:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:39:14,540:INFO:Memory: svmem(total=16969424896, available=4725755904, percent=72.2, used=12243668992, free=4725755904)
2023-03-19 17:39:14,540:INFO:Physical Core: 4
2023-03-19 17:39:14,540:INFO:Logical Core: 8
2023-03-19 17:39:14,540:INFO:Checking libraries
2023-03-19 17:39:14,540:INFO:System:
2023-03-19 17:39:14,540:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:39:14,540:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:39:14,540:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:39:14,540:INFO:PyCaret required dependencies:
2023-03-19 17:39:14,540:INFO:                 pip: 23.0.1
2023-03-19 17:39:14,540:INFO:          setuptools: 65.6.3
2023-03-19 17:39:14,540:INFO:             pycaret: 3.0.0
2023-03-19 17:39:14,540:INFO:             IPython: 8.11.0
2023-03-19 17:39:14,540:INFO:          ipywidgets: 8.0.4
2023-03-19 17:39:14,540:INFO:                tqdm: 4.65.0
2023-03-19 17:39:14,540:INFO:               numpy: 1.23.5
2023-03-19 17:39:14,540:INFO:              pandas: 1.5.3
2023-03-19 17:39:14,540:INFO:              jinja2: 3.1.2
2023-03-19 17:39:14,540:INFO:               scipy: 1.10.1
2023-03-19 17:39:14,540:INFO:              joblib: 1.2.0
2023-03-19 17:39:14,540:INFO:             sklearn: 1.2.2
2023-03-19 17:39:14,540:INFO:                pyod: 1.0.8
2023-03-19 17:39:14,540:INFO:            imblearn: 0.10.1
2023-03-19 17:39:14,540:INFO:   category_encoders: 2.6.0
2023-03-19 17:39:14,540:INFO:            lightgbm: 3.3.5
2023-03-19 17:39:14,540:INFO:               numba: 0.56.4
2023-03-19 17:39:14,540:INFO:            requests: 2.28.2
2023-03-19 17:39:14,540:INFO:          matplotlib: 3.7.1
2023-03-19 17:39:14,540:INFO:          scikitplot: 0.3.7
2023-03-19 17:39:14,540:INFO:         yellowbrick: 1.5
2023-03-19 17:39:14,540:INFO:              plotly: 5.13.1
2023-03-19 17:39:14,540:INFO:             kaleido: 0.2.1
2023-03-19 17:39:14,540:INFO:         statsmodels: 0.13.5
2023-03-19 17:39:14,540:INFO:              sktime: 0.16.1
2023-03-19 17:39:14,540:INFO:               tbats: 1.1.2
2023-03-19 17:39:14,540:INFO:            pmdarima: 2.0.3
2023-03-19 17:39:14,540:INFO:              psutil: 5.9.4
2023-03-19 17:39:14,540:INFO:PyCaret optional dependencies:
2023-03-19 17:39:14,540:INFO:                shap: 0.41.0
2023-03-19 17:39:14,540:INFO:           interpret: Not installed
2023-03-19 17:39:14,540:INFO:                umap: Not installed
2023-03-19 17:39:14,540:INFO:    pandas_profiling: Not installed
2023-03-19 17:39:14,540:INFO:  explainerdashboard: Not installed
2023-03-19 17:39:14,540:INFO:             autoviz: Not installed
2023-03-19 17:39:14,540:INFO:           fairlearn: Not installed
2023-03-19 17:39:14,540:INFO:             xgboost: Not installed
2023-03-19 17:39:14,540:INFO:            catboost: Not installed
2023-03-19 17:39:14,540:INFO:              kmodes: Not installed
2023-03-19 17:39:14,540:INFO:             mlxtend: Not installed
2023-03-19 17:39:14,540:INFO:       statsforecast: Not installed
2023-03-19 17:39:14,540:INFO:        tune_sklearn: Not installed
2023-03-19 17:39:14,540:INFO:                 ray: Not installed
2023-03-19 17:39:14,540:INFO:            hyperopt: Not installed
2023-03-19 17:39:14,540:INFO:              optuna: Not installed
2023-03-19 17:39:14,540:INFO:               skopt: Not installed
2023-03-19 17:39:14,540:INFO:              mlflow: 2.2.2
2023-03-19 17:39:14,540:INFO:              gradio: Not installed
2023-03-19 17:39:14,540:INFO:             fastapi: Not installed
2023-03-19 17:39:14,540:INFO:             uvicorn: Not installed
2023-03-19 17:39:14,540:INFO:              m2cgen: Not installed
2023-03-19 17:39:14,540:INFO:           evidently: Not installed
2023-03-19 17:39:14,540:INFO:               fugue: Not installed
2023-03-19 17:39:14,540:INFO:           streamlit: Not installed
2023-03-19 17:39:14,540:INFO:             prophet: Not installed
2023-03-19 17:39:14,540:INFO:None
2023-03-19 17:39:14,540:INFO:Set up data.
2023-03-19 17:39:14,573:INFO:Set up train/test split.
2023-03-19 17:39:14,597:INFO:Set up index.
2023-03-19 17:39:14,597:INFO:Set up folding strategy.
2023-03-19 17:39:14,597:INFO:Assigning column types.
2023-03-19 17:39:14,597:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:39:14,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:39:14,653:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:14,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:14,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:14,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:39:14,749:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:14,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:14,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:14,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:39:14,862:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:14,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:14,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:14,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:14,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:15,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:15,006:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:39:15,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:15,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:15,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:15,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:15,199:INFO:Preparing preprocessing pipeline...
2023-03-19 17:39:15,199:INFO:Set up simple imputation.
2023-03-19 17:39:15,206:INFO:Set up encoding of ordinal features.
2023-03-19 17:39:15,206:INFO:Set up encoding of categorical features.
2023-03-19 17:39:15,206:INFO:Set up column name cleaning.
2023-03-19 17:39:16,050:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:39:16,082:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:39:16,082:INFO:Creating final display dataframe.
2023-03-19 17:39:16,887:INFO:Setup _display_container:                     Description            Value
0                    Session id              124
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name    adult-dataset
23                          USI             4478
2023-03-19 17:39:17,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:17,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:17,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:17,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:17,112:INFO:Logging experiment in loggers
2023-03-19 17:39:17,210:INFO:SubProcess save_model() called ==================================
2023-03-19 17:39:17,250:INFO:Initializing save_model()
2023-03-19 17:39:17,250:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmpvxsvt2wq\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:39:17,250:INFO:Adding model into prep_pipe
2023-03-19 17:39:17,258:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:39:17,274:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmpvxsvt2wq\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:39:17,299:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:39:17,299:INFO:save_model() successfully completed......................................
2023-03-19 17:39:17,517:INFO:SubProcess save_model() end ==================================
2023-03-19 17:39:17,579:INFO:setup() successfully completed in 2.71s...............
2023-03-19 17:39:50,510:INFO:PyCaret ClassificationExperiment
2023-03-19 17:39:50,510:INFO:Logging name: adult-dataset
2023-03-19 17:39:50,510:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:39:50,510:INFO:version 3.0.0
2023-03-19 17:39:50,510:INFO:Initializing setup()
2023-03-19 17:39:50,510:INFO:self.USI: df64
2023-03-19 17:39:50,510:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_train', 'y', 'log_plots_param', 'n_jobs_param', 'X_train', 'fix_imbalance', '_ml_usecase', 'X_test', 'exp_name_log', '_available_plots', 'USI', 'pipeline', 'y_test', 'data', 'idx', 'gpu_param', 'is_multiclass', 'seed', 'target_param', 'memory', 'html_param', 'exp_id', 'X', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'logging_param'}
2023-03-19 17:39:50,510:INFO:Checking environment
2023-03-19 17:39:50,510:INFO:python_version: 3.10.0
2023-03-19 17:39:50,510:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:39:50,510:INFO:machine: AMD64
2023-03-19 17:39:50,510:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:39:50,528:INFO:Memory: svmem(total=16969424896, available=4577439744, percent=73.0, used=12391985152, free=4577439744)
2023-03-19 17:39:50,528:INFO:Physical Core: 4
2023-03-19 17:39:50,528:INFO:Logical Core: 8
2023-03-19 17:39:50,528:INFO:Checking libraries
2023-03-19 17:39:50,528:INFO:System:
2023-03-19 17:39:50,528:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:39:50,528:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:39:50,528:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:39:50,528:INFO:PyCaret required dependencies:
2023-03-19 17:39:50,528:INFO:                 pip: 23.0.1
2023-03-19 17:39:50,528:INFO:          setuptools: 65.6.3
2023-03-19 17:39:50,528:INFO:             pycaret: 3.0.0
2023-03-19 17:39:50,528:INFO:             IPython: 8.11.0
2023-03-19 17:39:50,528:INFO:          ipywidgets: 8.0.4
2023-03-19 17:39:50,528:INFO:                tqdm: 4.65.0
2023-03-19 17:39:50,528:INFO:               numpy: 1.23.5
2023-03-19 17:39:50,528:INFO:              pandas: 1.5.3
2023-03-19 17:39:50,528:INFO:              jinja2: 3.1.2
2023-03-19 17:39:50,528:INFO:               scipy: 1.10.1
2023-03-19 17:39:50,528:INFO:              joblib: 1.2.0
2023-03-19 17:39:50,528:INFO:             sklearn: 1.2.2
2023-03-19 17:39:50,528:INFO:                pyod: 1.0.8
2023-03-19 17:39:50,528:INFO:            imblearn: 0.10.1
2023-03-19 17:39:50,528:INFO:   category_encoders: 2.6.0
2023-03-19 17:39:50,528:INFO:            lightgbm: 3.3.5
2023-03-19 17:39:50,528:INFO:               numba: 0.56.4
2023-03-19 17:39:50,528:INFO:            requests: 2.28.2
2023-03-19 17:39:50,528:INFO:          matplotlib: 3.7.1
2023-03-19 17:39:50,528:INFO:          scikitplot: 0.3.7
2023-03-19 17:39:50,528:INFO:         yellowbrick: 1.5
2023-03-19 17:39:50,528:INFO:              plotly: 5.13.1
2023-03-19 17:39:50,528:INFO:             kaleido: 0.2.1
2023-03-19 17:39:50,528:INFO:         statsmodels: 0.13.5
2023-03-19 17:39:50,528:INFO:              sktime: 0.16.1
2023-03-19 17:39:50,528:INFO:               tbats: 1.1.2
2023-03-19 17:39:50,528:INFO:            pmdarima: 2.0.3
2023-03-19 17:39:50,528:INFO:              psutil: 5.9.4
2023-03-19 17:39:50,528:INFO:PyCaret optional dependencies:
2023-03-19 17:39:50,528:INFO:                shap: 0.41.0
2023-03-19 17:39:50,528:INFO:           interpret: Not installed
2023-03-19 17:39:50,528:INFO:                umap: Not installed
2023-03-19 17:39:50,528:INFO:    pandas_profiling: Not installed
2023-03-19 17:39:50,528:INFO:  explainerdashboard: Not installed
2023-03-19 17:39:50,528:INFO:             autoviz: Not installed
2023-03-19 17:39:50,528:INFO:           fairlearn: Not installed
2023-03-19 17:39:50,528:INFO:             xgboost: Not installed
2023-03-19 17:39:50,528:INFO:            catboost: Not installed
2023-03-19 17:39:50,528:INFO:              kmodes: Not installed
2023-03-19 17:39:50,528:INFO:             mlxtend: Not installed
2023-03-19 17:39:50,528:INFO:       statsforecast: Not installed
2023-03-19 17:39:50,528:INFO:        tune_sklearn: Not installed
2023-03-19 17:39:50,528:INFO:                 ray: Not installed
2023-03-19 17:39:50,528:INFO:            hyperopt: Not installed
2023-03-19 17:39:50,528:INFO:              optuna: Not installed
2023-03-19 17:39:50,528:INFO:               skopt: Not installed
2023-03-19 17:39:50,528:INFO:              mlflow: 2.2.2
2023-03-19 17:39:50,528:INFO:              gradio: Not installed
2023-03-19 17:39:50,528:INFO:             fastapi: Not installed
2023-03-19 17:39:50,528:INFO:             uvicorn: Not installed
2023-03-19 17:39:50,528:INFO:              m2cgen: Not installed
2023-03-19 17:39:50,528:INFO:           evidently: Not installed
2023-03-19 17:39:50,528:INFO:               fugue: Not installed
2023-03-19 17:39:50,528:INFO:           streamlit: Not installed
2023-03-19 17:39:50,528:INFO:             prophet: Not installed
2023-03-19 17:39:50,528:INFO:None
2023-03-19 17:39:50,528:INFO:Set up data.
2023-03-19 17:39:50,621:INFO:Set up train/test split.
2023-03-19 17:39:50,669:INFO:Set up index.
2023-03-19 17:39:50,669:INFO:Set up folding strategy.
2023-03-19 17:39:50,669:INFO:Assigning column types.
2023-03-19 17:39:50,685:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:39:50,828:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:39:50,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:50,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:50,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:39:51,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:51,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,176:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:39:51,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:51,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,628:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:39:51,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,725:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:39:51,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:39:51,966:INFO:Preparing preprocessing pipeline...
2023-03-19 17:39:51,966:INFO:Set up simple imputation.
2023-03-19 17:39:51,974:INFO:Set up encoding of ordinal features.
2023-03-19 17:39:51,982:INFO:Set up encoding of categorical features.
2023-03-19 17:39:51,982:INFO:Set up feature normalization.
2023-03-19 17:40:05,443:INFO:PyCaret ClassificationExperiment
2023-03-19 17:40:05,443:INFO:Logging name: adult-dataset
2023-03-19 17:40:05,443:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:40:05,443:INFO:version 3.0.0
2023-03-19 17:40:05,443:INFO:Initializing setup()
2023-03-19 17:40:05,443:INFO:self.USI: fdb4
2023-03-19 17:40:05,443:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_train', 'y', 'log_plots_param', 'n_jobs_param', 'X_train', 'fix_imbalance', '_ml_usecase', 'X_test', 'exp_name_log', '_available_plots', 'USI', 'pipeline', 'y_test', 'data', 'idx', 'gpu_param', 'is_multiclass', 'seed', 'target_param', 'memory', 'html_param', 'exp_id', 'X', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'logging_param'}
2023-03-19 17:40:05,443:INFO:Checking environment
2023-03-19 17:40:05,443:INFO:python_version: 3.10.0
2023-03-19 17:40:05,443:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:40:05,443:INFO:machine: AMD64
2023-03-19 17:40:05,443:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:40:05,451:INFO:Memory: svmem(total=16969424896, available=4607627264, percent=72.8, used=12361797632, free=4607627264)
2023-03-19 17:40:05,451:INFO:Physical Core: 4
2023-03-19 17:40:05,459:INFO:Logical Core: 8
2023-03-19 17:40:05,459:INFO:Checking libraries
2023-03-19 17:40:05,459:INFO:System:
2023-03-19 17:40:05,459:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:40:05,459:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:40:05,459:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:40:05,459:INFO:PyCaret required dependencies:
2023-03-19 17:40:05,459:INFO:                 pip: 23.0.1
2023-03-19 17:40:05,459:INFO:          setuptools: 65.6.3
2023-03-19 17:40:05,459:INFO:             pycaret: 3.0.0
2023-03-19 17:40:05,459:INFO:             IPython: 8.11.0
2023-03-19 17:40:05,459:INFO:          ipywidgets: 8.0.4
2023-03-19 17:40:05,459:INFO:                tqdm: 4.65.0
2023-03-19 17:40:05,459:INFO:               numpy: 1.23.5
2023-03-19 17:40:05,459:INFO:              pandas: 1.5.3
2023-03-19 17:40:05,459:INFO:              jinja2: 3.1.2
2023-03-19 17:40:05,459:INFO:               scipy: 1.10.1
2023-03-19 17:40:05,459:INFO:              joblib: 1.2.0
2023-03-19 17:40:05,459:INFO:             sklearn: 1.2.2
2023-03-19 17:40:05,459:INFO:                pyod: 1.0.8
2023-03-19 17:40:05,459:INFO:            imblearn: 0.10.1
2023-03-19 17:40:05,459:INFO:   category_encoders: 2.6.0
2023-03-19 17:40:05,459:INFO:            lightgbm: 3.3.5
2023-03-19 17:40:05,459:INFO:               numba: 0.56.4
2023-03-19 17:40:05,459:INFO:            requests: 2.28.2
2023-03-19 17:40:05,459:INFO:          matplotlib: 3.7.1
2023-03-19 17:40:05,459:INFO:          scikitplot: 0.3.7
2023-03-19 17:40:05,459:INFO:         yellowbrick: 1.5
2023-03-19 17:40:05,459:INFO:              plotly: 5.13.1
2023-03-19 17:40:05,459:INFO:             kaleido: 0.2.1
2023-03-19 17:40:05,459:INFO:         statsmodels: 0.13.5
2023-03-19 17:40:05,459:INFO:              sktime: 0.16.1
2023-03-19 17:40:05,459:INFO:               tbats: 1.1.2
2023-03-19 17:40:05,459:INFO:            pmdarima: 2.0.3
2023-03-19 17:40:05,459:INFO:              psutil: 5.9.4
2023-03-19 17:40:05,459:INFO:PyCaret optional dependencies:
2023-03-19 17:40:05,459:INFO:                shap: 0.41.0
2023-03-19 17:40:05,459:INFO:           interpret: Not installed
2023-03-19 17:40:05,459:INFO:                umap: Not installed
2023-03-19 17:40:05,459:INFO:    pandas_profiling: Not installed
2023-03-19 17:40:05,459:INFO:  explainerdashboard: Not installed
2023-03-19 17:40:05,459:INFO:             autoviz: Not installed
2023-03-19 17:40:05,459:INFO:           fairlearn: Not installed
2023-03-19 17:40:05,459:INFO:             xgboost: Not installed
2023-03-19 17:40:05,459:INFO:            catboost: Not installed
2023-03-19 17:40:05,459:INFO:              kmodes: Not installed
2023-03-19 17:40:05,459:INFO:             mlxtend: Not installed
2023-03-19 17:40:05,459:INFO:       statsforecast: Not installed
2023-03-19 17:40:05,459:INFO:        tune_sklearn: Not installed
2023-03-19 17:40:05,459:INFO:                 ray: Not installed
2023-03-19 17:40:05,459:INFO:            hyperopt: Not installed
2023-03-19 17:40:05,459:INFO:              optuna: Not installed
2023-03-19 17:40:05,459:INFO:               skopt: Not installed
2023-03-19 17:40:05,459:INFO:              mlflow: 2.2.2
2023-03-19 17:40:05,459:INFO:              gradio: Not installed
2023-03-19 17:40:05,459:INFO:             fastapi: Not installed
2023-03-19 17:40:05,459:INFO:             uvicorn: Not installed
2023-03-19 17:40:05,459:INFO:              m2cgen: Not installed
2023-03-19 17:40:05,459:INFO:           evidently: Not installed
2023-03-19 17:40:05,459:INFO:               fugue: Not installed
2023-03-19 17:40:05,459:INFO:           streamlit: Not installed
2023-03-19 17:40:05,459:INFO:             prophet: Not installed
2023-03-19 17:40:05,459:INFO:None
2023-03-19 17:40:05,459:INFO:Set up data.
2023-03-19 17:40:05,499:INFO:Set up train/test split.
2023-03-19 17:40:05,518:INFO:Set up index.
2023-03-19 17:40:05,518:INFO:Set up folding strategy.
2023-03-19 17:40:05,518:INFO:Assigning column types.
2023-03-19 17:40:05,526:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:40:05,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:40:05,626:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:40:05,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:40:05,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:40:05,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,771:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:40:05,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:40:05,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,947:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:40:05,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:05,979:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:40:06,075:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:06,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:06,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:06,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:06,196:INFO:Preparing preprocessing pipeline...
2023-03-19 17:40:06,196:INFO:Set up simple imputation.
2023-03-19 17:40:06,204:INFO:Set up encoding of ordinal features.
2023-03-19 17:40:06,204:INFO:Set up encoding of categorical features.
2023-03-19 17:40:06,204:INFO:Set up feature normalization.
2023-03-19 17:40:06,204:INFO:Set up column name cleaning.
2023-03-19 17:40:06,809:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:40:06,841:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:40:06,841:INFO:Creating final display dataframe.
2023-03-19 17:40:07,724:INFO:Setup _display_container:                     Description            Value
0                    Session id              124
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment     MlflowLogger
24              Experiment Name    adult-dataset
25                          USI             fdb4
2023-03-19 17:40:07,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:07,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:07,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:07,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:40:07,958:INFO:Logging experiment in loggers
2023-03-19 17:40:08,078:INFO:SubProcess save_model() called ==================================
2023-03-19 17:40:08,130:INFO:Initializing save_model()
2023-03-19 17:40:08,130:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmpm7b3_1tx\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:40:08,130:INFO:Adding model into prep_pipe
2023-03-19 17:40:08,130:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:40:08,147:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmpm7b3_1tx\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:40:08,180:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=124,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:40:08,180:INFO:save_model() successfully completed......................................
2023-03-19 17:40:08,397:INFO:SubProcess save_model() end ==================================
2023-03-19 17:40:08,454:INFO:setup() successfully completed in 2.64s...............
2023-03-19 17:40:21,754:INFO:Initializing compare_models()
2023-03-19 17:40:21,754:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:40:21,754:INFO:Checking exceptions
2023-03-19 17:40:21,769:INFO:Preparing display monitor
2023-03-19 17:40:21,795:INFO:Initializing Logistic Regression
2023-03-19 17:40:21,795:INFO:Total runtime is 0.0 minutes
2023-03-19 17:40:21,803:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:21,803:INFO:Initializing create_model()
2023-03-19 17:40:21,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:21,803:INFO:Checking exceptions
2023-03-19 17:40:21,803:INFO:Importing libraries
2023-03-19 17:40:21,803:INFO:Copying training dataset
2023-03-19 17:40:21,819:INFO:Defining folds
2023-03-19 17:40:21,819:INFO:Declaring metric variables
2023-03-19 17:40:21,827:INFO:Importing untrained model
2023-03-19 17:40:21,835:INFO:Logistic Regression Imported successfully
2023-03-19 17:40:21,847:INFO:Starting cross validation
2023-03-19 17:40:21,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:26,502:INFO:Calculating mean and std
2023-03-19 17:40:26,502:INFO:Creating metrics dataframe
2023-03-19 17:40:26,762:INFO:Uploading results into container
2023-03-19 17:40:26,762:INFO:Uploading model into container now
2023-03-19 17:40:26,762:INFO:_master_model_container: 1
2023-03-19 17:40:26,762:INFO:_display_container: 2
2023-03-19 17:40:26,762:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=124, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:40:26,762:INFO:create_model() successfully completed......................................
2023-03-19 17:40:26,867:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:26,867:INFO:Creating metrics dataframe
2023-03-19 17:40:26,883:INFO:Initializing K Neighbors Classifier
2023-03-19 17:40:26,883:INFO:Total runtime is 0.08479905923207601 minutes
2023-03-19 17:40:26,883:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:26,891:INFO:Initializing create_model()
2023-03-19 17:40:26,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:26,891:INFO:Checking exceptions
2023-03-19 17:40:26,891:INFO:Importing libraries
2023-03-19 17:40:26,891:INFO:Copying training dataset
2023-03-19 17:40:26,899:INFO:Defining folds
2023-03-19 17:40:26,899:INFO:Declaring metric variables
2023-03-19 17:40:26,907:INFO:Importing untrained model
2023-03-19 17:40:26,915:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:40:26,924:INFO:Starting cross validation
2023-03-19 17:40:26,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:32,647:INFO:Calculating mean and std
2023-03-19 17:40:32,655:INFO:Creating metrics dataframe
2023-03-19 17:40:32,905:INFO:Uploading results into container
2023-03-19 17:40:32,905:INFO:Uploading model into container now
2023-03-19 17:40:32,905:INFO:_master_model_container: 2
2023-03-19 17:40:32,905:INFO:_display_container: 2
2023-03-19 17:40:32,905:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:40:32,905:INFO:create_model() successfully completed......................................
2023-03-19 17:40:33,017:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:33,017:INFO:Creating metrics dataframe
2023-03-19 17:40:33,041:INFO:Initializing Naive Bayes
2023-03-19 17:40:33,041:INFO:Total runtime is 0.18742826382319133 minutes
2023-03-19 17:40:33,041:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:33,041:INFO:Initializing create_model()
2023-03-19 17:40:33,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:33,041:INFO:Checking exceptions
2023-03-19 17:40:33,049:INFO:Importing libraries
2023-03-19 17:40:33,049:INFO:Copying training dataset
2023-03-19 17:40:33,065:INFO:Defining folds
2023-03-19 17:40:33,065:INFO:Declaring metric variables
2023-03-19 17:40:33,073:INFO:Importing untrained model
2023-03-19 17:40:33,081:INFO:Naive Bayes Imported successfully
2023-03-19 17:40:33,098:INFO:Starting cross validation
2023-03-19 17:40:33,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:36,230:INFO:Calculating mean and std
2023-03-19 17:40:36,230:INFO:Creating metrics dataframe
2023-03-19 17:40:36,415:INFO:Uploading results into container
2023-03-19 17:40:36,415:INFO:Uploading model into container now
2023-03-19 17:40:36,415:INFO:_master_model_container: 3
2023-03-19 17:40:36,415:INFO:_display_container: 2
2023-03-19 17:40:36,415:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:40:36,415:INFO:create_model() successfully completed......................................
2023-03-19 17:40:36,511:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:36,511:INFO:Creating metrics dataframe
2023-03-19 17:40:36,527:INFO:Initializing Decision Tree Classifier
2023-03-19 17:40:36,527:INFO:Total runtime is 0.24553552468617756 minutes
2023-03-19 17:40:36,527:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:36,527:INFO:Initializing create_model()
2023-03-19 17:40:36,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:36,527:INFO:Checking exceptions
2023-03-19 17:40:36,535:INFO:Importing libraries
2023-03-19 17:40:36,535:INFO:Copying training dataset
2023-03-19 17:40:36,551:INFO:Defining folds
2023-03-19 17:40:36,551:INFO:Declaring metric variables
2023-03-19 17:40:36,551:INFO:Importing untrained model
2023-03-19 17:40:36,561:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:40:36,568:INFO:Starting cross validation
2023-03-19 17:40:36,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:39,569:INFO:Calculating mean and std
2023-03-19 17:40:39,569:INFO:Creating metrics dataframe
2023-03-19 17:40:39,746:INFO:Uploading results into container
2023-03-19 17:40:39,746:INFO:Uploading model into container now
2023-03-19 17:40:39,746:INFO:_master_model_container: 4
2023-03-19 17:40:39,746:INFO:_display_container: 2
2023-03-19 17:40:39,746:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=124, splitter='best')
2023-03-19 17:40:39,746:INFO:create_model() successfully completed......................................
2023-03-19 17:40:39,858:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:39,858:INFO:Creating metrics dataframe
2023-03-19 17:40:39,866:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:40:39,866:INFO:Total runtime is 0.30118099053700764 minutes
2023-03-19 17:40:39,874:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:39,874:INFO:Initializing create_model()
2023-03-19 17:40:39,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:39,874:INFO:Checking exceptions
2023-03-19 17:40:39,874:INFO:Importing libraries
2023-03-19 17:40:39,874:INFO:Copying training dataset
2023-03-19 17:40:39,891:INFO:Defining folds
2023-03-19 17:40:39,891:INFO:Declaring metric variables
2023-03-19 17:40:39,898:INFO:Importing untrained model
2023-03-19 17:40:39,906:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:40:39,914:INFO:Starting cross validation
2023-03-19 17:40:39,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:41,862:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:41,895:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:41,926:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:41,952:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:41,975:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:41,991:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:41,999:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:42,015:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:43,557:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:43,557:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:40:43,750:INFO:Calculating mean and std
2023-03-19 17:40:43,750:INFO:Creating metrics dataframe
2023-03-19 17:40:43,934:INFO:Uploading results into container
2023-03-19 17:40:43,942:INFO:Uploading model into container now
2023-03-19 17:40:43,942:INFO:_master_model_container: 5
2023-03-19 17:40:43,942:INFO:_display_container: 2
2023-03-19 17:40:43,942:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=124, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:40:43,942:INFO:create_model() successfully completed......................................
2023-03-19 17:40:44,039:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:44,039:INFO:Creating metrics dataframe
2023-03-19 17:40:44,047:INFO:Initializing Ridge Classifier
2023-03-19 17:40:44,047:INFO:Total runtime is 0.3708599925041199 minutes
2023-03-19 17:40:44,055:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:44,055:INFO:Initializing create_model()
2023-03-19 17:40:44,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:44,055:INFO:Checking exceptions
2023-03-19 17:40:44,055:INFO:Importing libraries
2023-03-19 17:40:44,055:INFO:Copying training dataset
2023-03-19 17:40:44,067:INFO:Defining folds
2023-03-19 17:40:44,067:INFO:Declaring metric variables
2023-03-19 17:40:44,071:INFO:Importing untrained model
2023-03-19 17:40:44,071:INFO:Ridge Classifier Imported successfully
2023-03-19 17:40:44,087:INFO:Starting cross validation
2023-03-19 17:40:44,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:45,281:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,281:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,353:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,361:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,361:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,445:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,451:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:45,500:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:46,490:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:46,514:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:40:47,170:INFO:Calculating mean and std
2023-03-19 17:40:47,170:INFO:Creating metrics dataframe
2023-03-19 17:40:47,436:INFO:Uploading results into container
2023-03-19 17:40:47,436:INFO:Uploading model into container now
2023-03-19 17:40:47,436:INFO:_master_model_container: 6
2023-03-19 17:40:47,436:INFO:_display_container: 2
2023-03-19 17:40:47,436:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=124, solver='auto',
                tol=0.0001)
2023-03-19 17:40:47,444:INFO:create_model() successfully completed......................................
2023-03-19 17:40:47,556:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:47,556:INFO:Creating metrics dataframe
2023-03-19 17:40:47,572:INFO:Initializing Random Forest Classifier
2023-03-19 17:40:47,572:INFO:Total runtime is 0.42960776487986246 minutes
2023-03-19 17:40:47,576:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:47,576:INFO:Initializing create_model()
2023-03-19 17:40:47,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:47,576:INFO:Checking exceptions
2023-03-19 17:40:47,576:INFO:Importing libraries
2023-03-19 17:40:47,576:INFO:Copying training dataset
2023-03-19 17:40:47,596:INFO:Defining folds
2023-03-19 17:40:47,596:INFO:Declaring metric variables
2023-03-19 17:40:47,604:INFO:Importing untrained model
2023-03-19 17:40:47,612:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:40:47,620:INFO:Starting cross validation
2023-03-19 17:40:47,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:52,125:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:40:52,309:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:40:52,388:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:40:52,414:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:40:56,703:INFO:Calculating mean and std
2023-03-19 17:40:56,711:INFO:Creating metrics dataframe
2023-03-19 17:40:56,936:INFO:Uploading results into container
2023-03-19 17:40:56,936:INFO:Uploading model into container now
2023-03-19 17:40:56,936:INFO:_master_model_container: 7
2023-03-19 17:40:56,936:INFO:_display_container: 2
2023-03-19 17:40:56,936:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=124, verbose=0, warm_start=False)
2023-03-19 17:40:56,936:INFO:create_model() successfully completed......................................
2023-03-19 17:40:57,033:INFO:SubProcess create_model() end ==================================
2023-03-19 17:40:57,041:INFO:Creating metrics dataframe
2023-03-19 17:40:57,049:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:40:57,049:INFO:Total runtime is 0.5875563422838846 minutes
2023-03-19 17:40:57,057:INFO:SubProcess create_model() called ==================================
2023-03-19 17:40:57,057:INFO:Initializing create_model()
2023-03-19 17:40:57,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:40:57,057:INFO:Checking exceptions
2023-03-19 17:40:57,057:INFO:Importing libraries
2023-03-19 17:40:57,057:INFO:Copying training dataset
2023-03-19 17:40:57,065:INFO:Defining folds
2023-03-19 17:40:57,065:INFO:Declaring metric variables
2023-03-19 17:40:57,076:INFO:Importing untrained model
2023-03-19 17:40:57,081:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:40:57,100:INFO:Starting cross validation
2023-03-19 17:40:57,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:40:58,294:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:58,334:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:58,431:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:58,447:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:58,566:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:58,927:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:58,951:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:40:59,119:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:41:00,472:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:41:00,472:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:41:01,717:INFO:Calculating mean and std
2023-03-19 17:41:01,717:INFO:Creating metrics dataframe
2023-03-19 17:41:01,962:INFO:Uploading results into container
2023-03-19 17:41:01,962:INFO:Uploading model into container now
2023-03-19 17:41:01,962:INFO:_master_model_container: 8
2023-03-19 17:41:01,962:INFO:_display_container: 2
2023-03-19 17:41:01,966:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:41:01,966:INFO:create_model() successfully completed......................................
2023-03-19 17:41:02,062:INFO:SubProcess create_model() end ==================================
2023-03-19 17:41:02,062:INFO:Creating metrics dataframe
2023-03-19 17:41:02,070:INFO:Initializing Ada Boost Classifier
2023-03-19 17:41:02,070:INFO:Total runtime is 0.6712432702382405 minutes
2023-03-19 17:41:02,078:INFO:SubProcess create_model() called ==================================
2023-03-19 17:41:02,082:INFO:Initializing create_model()
2023-03-19 17:41:02,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:41:02,082:INFO:Checking exceptions
2023-03-19 17:41:02,082:INFO:Importing libraries
2023-03-19 17:41:02,082:INFO:Copying training dataset
2023-03-19 17:41:02,094:INFO:Defining folds
2023-03-19 17:41:02,094:INFO:Declaring metric variables
2023-03-19 17:41:02,094:INFO:Importing untrained model
2023-03-19 17:41:02,102:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:41:02,127:INFO:Starting cross validation
2023-03-19 17:41:02,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:41:03,797:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:41:13,467:INFO:Calculating mean and std
2023-03-19 17:41:13,470:INFO:Creating metrics dataframe
2023-03-19 17:41:13,791:INFO:Uploading results into container
2023-03-19 17:41:13,795:INFO:Uploading model into container now
2023-03-19 17:41:13,795:INFO:_master_model_container: 9
2023-03-19 17:41:13,795:INFO:_display_container: 2
2023-03-19 17:41:13,795:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=124)
2023-03-19 17:41:13,795:INFO:create_model() successfully completed......................................
2023-03-19 17:41:13,912:INFO:SubProcess create_model() end ==================================
2023-03-19 17:41:13,912:INFO:Creating metrics dataframe
2023-03-19 17:41:13,929:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:41:13,929:INFO:Total runtime is 0.8688927094141642 minutes
2023-03-19 17:41:13,937:INFO:SubProcess create_model() called ==================================
2023-03-19 17:41:13,937:INFO:Initializing create_model()
2023-03-19 17:41:13,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:41:13,937:INFO:Checking exceptions
2023-03-19 17:41:13,937:INFO:Importing libraries
2023-03-19 17:41:13,937:INFO:Copying training dataset
2023-03-19 17:41:13,953:INFO:Defining folds
2023-03-19 17:41:13,953:INFO:Declaring metric variables
2023-03-19 17:41:13,961:INFO:Importing untrained model
2023-03-19 17:41:13,969:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:41:13,985:INFO:Starting cross validation
2023-03-19 17:41:13,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:41:28,178:INFO:Calculating mean and std
2023-03-19 17:41:28,178:INFO:Creating metrics dataframe
2023-03-19 17:41:28,429:INFO:Uploading results into container
2023-03-19 17:41:28,429:INFO:Uploading model into container now
2023-03-19 17:41:28,429:INFO:_master_model_container: 10
2023-03-19 17:41:28,429:INFO:_display_container: 2
2023-03-19 17:41:28,429:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=124, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:41:28,429:INFO:create_model() successfully completed......................................
2023-03-19 17:41:28,528:INFO:SubProcess create_model() end ==================================
2023-03-19 17:41:28,528:INFO:Creating metrics dataframe
2023-03-19 17:41:28,544:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:41:28,544:INFO:Total runtime is 1.112489398320516 minutes
2023-03-19 17:41:28,551:INFO:SubProcess create_model() called ==================================
2023-03-19 17:41:28,551:INFO:Initializing create_model()
2023-03-19 17:41:28,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:41:28,551:INFO:Checking exceptions
2023-03-19 17:41:28,551:INFO:Importing libraries
2023-03-19 17:41:28,551:INFO:Copying training dataset
2023-03-19 17:41:28,567:INFO:Defining folds
2023-03-19 17:41:28,567:INFO:Declaring metric variables
2023-03-19 17:41:28,575:INFO:Importing untrained model
2023-03-19 17:41:28,588:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:41:28,600:INFO:Starting cross validation
2023-03-19 17:41:28,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:41:33,299:INFO:Calculating mean and std
2023-03-19 17:41:33,299:INFO:Creating metrics dataframe
2023-03-19 17:41:33,551:INFO:Uploading results into container
2023-03-19 17:41:33,559:INFO:Uploading model into container now
2023-03-19 17:41:33,559:INFO:_master_model_container: 11
2023-03-19 17:41:33,559:INFO:_display_container: 2
2023-03-19 17:41:33,559:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:41:33,559:INFO:create_model() successfully completed......................................
2023-03-19 17:41:33,664:INFO:SubProcess create_model() end ==================================
2023-03-19 17:41:33,664:INFO:Creating metrics dataframe
2023-03-19 17:41:33,672:INFO:Initializing Extra Trees Classifier
2023-03-19 17:41:33,672:INFO:Total runtime is 1.1979480663935345 minutes
2023-03-19 17:41:33,680:INFO:SubProcess create_model() called ==================================
2023-03-19 17:41:33,680:INFO:Initializing create_model()
2023-03-19 17:41:33,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:41:33,680:INFO:Checking exceptions
2023-03-19 17:41:33,680:INFO:Importing libraries
2023-03-19 17:41:33,680:INFO:Copying training dataset
2023-03-19 17:41:33,696:INFO:Defining folds
2023-03-19 17:41:33,696:INFO:Declaring metric variables
2023-03-19 17:41:33,696:INFO:Importing untrained model
2023-03-19 17:41:33,704:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:41:33,719:INFO:Starting cross validation
2023-03-19 17:41:33,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:41:41,951:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:42,460:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:42,907:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:43,492:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:44,336:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:44,494:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:44,496:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:44,604:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:41:44,656:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:44,854:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:44,983:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:45,089:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:46,013:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:46,093:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:46,631:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:46,659:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:41:53,867:INFO:Calculating mean and std
2023-03-19 17:41:53,867:INFO:Creating metrics dataframe
2023-03-19 17:41:54,653:INFO:Uploading results into container
2023-03-19 17:41:54,660:INFO:Uploading model into container now
2023-03-19 17:41:54,661:INFO:_master_model_container: 12
2023-03-19 17:41:54,661:INFO:_display_container: 2
2023-03-19 17:41:54,662:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=124, verbose=0, warm_start=False)
2023-03-19 17:41:54,662:INFO:create_model() successfully completed......................................
2023-03-19 17:41:54,818:INFO:SubProcess create_model() end ==================================
2023-03-19 17:41:54,818:INFO:Creating metrics dataframe
2023-03-19 17:41:54,847:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:41:54,847:INFO:Total runtime is 1.550871249039968 minutes
2023-03-19 17:41:54,872:INFO:SubProcess create_model() called ==================================
2023-03-19 17:41:54,874:INFO:Initializing create_model()
2023-03-19 17:41:54,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:41:54,876:INFO:Checking exceptions
2023-03-19 17:41:54,876:INFO:Importing libraries
2023-03-19 17:41:54,876:INFO:Copying training dataset
2023-03-19 17:41:54,904:INFO:Defining folds
2023-03-19 17:41:54,904:INFO:Declaring metric variables
2023-03-19 17:41:54,922:INFO:Importing untrained model
2023-03-19 17:41:54,936:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:41:54,959:INFO:Starting cross validation
2023-03-19 17:41:54,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:42:05,216:INFO:Calculating mean and std
2023-03-19 17:42:05,216:INFO:Creating metrics dataframe
2023-03-19 17:42:06,020:INFO:Uploading results into container
2023-03-19 17:42:06,020:INFO:Uploading model into container now
2023-03-19 17:42:06,028:INFO:_master_model_container: 13
2023-03-19 17:42:06,028:INFO:_display_container: 2
2023-03-19 17:42:06,029:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=124, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:42:06,030:INFO:create_model() successfully completed......................................
2023-03-19 17:42:06,203:INFO:SubProcess create_model() end ==================================
2023-03-19 17:42:06,203:INFO:Creating metrics dataframe
2023-03-19 17:42:06,243:INFO:Initializing Dummy Classifier
2023-03-19 17:42:06,243:INFO:Total runtime is 1.7408006429672245 minutes
2023-03-19 17:42:06,257:INFO:SubProcess create_model() called ==================================
2023-03-19 17:42:06,260:INFO:Initializing create_model()
2023-03-19 17:42:06,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:42:06,260:INFO:Checking exceptions
2023-03-19 17:42:06,260:INFO:Importing libraries
2023-03-19 17:42:06,260:INFO:Copying training dataset
2023-03-19 17:42:06,284:INFO:Defining folds
2023-03-19 17:42:06,284:INFO:Declaring metric variables
2023-03-19 17:42:06,299:INFO:Importing untrained model
2023-03-19 17:42:06,310:INFO:Dummy Classifier Imported successfully
2023-03-19 17:42:06,339:INFO:Starting cross validation
2023-03-19 17:42:06,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:42:08,523:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,537:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,570:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,570:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,595:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,711:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,711:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:08,743:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:11,521:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:11,598:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:42:14,602:INFO:Calculating mean and std
2023-03-19 17:42:14,602:INFO:Creating metrics dataframe
2023-03-19 17:42:15,443:INFO:Uploading results into container
2023-03-19 17:42:15,443:INFO:Uploading model into container now
2023-03-19 17:42:15,443:INFO:_master_model_container: 14
2023-03-19 17:42:15,443:INFO:_display_container: 2
2023-03-19 17:42:15,450:INFO:DummyClassifier(constant=None, random_state=124, strategy='prior')
2023-03-19 17:42:15,450:INFO:create_model() successfully completed......................................
2023-03-19 17:42:15,617:INFO:SubProcess create_model() end ==================================
2023-03-19 17:42:15,617:INFO:Creating metrics dataframe
2023-03-19 17:42:15,680:INFO:Initializing create_model()
2023-03-19 17:42:15,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=124, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:42:15,680:INFO:Checking exceptions
2023-03-19 17:42:15,695:INFO:Importing libraries
2023-03-19 17:42:15,695:INFO:Copying training dataset
2023-03-19 17:42:15,712:INFO:Defining folds
2023-03-19 17:42:15,712:INFO:Declaring metric variables
2023-03-19 17:42:15,712:INFO:Importing untrained model
2023-03-19 17:42:15,712:INFO:Declaring custom model
2023-03-19 17:42:15,712:INFO:Logistic Regression Imported successfully
2023-03-19 17:42:15,735:INFO:Cross validation set to False
2023-03-19 17:42:15,735:INFO:Fitting Model
2023-03-19 17:42:17,770:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=124, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:42:17,770:INFO:create_model() successfully completed......................................
2023-03-19 17:42:17,869:INFO:Creating Dashboard logs
2023-03-19 17:42:17,878:INFO:Model: Logistic Regression
2023-03-19 17:42:17,949:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 124, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 17:42:18,100:INFO:Initializing predict_model()
2023-03-19 17:42:18,100:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160BCBAF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=124, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000017160B87B50>)
2023-03-19 17:42:18,100:INFO:Checking exceptions
2023-03-19 17:42:18,100:INFO:Preloading libraries
2023-03-19 17:42:18,735:INFO:Creating Dashboard logs
2023-03-19 17:42:18,735:INFO:Model: Linear Discriminant Analysis
2023-03-19 17:42:18,805:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:42:19,356:INFO:Creating Dashboard logs
2023-03-19 17:42:19,364:INFO:Model: SVM - Linear Kernel
2023-03-19 17:42:19,413:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 124, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:42:19,933:INFO:Creating Dashboard logs
2023-03-19 17:42:19,945:INFO:Model: Ridge Classifier
2023-03-19 17:42:20,015:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 124, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 17:42:20,600:INFO:Creating Dashboard logs
2023-03-19 17:42:20,608:INFO:Model: Extra Trees Classifier
2023-03-19 17:42:20,670:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 124, 'verbose': 0, 'warm_start': False}
2023-03-19 17:42:21,175:INFO:Creating Dashboard logs
2023-03-19 17:42:21,184:INFO:Model: K Neighbors Classifier
2023-03-19 17:42:21,264:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 17:42:21,799:INFO:Creating Dashboard logs
2023-03-19 17:42:21,809:INFO:Model: Random Forest Classifier
2023-03-19 17:42:21,870:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 124, 'verbose': 0, 'warm_start': False}
2023-03-19 17:42:22,477:INFO:Creating Dashboard logs
2023-03-19 17:42:22,489:INFO:Model: str
2023-03-19 17:42:22,571:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 124}
2023-03-19 17:42:23,160:INFO:Creating Dashboard logs
2023-03-19 17:42:23,171:INFO:Model: Dummy Classifier
2023-03-19 17:42:23,250:INFO:Logged params: {'constant': None, 'random_state': 124, 'strategy': 'prior'}
2023-03-19 17:42:23,762:INFO:Creating Dashboard logs
2023-03-19 17:42:23,772:INFO:Model: Light Gradient Boosting Machine
2023-03-19 17:42:23,828:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 124, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 17:42:24,384:INFO:Creating Dashboard logs
2023-03-19 17:42:24,392:INFO:Model: Decision Tree Classifier
2023-03-19 17:42:24,457:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 124, 'splitter': 'best'}
2023-03-19 17:42:24,969:INFO:Creating Dashboard logs
2023-03-19 17:42:24,977:INFO:Model: Gradient Boosting Classifier
2023-03-19 17:42:25,033:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 124, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:42:25,689:INFO:Creating Dashboard logs
2023-03-19 17:42:25,691:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 17:42:25,756:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:42:26,242:INFO:Creating Dashboard logs
2023-03-19 17:42:26,250:INFO:Model: Naive Bayes
2023-03-19 17:42:26,316:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 17:42:26,874:INFO:_master_model_container: 14
2023-03-19 17:42:26,882:INFO:_display_container: 2
2023-03-19 17:42:26,882:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=124, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:42:26,882:INFO:compare_models() successfully completed......................................
2023-03-19 17:49:23,302:INFO:PyCaret ClassificationExperiment
2023-03-19 17:49:23,302:INFO:Logging name: adult-dataset
2023-03-19 17:49:23,302:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:49:23,302:INFO:version 3.0.0
2023-03-19 17:49:23,302:INFO:Initializing setup()
2023-03-19 17:49:23,302:INFO:self.USI: a125
2023-03-19 17:49:23,302:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_train', 'y', 'log_plots_param', 'n_jobs_param', 'X_train', 'fix_imbalance', '_ml_usecase', 'X_test', 'exp_name_log', '_available_plots', 'USI', 'pipeline', 'y_test', 'data', 'idx', 'gpu_param', 'is_multiclass', 'seed', 'target_param', 'memory', 'html_param', 'exp_id', 'X', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'logging_param'}
2023-03-19 17:49:23,302:INFO:Checking environment
2023-03-19 17:49:23,302:INFO:python_version: 3.10.0
2023-03-19 17:49:23,302:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:49:23,302:INFO:machine: AMD64
2023-03-19 17:49:23,302:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:49:23,313:INFO:Memory: svmem(total=16969424896, available=5697232896, percent=66.4, used=11272192000, free=5697232896)
2023-03-19 17:49:23,313:INFO:Physical Core: 4
2023-03-19 17:49:23,313:INFO:Logical Core: 8
2023-03-19 17:49:23,313:INFO:Checking libraries
2023-03-19 17:49:23,313:INFO:System:
2023-03-19 17:49:23,313:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:49:23,313:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:49:23,313:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:49:23,313:INFO:PyCaret required dependencies:
2023-03-19 17:49:23,313:INFO:                 pip: 23.0.1
2023-03-19 17:49:23,313:INFO:          setuptools: 65.6.3
2023-03-19 17:49:23,313:INFO:             pycaret: 3.0.0
2023-03-19 17:49:23,313:INFO:             IPython: 8.11.0
2023-03-19 17:49:23,313:INFO:          ipywidgets: 8.0.4
2023-03-19 17:49:23,313:INFO:                tqdm: 4.65.0
2023-03-19 17:49:23,313:INFO:               numpy: 1.23.5
2023-03-19 17:49:23,319:INFO:              pandas: 1.5.3
2023-03-19 17:49:23,319:INFO:              jinja2: 3.1.2
2023-03-19 17:49:23,319:INFO:               scipy: 1.10.1
2023-03-19 17:49:23,319:INFO:              joblib: 1.2.0
2023-03-19 17:49:23,319:INFO:             sklearn: 1.2.2
2023-03-19 17:49:23,319:INFO:                pyod: 1.0.8
2023-03-19 17:49:23,319:INFO:            imblearn: 0.10.1
2023-03-19 17:49:23,319:INFO:   category_encoders: 2.6.0
2023-03-19 17:49:23,319:INFO:            lightgbm: 3.3.5
2023-03-19 17:49:23,319:INFO:               numba: 0.56.4
2023-03-19 17:49:23,319:INFO:            requests: 2.28.2
2023-03-19 17:49:23,319:INFO:          matplotlib: 3.7.1
2023-03-19 17:49:23,319:INFO:          scikitplot: 0.3.7
2023-03-19 17:49:23,319:INFO:         yellowbrick: 1.5
2023-03-19 17:49:23,319:INFO:              plotly: 5.13.1
2023-03-19 17:49:23,319:INFO:             kaleido: 0.2.1
2023-03-19 17:49:23,319:INFO:         statsmodels: 0.13.5
2023-03-19 17:49:23,319:INFO:              sktime: 0.16.1
2023-03-19 17:49:23,319:INFO:               tbats: 1.1.2
2023-03-19 17:49:23,319:INFO:            pmdarima: 2.0.3
2023-03-19 17:49:23,319:INFO:              psutil: 5.9.4
2023-03-19 17:49:23,319:INFO:PyCaret optional dependencies:
2023-03-19 17:49:23,319:INFO:                shap: 0.41.0
2023-03-19 17:49:23,319:INFO:           interpret: Not installed
2023-03-19 17:49:23,319:INFO:                umap: Not installed
2023-03-19 17:49:23,319:INFO:    pandas_profiling: Not installed
2023-03-19 17:49:23,319:INFO:  explainerdashboard: Not installed
2023-03-19 17:49:23,319:INFO:             autoviz: Not installed
2023-03-19 17:49:23,319:INFO:           fairlearn: Not installed
2023-03-19 17:49:23,319:INFO:             xgboost: Not installed
2023-03-19 17:49:23,319:INFO:            catboost: Not installed
2023-03-19 17:49:23,319:INFO:              kmodes: Not installed
2023-03-19 17:49:23,319:INFO:             mlxtend: Not installed
2023-03-19 17:49:23,319:INFO:       statsforecast: Not installed
2023-03-19 17:49:23,319:INFO:        tune_sklearn: Not installed
2023-03-19 17:49:23,319:INFO:                 ray: Not installed
2023-03-19 17:49:23,319:INFO:            hyperopt: Not installed
2023-03-19 17:49:23,319:INFO:              optuna: Not installed
2023-03-19 17:49:23,319:INFO:               skopt: Not installed
2023-03-19 17:49:23,319:INFO:              mlflow: 2.2.2
2023-03-19 17:49:23,319:INFO:              gradio: Not installed
2023-03-19 17:49:23,319:INFO:             fastapi: Not installed
2023-03-19 17:49:23,319:INFO:             uvicorn: Not installed
2023-03-19 17:49:23,319:INFO:              m2cgen: Not installed
2023-03-19 17:49:23,319:INFO:           evidently: Not installed
2023-03-19 17:49:23,319:INFO:               fugue: Not installed
2023-03-19 17:49:23,319:INFO:           streamlit: Not installed
2023-03-19 17:49:23,319:INFO:             prophet: Not installed
2023-03-19 17:49:23,319:INFO:None
2023-03-19 17:49:23,319:INFO:Set up data.
2023-03-19 17:49:23,359:INFO:Set up train/test split.
2023-03-19 17:49:23,391:INFO:Set up index.
2023-03-19 17:49:23,399:INFO:Set up folding strategy.
2023-03-19 17:49:23,399:INFO:Assigning column types.
2023-03-19 17:49:23,407:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:49:23,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:49:23,488:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:49:23,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:49:23,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:49:23,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,625:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:49:23,681:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:49:23,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,819:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:49:23,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,885:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:49:23,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:23,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:24,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:24,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:24,079:INFO:Preparing preprocessing pipeline...
2023-03-19 17:49:24,088:INFO:Set up simple imputation.
2023-03-19 17:49:24,096:INFO:Set up encoding of ordinal features.
2023-03-19 17:49:24,096:INFO:Set up encoding of categorical features.
2023-03-19 17:49:24,096:INFO:Set up column name cleaning.
2023-03-19 17:49:24,817:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:49:24,833:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8146,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:49:24,833:INFO:Creating final display dataframe.
2023-03-19 17:49:25,611:INFO:Setup _display_container:                     Description            Value
0                    Session id             8146
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name    adult-dataset
23                          USI             a125
2023-03-19 17:49:25,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:25,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:25,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:25,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:49:25,806:INFO:Logging experiment in loggers
2023-03-19 17:49:25,935:INFO:SubProcess save_model() called ==================================
2023-03-19 17:49:25,977:INFO:Initializing save_model()
2023-03-19 17:49:25,977:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8146,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmp7nw_nzjp\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8146,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:49:25,977:INFO:Adding model into prep_pipe
2023-03-19 17:49:25,984:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:49:25,993:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmp7nw_nzjp\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:49:26,016:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8146,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:49:26,016:INFO:save_model() successfully completed......................................
2023-03-19 17:49:26,349:INFO:SubProcess save_model() end ==================================
2023-03-19 17:49:26,447:INFO:setup() successfully completed in 2.8s...............
2023-03-19 17:49:26,496:INFO:Initializing compare_models()
2023-03-19 17:49:26,496:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:49:26,496:INFO:Checking exceptions
2023-03-19 17:49:26,504:INFO:Preparing display monitor
2023-03-19 17:49:26,544:INFO:Initializing Logistic Regression
2023-03-19 17:49:26,544:INFO:Total runtime is 0.0 minutes
2023-03-19 17:49:26,552:INFO:SubProcess create_model() called ==================================
2023-03-19 17:49:26,552:INFO:Initializing create_model()
2023-03-19 17:49:26,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:49:26,552:INFO:Checking exceptions
2023-03-19 17:49:26,552:INFO:Importing libraries
2023-03-19 17:49:26,552:INFO:Copying training dataset
2023-03-19 17:49:26,569:INFO:Defining folds
2023-03-19 17:49:26,569:INFO:Declaring metric variables
2023-03-19 17:49:26,576:INFO:Importing untrained model
2023-03-19 17:49:26,577:INFO:Logistic Regression Imported successfully
2023-03-19 17:49:26,593:INFO:Starting cross validation
2023-03-19 17:49:26,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:49:35,097:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-19 17:49:35,097:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-19 17:49:40,802:INFO:Calculating mean and std
2023-03-19 17:49:40,802:INFO:Creating metrics dataframe
2023-03-19 17:49:41,125:INFO:Uploading results into container
2023-03-19 17:49:41,125:INFO:Uploading model into container now
2023-03-19 17:49:41,125:INFO:_master_model_container: 1
2023-03-19 17:49:41,125:INFO:_display_container: 2
2023-03-19 17:49:41,125:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8146, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:49:41,125:INFO:create_model() successfully completed......................................
2023-03-19 17:49:41,228:INFO:SubProcess create_model() end ==================================
2023-03-19 17:49:41,229:INFO:Creating metrics dataframe
2023-03-19 17:49:41,237:INFO:Initializing K Neighbors Classifier
2023-03-19 17:49:41,237:INFO:Total runtime is 0.24488045374552408 minutes
2023-03-19 17:49:41,245:INFO:SubProcess create_model() called ==================================
2023-03-19 17:49:41,245:INFO:Initializing create_model()
2023-03-19 17:49:41,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:49:41,245:INFO:Checking exceptions
2023-03-19 17:49:41,245:INFO:Importing libraries
2023-03-19 17:49:41,245:INFO:Copying training dataset
2023-03-19 17:49:41,261:INFO:Defining folds
2023-03-19 17:49:41,261:INFO:Declaring metric variables
2023-03-19 17:49:41,269:INFO:Importing untrained model
2023-03-19 17:49:41,277:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:49:41,286:INFO:Starting cross validation
2023-03-19 17:49:41,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:49:48,002:INFO:Calculating mean and std
2023-03-19 17:49:48,006:INFO:Creating metrics dataframe
2023-03-19 17:49:48,312:INFO:Uploading results into container
2023-03-19 17:49:48,312:INFO:Uploading model into container now
2023-03-19 17:49:48,312:INFO:_master_model_container: 2
2023-03-19 17:49:48,315:INFO:_display_container: 2
2023-03-19 17:49:48,315:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:49:48,315:INFO:create_model() successfully completed......................................
2023-03-19 17:49:48,407:INFO:SubProcess create_model() end ==================================
2023-03-19 17:49:48,407:INFO:Creating metrics dataframe
2023-03-19 17:49:48,423:INFO:Initializing Naive Bayes
2023-03-19 17:49:48,423:INFO:Total runtime is 0.3646455883979797 minutes
2023-03-19 17:49:48,431:INFO:SubProcess create_model() called ==================================
2023-03-19 17:49:48,431:INFO:Initializing create_model()
2023-03-19 17:49:48,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:49:48,431:INFO:Checking exceptions
2023-03-19 17:49:48,431:INFO:Importing libraries
2023-03-19 17:49:48,431:INFO:Copying training dataset
2023-03-19 17:49:48,447:INFO:Defining folds
2023-03-19 17:49:48,447:INFO:Declaring metric variables
2023-03-19 17:49:48,455:INFO:Importing untrained model
2023-03-19 17:49:48,463:INFO:Naive Bayes Imported successfully
2023-03-19 17:49:48,471:INFO:Starting cross validation
2023-03-19 17:49:48,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:49:52,705:INFO:Calculating mean and std
2023-03-19 17:49:52,705:INFO:Creating metrics dataframe
2023-03-19 17:49:53,018:INFO:Uploading results into container
2023-03-19 17:49:53,018:INFO:Uploading model into container now
2023-03-19 17:49:53,018:INFO:_master_model_container: 3
2023-03-19 17:49:53,018:INFO:_display_container: 2
2023-03-19 17:49:53,018:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:49:53,018:INFO:create_model() successfully completed......................................
2023-03-19 17:49:53,122:INFO:SubProcess create_model() end ==================================
2023-03-19 17:49:53,122:INFO:Creating metrics dataframe
2023-03-19 17:49:53,139:INFO:Initializing Decision Tree Classifier
2023-03-19 17:49:53,139:INFO:Total runtime is 0.44324452877044673 minutes
2023-03-19 17:49:53,139:INFO:SubProcess create_model() called ==================================
2023-03-19 17:49:53,139:INFO:Initializing create_model()
2023-03-19 17:49:53,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:49:53,147:INFO:Checking exceptions
2023-03-19 17:49:53,147:INFO:Importing libraries
2023-03-19 17:49:53,147:INFO:Copying training dataset
2023-03-19 17:49:53,155:INFO:Defining folds
2023-03-19 17:49:53,155:INFO:Declaring metric variables
2023-03-19 17:49:53,163:INFO:Importing untrained model
2023-03-19 17:49:53,163:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:49:53,179:INFO:Starting cross validation
2023-03-19 17:49:53,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:49:57,811:INFO:Calculating mean and std
2023-03-19 17:49:57,812:INFO:Creating metrics dataframe
2023-03-19 17:49:58,146:INFO:Uploading results into container
2023-03-19 17:49:58,147:INFO:Uploading model into container now
2023-03-19 17:49:58,147:INFO:_master_model_container: 4
2023-03-19 17:49:58,147:INFO:_display_container: 2
2023-03-19 17:49:58,148:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8146, splitter='best')
2023-03-19 17:49:58,148:INFO:create_model() successfully completed......................................
2023-03-19 17:49:58,237:INFO:SubProcess create_model() end ==================================
2023-03-19 17:49:58,237:INFO:Creating metrics dataframe
2023-03-19 17:49:58,247:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:49:58,247:INFO:Total runtime is 0.5283870736757914 minutes
2023-03-19 17:49:58,252:INFO:SubProcess create_model() called ==================================
2023-03-19 17:49:58,252:INFO:Initializing create_model()
2023-03-19 17:49:58,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:49:58,253:INFO:Checking exceptions
2023-03-19 17:49:58,253:INFO:Importing libraries
2023-03-19 17:49:58,253:INFO:Copying training dataset
2023-03-19 17:49:58,263:INFO:Defining folds
2023-03-19 17:49:58,263:INFO:Declaring metric variables
2023-03-19 17:49:58,267:INFO:Importing untrained model
2023-03-19 17:49:58,271:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:49:58,279:INFO:Starting cross validation
2023-03-19 17:49:58,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:01,140:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:01,203:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:01,536:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:01,730:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:01,765:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:01,827:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:01,919:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:02,118:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:03,744:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:03,931:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:50:04,037:INFO:Calculating mean and std
2023-03-19 17:50:04,039:INFO:Creating metrics dataframe
2023-03-19 17:50:04,381:INFO:Uploading results into container
2023-03-19 17:50:04,381:INFO:Uploading model into container now
2023-03-19 17:50:04,382:INFO:_master_model_container: 5
2023-03-19 17:50:04,382:INFO:_display_container: 2
2023-03-19 17:50:04,384:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8146, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:50:04,384:INFO:create_model() successfully completed......................................
2023-03-19 17:50:04,481:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:04,481:INFO:Creating metrics dataframe
2023-03-19 17:50:04,491:INFO:Initializing Ridge Classifier
2023-03-19 17:50:04,491:INFO:Total runtime is 0.6324424346288045 minutes
2023-03-19 17:50:04,495:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:04,495:INFO:Initializing create_model()
2023-03-19 17:50:04,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:04,496:INFO:Checking exceptions
2023-03-19 17:50:04,496:INFO:Importing libraries
2023-03-19 17:50:04,496:INFO:Copying training dataset
2023-03-19 17:50:04,503:INFO:Defining folds
2023-03-19 17:50:04,503:INFO:Declaring metric variables
2023-03-19 17:50:04,509:INFO:Importing untrained model
2023-03-19 17:50:04,512:INFO:Ridge Classifier Imported successfully
2023-03-19 17:50:04,519:INFO:Starting cross validation
2023-03-19 17:50:04,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:05,408:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,433:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,489:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,517:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,547:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,580:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,697:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:05,764:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:06,522:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:06,561:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:50:07,666:INFO:Calculating mean and std
2023-03-19 17:50:07,667:INFO:Creating metrics dataframe
2023-03-19 17:50:07,921:INFO:Uploading results into container
2023-03-19 17:50:07,922:INFO:Uploading model into container now
2023-03-19 17:50:07,923:INFO:_master_model_container: 6
2023-03-19 17:50:07,923:INFO:_display_container: 2
2023-03-19 17:50:07,923:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8146, solver='auto',
                tol=0.0001)
2023-03-19 17:50:07,923:INFO:create_model() successfully completed......................................
2023-03-19 17:50:08,000:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:08,001:INFO:Creating metrics dataframe
2023-03-19 17:50:08,012:INFO:Initializing Random Forest Classifier
2023-03-19 17:50:08,012:INFO:Total runtime is 0.6911301374435425 minutes
2023-03-19 17:50:08,015:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:08,016:INFO:Initializing create_model()
2023-03-19 17:50:08,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:08,016:INFO:Checking exceptions
2023-03-19 17:50:08,016:INFO:Importing libraries
2023-03-19 17:50:08,016:INFO:Copying training dataset
2023-03-19 17:50:08,027:INFO:Defining folds
2023-03-19 17:50:08,027:INFO:Declaring metric variables
2023-03-19 17:50:08,030:INFO:Importing untrained model
2023-03-19 17:50:08,033:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:50:08,042:INFO:Starting cross validation
2023-03-19 17:50:08,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:09,489:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:50:10,852:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:10,880:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:10,897:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:14,872:INFO:Calculating mean and std
2023-03-19 17:50:14,873:INFO:Creating metrics dataframe
2023-03-19 17:50:15,143:INFO:Uploading results into container
2023-03-19 17:50:15,145:INFO:Uploading model into container now
2023-03-19 17:50:15,146:INFO:_master_model_container: 7
2023-03-19 17:50:15,146:INFO:_display_container: 2
2023-03-19 17:50:15,146:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8146, verbose=0, warm_start=False)
2023-03-19 17:50:15,146:INFO:create_model() successfully completed......................................
2023-03-19 17:50:15,236:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:15,236:INFO:Creating metrics dataframe
2023-03-19 17:50:15,249:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:50:15,249:INFO:Total runtime is 0.8117481033007303 minutes
2023-03-19 17:50:15,254:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:15,254:INFO:Initializing create_model()
2023-03-19 17:50:15,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:15,255:INFO:Checking exceptions
2023-03-19 17:50:15,255:INFO:Importing libraries
2023-03-19 17:50:15,255:INFO:Copying training dataset
2023-03-19 17:50:15,269:INFO:Defining folds
2023-03-19 17:50:15,269:INFO:Declaring metric variables
2023-03-19 17:50:15,273:INFO:Importing untrained model
2023-03-19 17:50:15,276:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:50:15,285:INFO:Starting cross validation
2023-03-19 17:50:15,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:16,049:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,070:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,157:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,190:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,219:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,239:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,379:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:16,440:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:17,837:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:17,909:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:50:19,401:INFO:Calculating mean and std
2023-03-19 17:50:19,403:INFO:Creating metrics dataframe
2023-03-19 17:50:19,700:INFO:Uploading results into container
2023-03-19 17:50:19,700:INFO:Uploading model into container now
2023-03-19 17:50:19,701:INFO:_master_model_container: 8
2023-03-19 17:50:19,701:INFO:_display_container: 2
2023-03-19 17:50:19,701:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:50:19,701:INFO:create_model() successfully completed......................................
2023-03-19 17:50:19,778:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:19,778:INFO:Creating metrics dataframe
2023-03-19 17:50:19,788:INFO:Initializing Ada Boost Classifier
2023-03-19 17:50:19,788:INFO:Total runtime is 0.8874034245808918 minutes
2023-03-19 17:50:19,794:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:19,794:INFO:Initializing create_model()
2023-03-19 17:50:19,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:19,795:INFO:Checking exceptions
2023-03-19 17:50:19,795:INFO:Importing libraries
2023-03-19 17:50:19,795:INFO:Copying training dataset
2023-03-19 17:50:19,802:INFO:Defining folds
2023-03-19 17:50:19,802:INFO:Declaring metric variables
2023-03-19 17:50:19,804:INFO:Importing untrained model
2023-03-19 17:50:19,809:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:50:19,817:INFO:Starting cross validation
2023-03-19 17:50:19,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:26,417:INFO:Calculating mean and std
2023-03-19 17:50:26,419:INFO:Creating metrics dataframe
2023-03-19 17:50:26,745:INFO:Uploading results into container
2023-03-19 17:50:26,746:INFO:Uploading model into container now
2023-03-19 17:50:26,746:INFO:_master_model_container: 9
2023-03-19 17:50:26,746:INFO:_display_container: 2
2023-03-19 17:50:26,747:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8146)
2023-03-19 17:50:26,747:INFO:create_model() successfully completed......................................
2023-03-19 17:50:26,829:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:26,829:INFO:Creating metrics dataframe
2023-03-19 17:50:26,843:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:50:26,843:INFO:Total runtime is 1.0049765427907307 minutes
2023-03-19 17:50:26,847:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:26,847:INFO:Initializing create_model()
2023-03-19 17:50:26,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:26,847:INFO:Checking exceptions
2023-03-19 17:50:26,847:INFO:Importing libraries
2023-03-19 17:50:26,847:INFO:Copying training dataset
2023-03-19 17:50:26,858:INFO:Defining folds
2023-03-19 17:50:26,859:INFO:Declaring metric variables
2023-03-19 17:50:26,861:INFO:Importing untrained model
2023-03-19 17:50:26,866:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:50:26,875:INFO:Starting cross validation
2023-03-19 17:50:26,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:40,426:INFO:Calculating mean and std
2023-03-19 17:50:40,427:INFO:Creating metrics dataframe
2023-03-19 17:50:40,727:INFO:Uploading results into container
2023-03-19 17:50:40,728:INFO:Uploading model into container now
2023-03-19 17:50:40,728:INFO:_master_model_container: 10
2023-03-19 17:50:40,728:INFO:_display_container: 2
2023-03-19 17:50:40,729:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8146, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:50:40,729:INFO:create_model() successfully completed......................................
2023-03-19 17:50:40,810:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:40,810:INFO:Creating metrics dataframe
2023-03-19 17:50:40,823:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:50:40,824:INFO:Total runtime is 1.2379879554112752 minutes
2023-03-19 17:50:40,826:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:40,827:INFO:Initializing create_model()
2023-03-19 17:50:40,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:40,827:INFO:Checking exceptions
2023-03-19 17:50:40,827:INFO:Importing libraries
2023-03-19 17:50:40,827:INFO:Copying training dataset
2023-03-19 17:50:40,837:INFO:Defining folds
2023-03-19 17:50:40,838:INFO:Declaring metric variables
2023-03-19 17:50:40,842:INFO:Importing untrained model
2023-03-19 17:50:40,846:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:50:40,853:INFO:Starting cross validation
2023-03-19 17:50:40,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:46,063:INFO:Calculating mean and std
2023-03-19 17:50:46,066:INFO:Creating metrics dataframe
2023-03-19 17:50:46,371:INFO:Uploading results into container
2023-03-19 17:50:46,372:INFO:Uploading model into container now
2023-03-19 17:50:46,372:INFO:_master_model_container: 11
2023-03-19 17:50:46,372:INFO:_display_container: 2
2023-03-19 17:50:46,373:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:50:46,373:INFO:create_model() successfully completed......................................
2023-03-19 17:50:46,457:INFO:SubProcess create_model() end ==================================
2023-03-19 17:50:46,457:INFO:Creating metrics dataframe
2023-03-19 17:50:46,469:INFO:Initializing Extra Trees Classifier
2023-03-19 17:50:46,469:INFO:Total runtime is 1.3320868055025736 minutes
2023-03-19 17:50:46,474:INFO:SubProcess create_model() called ==================================
2023-03-19 17:50:46,475:INFO:Initializing create_model()
2023-03-19 17:50:46,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:50:46,475:INFO:Checking exceptions
2023-03-19 17:50:46,475:INFO:Importing libraries
2023-03-19 17:50:46,475:INFO:Copying training dataset
2023-03-19 17:50:46,485:INFO:Defining folds
2023-03-19 17:50:46,485:INFO:Declaring metric variables
2023-03-19 17:50:46,489:INFO:Importing untrained model
2023-03-19 17:50:46,492:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:50:46,499:INFO:Starting cross validation
2023-03-19 17:50:46,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:50:51,676:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:52,501:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:52,727:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:52,735:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:53,063:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:56,964:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:50:59,479:INFO:Calculating mean and std
2023-03-19 17:50:59,489:INFO:Creating metrics dataframe
2023-03-19 17:51:00,145:INFO:Uploading results into container
2023-03-19 17:51:00,145:INFO:Uploading model into container now
2023-03-19 17:51:00,150:INFO:_master_model_container: 12
2023-03-19 17:51:00,151:INFO:_display_container: 2
2023-03-19 17:51:00,151:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8146, verbose=0, warm_start=False)
2023-03-19 17:51:00,152:INFO:create_model() successfully completed......................................
2023-03-19 17:51:00,273:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:00,274:INFO:Creating metrics dataframe
2023-03-19 17:51:00,290:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:51:00,290:INFO:Total runtime is 1.5624250968297322 minutes
2023-03-19 17:51:00,293:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:00,294:INFO:Initializing create_model()
2023-03-19 17:51:00,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:00,294:INFO:Checking exceptions
2023-03-19 17:51:00,294:INFO:Importing libraries
2023-03-19 17:51:00,294:INFO:Copying training dataset
2023-03-19 17:51:00,311:INFO:Defining folds
2023-03-19 17:51:00,311:INFO:Declaring metric variables
2023-03-19 17:51:00,317:INFO:Importing untrained model
2023-03-19 17:51:00,323:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:51:00,332:INFO:Starting cross validation
2023-03-19 17:51:00,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:51:06,793:INFO:Calculating mean and std
2023-03-19 17:51:06,793:INFO:Creating metrics dataframe
2023-03-19 17:51:07,449:INFO:Uploading results into container
2023-03-19 17:51:07,449:INFO:Uploading model into container now
2023-03-19 17:51:07,449:INFO:_master_model_container: 13
2023-03-19 17:51:07,449:INFO:_display_container: 2
2023-03-19 17:51:07,449:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8146, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:51:07,449:INFO:create_model() successfully completed......................................
2023-03-19 17:51:07,571:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:07,571:INFO:Creating metrics dataframe
2023-03-19 17:51:07,571:INFO:Initializing Dummy Classifier
2023-03-19 17:51:07,586:INFO:Total runtime is 1.6840329885482788 minutes
2023-03-19 17:51:07,596:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:07,596:INFO:Initializing create_model()
2023-03-19 17:51:07,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001715FB1AE00>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:07,596:INFO:Checking exceptions
2023-03-19 17:51:07,596:INFO:Importing libraries
2023-03-19 17:51:07,596:INFO:Copying training dataset
2023-03-19 17:51:07,601:INFO:Defining folds
2023-03-19 17:51:07,601:INFO:Declaring metric variables
2023-03-19 17:51:07,617:INFO:Importing untrained model
2023-03-19 17:51:07,617:INFO:Dummy Classifier Imported successfully
2023-03-19 17:51:07,633:INFO:Starting cross validation
2023-03-19 17:51:07,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:51:08,521:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,528:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,561:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,579:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,579:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,610:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,610:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:08,639:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:09,885:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:09,943:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:51:12,538:INFO:Calculating mean and std
2023-03-19 17:51:12,538:INFO:Creating metrics dataframe
2023-03-19 17:51:13,107:INFO:Uploading results into container
2023-03-19 17:51:13,107:INFO:Uploading model into container now
2023-03-19 17:51:13,107:INFO:_master_model_container: 14
2023-03-19 17:51:13,107:INFO:_display_container: 2
2023-03-19 17:51:13,107:INFO:DummyClassifier(constant=None, random_state=8146, strategy='prior')
2023-03-19 17:51:13,107:INFO:create_model() successfully completed......................................
2023-03-19 17:51:13,207:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:13,207:INFO:Creating metrics dataframe
2023-03-19 17:51:13,233:INFO:Initializing create_model()
2023-03-19 17:51:13,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:13,233:INFO:Checking exceptions
2023-03-19 17:51:13,233:INFO:Importing libraries
2023-03-19 17:51:13,233:INFO:Copying training dataset
2023-03-19 17:51:13,264:INFO:Defining folds
2023-03-19 17:51:13,264:INFO:Declaring metric variables
2023-03-19 17:51:13,264:INFO:Importing untrained model
2023-03-19 17:51:13,264:INFO:Declaring custom model
2023-03-19 17:51:13,264:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:51:13,264:INFO:Cross validation set to False
2023-03-19 17:51:13,264:INFO:Fitting Model
2023-03-19 17:51:14,590:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:51:14,590:INFO:create_model() successfully completed......................................
2023-03-19 17:51:14,707:INFO:Creating Dashboard logs
2023-03-19 17:51:14,711:INFO:Model: Linear Discriminant Analysis
2023-03-19 17:51:14,772:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:51:14,875:INFO:Initializing predict_model()
2023-03-19 17:51:14,875:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001715FD341C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000017160DB3A30>)
2023-03-19 17:51:14,875:INFO:Checking exceptions
2023-03-19 17:51:14,875:INFO:Preloading libraries
2023-03-19 17:51:15,778:INFO:Creating Dashboard logs
2023-03-19 17:51:15,783:INFO:Model: Ridge Classifier
2023-03-19 17:51:15,850:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8146, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 17:51:16,588:INFO:Creating Dashboard logs
2023-03-19 17:51:16,604:INFO:Model: Extra Trees Classifier
2023-03-19 17:51:16,683:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8146, 'verbose': 0, 'warm_start': False}
2023-03-19 17:51:17,392:INFO:Creating Dashboard logs
2023-03-19 17:51:17,399:INFO:Model: Logistic Regression
2023-03-19 17:51:17,473:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8146, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 17:51:18,181:INFO:Creating Dashboard logs
2023-03-19 17:51:18,189:INFO:Model: Naive Bayes
2023-03-19 17:51:18,271:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 17:51:18,923:INFO:Creating Dashboard logs
2023-03-19 17:51:18,929:INFO:Model: Random Forest Classifier
2023-03-19 17:51:18,982:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8146, 'verbose': 0, 'warm_start': False}
2023-03-19 17:51:19,690:INFO:Creating Dashboard logs
2023-03-19 17:51:19,696:INFO:Model: K Neighbors Classifier
2023-03-19 17:51:19,748:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 17:51:20,529:INFO:Creating Dashboard logs
2023-03-19 17:51:20,529:INFO:Model: str
2023-03-19 17:51:20,610:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8146}
2023-03-19 17:51:21,355:INFO:Creating Dashboard logs
2023-03-19 17:51:21,364:INFO:Model: Dummy Classifier
2023-03-19 17:51:21,446:INFO:Logged params: {'constant': None, 'random_state': 8146, 'strategy': 'prior'}
2023-03-19 17:51:22,081:INFO:Creating Dashboard logs
2023-03-19 17:51:22,081:INFO:Model: Gradient Boosting Classifier
2023-03-19 17:51:22,161:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8146, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:51:22,853:INFO:Creating Dashboard logs
2023-03-19 17:51:22,856:INFO:Model: Decision Tree Classifier
2023-03-19 17:51:22,932:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 8146, 'splitter': 'best'}
2023-03-19 17:51:23,572:INFO:Creating Dashboard logs
2023-03-19 17:51:23,580:INFO:Model: Light Gradient Boosting Machine
2023-03-19 17:51:23,666:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8146, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 17:51:24,341:INFO:Creating Dashboard logs
2023-03-19 17:51:24,345:INFO:Model: SVM - Linear Kernel
2023-03-19 17:51:24,435:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 8146, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:51:25,182:INFO:Creating Dashboard logs
2023-03-19 17:51:25,186:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 17:51:25,253:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:51:26,005:INFO:_master_model_container: 14
2023-03-19 17:51:26,005:INFO:_display_container: 2
2023-03-19 17:51:26,006:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:51:26,006:INFO:compare_models() successfully completed......................................
2023-03-19 17:51:26,536:INFO:PyCaret ClassificationExperiment
2023-03-19 17:51:26,536:INFO:Logging name: adult-dataset
2023-03-19 17:51:26,536:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:51:26,536:INFO:version 3.0.0
2023-03-19 17:51:26,536:INFO:Initializing setup()
2023-03-19 17:51:26,537:INFO:self.USI: 71ef
2023-03-19 17:51:26,537:INFO:self._variable_keys: {'gpu_n_jobs_param', 'y_train', 'y', 'log_plots_param', 'n_jobs_param', 'X_train', 'fix_imbalance', '_ml_usecase', 'X_test', 'exp_name_log', '_available_plots', 'USI', 'pipeline', 'y_test', 'data', 'idx', 'gpu_param', 'is_multiclass', 'seed', 'target_param', 'memory', 'html_param', 'exp_id', 'X', 'fold_shuffle_param', 'fold_generator', 'fold_groups_param', 'logging_param'}
2023-03-19 17:51:26,537:INFO:Checking environment
2023-03-19 17:51:26,537:INFO:python_version: 3.10.0
2023-03-19 17:51:26,537:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:51:26,537:INFO:machine: AMD64
2023-03-19 17:51:26,537:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:51:26,543:INFO:Memory: svmem(total=16969424896, available=4383842304, percent=74.2, used=12585582592, free=4383842304)
2023-03-19 17:51:26,543:INFO:Physical Core: 4
2023-03-19 17:51:26,543:INFO:Logical Core: 8
2023-03-19 17:51:26,543:INFO:Checking libraries
2023-03-19 17:51:26,543:INFO:System:
2023-03-19 17:51:26,543:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:51:26,543:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:51:26,543:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:51:26,543:INFO:PyCaret required dependencies:
2023-03-19 17:51:26,543:INFO:                 pip: 23.0.1
2023-03-19 17:51:26,543:INFO:          setuptools: 65.6.3
2023-03-19 17:51:26,543:INFO:             pycaret: 3.0.0
2023-03-19 17:51:26,543:INFO:             IPython: 8.11.0
2023-03-19 17:51:26,543:INFO:          ipywidgets: 8.0.4
2023-03-19 17:51:26,543:INFO:                tqdm: 4.65.0
2023-03-19 17:51:26,543:INFO:               numpy: 1.23.5
2023-03-19 17:51:26,543:INFO:              pandas: 1.5.3
2023-03-19 17:51:26,543:INFO:              jinja2: 3.1.2
2023-03-19 17:51:26,543:INFO:               scipy: 1.10.1
2023-03-19 17:51:26,543:INFO:              joblib: 1.2.0
2023-03-19 17:51:26,543:INFO:             sklearn: 1.2.2
2023-03-19 17:51:26,543:INFO:                pyod: 1.0.8
2023-03-19 17:51:26,543:INFO:            imblearn: 0.10.1
2023-03-19 17:51:26,543:INFO:   category_encoders: 2.6.0
2023-03-19 17:51:26,543:INFO:            lightgbm: 3.3.5
2023-03-19 17:51:26,543:INFO:               numba: 0.56.4
2023-03-19 17:51:26,543:INFO:            requests: 2.28.2
2023-03-19 17:51:26,543:INFO:          matplotlib: 3.7.1
2023-03-19 17:51:26,543:INFO:          scikitplot: 0.3.7
2023-03-19 17:51:26,543:INFO:         yellowbrick: 1.5
2023-03-19 17:51:26,543:INFO:              plotly: 5.13.1
2023-03-19 17:51:26,543:INFO:             kaleido: 0.2.1
2023-03-19 17:51:26,543:INFO:         statsmodels: 0.13.5
2023-03-19 17:51:26,543:INFO:              sktime: 0.16.1
2023-03-19 17:51:26,543:INFO:               tbats: 1.1.2
2023-03-19 17:51:26,543:INFO:            pmdarima: 2.0.3
2023-03-19 17:51:26,543:INFO:              psutil: 5.9.4
2023-03-19 17:51:26,543:INFO:PyCaret optional dependencies:
2023-03-19 17:51:26,543:INFO:                shap: 0.41.0
2023-03-19 17:51:26,543:INFO:           interpret: Not installed
2023-03-19 17:51:26,543:INFO:                umap: Not installed
2023-03-19 17:51:26,543:INFO:    pandas_profiling: Not installed
2023-03-19 17:51:26,543:INFO:  explainerdashboard: Not installed
2023-03-19 17:51:26,543:INFO:             autoviz: Not installed
2023-03-19 17:51:26,543:INFO:           fairlearn: Not installed
2023-03-19 17:51:26,543:INFO:             xgboost: Not installed
2023-03-19 17:51:26,543:INFO:            catboost: Not installed
2023-03-19 17:51:26,543:INFO:              kmodes: Not installed
2023-03-19 17:51:26,543:INFO:             mlxtend: Not installed
2023-03-19 17:51:26,543:INFO:       statsforecast: Not installed
2023-03-19 17:51:26,543:INFO:        tune_sklearn: Not installed
2023-03-19 17:51:26,543:INFO:                 ray: Not installed
2023-03-19 17:51:26,543:INFO:            hyperopt: Not installed
2023-03-19 17:51:26,543:INFO:              optuna: Not installed
2023-03-19 17:51:26,543:INFO:               skopt: Not installed
2023-03-19 17:51:26,543:INFO:              mlflow: 2.2.2
2023-03-19 17:51:26,543:INFO:              gradio: Not installed
2023-03-19 17:51:26,543:INFO:             fastapi: Not installed
2023-03-19 17:51:26,543:INFO:             uvicorn: Not installed
2023-03-19 17:51:26,543:INFO:              m2cgen: Not installed
2023-03-19 17:51:26,543:INFO:           evidently: Not installed
2023-03-19 17:51:26,543:INFO:               fugue: Not installed
2023-03-19 17:51:26,543:INFO:           streamlit: Not installed
2023-03-19 17:51:26,543:INFO:             prophet: Not installed
2023-03-19 17:51:26,543:INFO:None
2023-03-19 17:51:26,543:INFO:Set up data.
2023-03-19 17:51:26,610:INFO:Set up train/test split.
2023-03-19 17:51:26,625:INFO:Set up index.
2023-03-19 17:51:26,625:INFO:Set up folding strategy.
2023-03-19 17:51:26,625:INFO:Assigning column types.
2023-03-19 17:51:26,642:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:51:26,725:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:51:26,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:51:26,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:26,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:26,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:51:26,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:51:26,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:26,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:26,868:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:51:26,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:51:26,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:26,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:51:27,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,094:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:51:27,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:27,319:INFO:Preparing preprocessing pipeline...
2023-03-19 17:51:27,321:INFO:Set up simple imputation.
2023-03-19 17:51:27,332:INFO:Set up encoding of ordinal features.
2023-03-19 17:51:27,336:INFO:Set up encoding of categorical features.
2023-03-19 17:51:27,336:INFO:Set up feature normalization.
2023-03-19 17:51:27,337:INFO:Set up column name cleaning.
2023-03-19 17:51:28,255:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:51:28,278:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=3509,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:51:28,279:INFO:Creating final display dataframe.
2023-03-19 17:51:29,179:INFO:Setup _display_container:                     Description            Value
0                    Session id             3509
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment     MlflowLogger
24              Experiment Name    adult-dataset
25                          USI             71ef
2023-03-19 17:51:29,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:29,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:29,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:29,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:51:29,407:INFO:Logging experiment in loggers
2023-03-19 17:51:29,531:INFO:SubProcess save_model() called ==================================
2023-03-19 17:51:29,579:INFO:Initializing save_model()
2023-03-19 17:51:29,579:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=3509,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmpj8fhqw6d\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=3509,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:51:29,579:INFO:Adding model into prep_pipe
2023-03-19 17:51:29,586:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:51:29,601:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmpj8fhqw6d\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:51:29,631:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=3509,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:51:29,631:INFO:save_model() successfully completed......................................
2023-03-19 17:51:30,136:INFO:SubProcess save_model() end ==================================
2023-03-19 17:51:30,191:INFO:setup() successfully completed in 3.29s...............
2023-03-19 17:51:30,239:INFO:Initializing compare_models()
2023-03-19 17:51:30,239:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:51:30,239:INFO:Checking exceptions
2023-03-19 17:51:30,256:INFO:Preparing display monitor
2023-03-19 17:51:30,290:INFO:Initializing Logistic Regression
2023-03-19 17:51:30,290:INFO:Total runtime is 0.0 minutes
2023-03-19 17:51:30,290:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:30,290:INFO:Initializing create_model()
2023-03-19 17:51:30,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:30,290:INFO:Checking exceptions
2023-03-19 17:51:30,290:INFO:Importing libraries
2023-03-19 17:51:30,290:INFO:Copying training dataset
2023-03-19 17:51:30,322:INFO:Defining folds
2023-03-19 17:51:30,322:INFO:Declaring metric variables
2023-03-19 17:51:30,326:INFO:Importing untrained model
2023-03-19 17:51:30,329:INFO:Logistic Regression Imported successfully
2023-03-19 17:51:30,339:INFO:Starting cross validation
2023-03-19 17:51:30,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:51:37,367:INFO:Calculating mean and std
2023-03-19 17:51:37,367:INFO:Creating metrics dataframe
2023-03-19 17:51:38,007:INFO:Uploading results into container
2023-03-19 17:51:38,008:INFO:Uploading model into container now
2023-03-19 17:51:38,008:INFO:_master_model_container: 1
2023-03-19 17:51:38,009:INFO:_display_container: 2
2023-03-19 17:51:38,009:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3509, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:51:38,009:INFO:create_model() successfully completed......................................
2023-03-19 17:51:38,136:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:38,137:INFO:Creating metrics dataframe
2023-03-19 17:51:38,156:INFO:Initializing K Neighbors Classifier
2023-03-19 17:51:38,156:INFO:Total runtime is 0.13111239274342854 minutes
2023-03-19 17:51:38,160:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:38,160:INFO:Initializing create_model()
2023-03-19 17:51:38,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:38,161:INFO:Checking exceptions
2023-03-19 17:51:38,161:INFO:Importing libraries
2023-03-19 17:51:38,161:INFO:Copying training dataset
2023-03-19 17:51:38,178:INFO:Defining folds
2023-03-19 17:51:38,179:INFO:Declaring metric variables
2023-03-19 17:51:38,187:INFO:Importing untrained model
2023-03-19 17:51:38,193:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:51:38,205:INFO:Starting cross validation
2023-03-19 17:51:38,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:51:45,367:INFO:Calculating mean and std
2023-03-19 17:51:45,375:INFO:Creating metrics dataframe
2023-03-19 17:51:45,957:INFO:Uploading results into container
2023-03-19 17:51:45,958:INFO:Uploading model into container now
2023-03-19 17:51:45,958:INFO:_master_model_container: 2
2023-03-19 17:51:45,959:INFO:_display_container: 2
2023-03-19 17:51:45,959:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:51:45,959:INFO:create_model() successfully completed......................................
2023-03-19 17:51:46,083:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:46,083:INFO:Creating metrics dataframe
2023-03-19 17:51:46,097:INFO:Initializing Naive Bayes
2023-03-19 17:51:46,097:INFO:Total runtime is 0.2634544730186462 minutes
2023-03-19 17:51:46,101:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:46,101:INFO:Initializing create_model()
2023-03-19 17:51:46,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:46,101:INFO:Checking exceptions
2023-03-19 17:51:46,101:INFO:Importing libraries
2023-03-19 17:51:46,101:INFO:Copying training dataset
2023-03-19 17:51:46,119:INFO:Defining folds
2023-03-19 17:51:46,119:INFO:Declaring metric variables
2023-03-19 17:51:46,125:INFO:Importing untrained model
2023-03-19 17:51:46,131:INFO:Naive Bayes Imported successfully
2023-03-19 17:51:46,141:INFO:Starting cross validation
2023-03-19 17:51:46,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:51:51,912:INFO:Calculating mean and std
2023-03-19 17:51:51,927:INFO:Creating metrics dataframe
2023-03-19 17:51:52,654:INFO:Uploading results into container
2023-03-19 17:51:52,654:INFO:Uploading model into container now
2023-03-19 17:51:52,659:INFO:_master_model_container: 3
2023-03-19 17:51:52,659:INFO:_display_container: 2
2023-03-19 17:51:52,659:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:51:52,659:INFO:create_model() successfully completed......................................
2023-03-19 17:51:52,782:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:52,782:INFO:Creating metrics dataframe
2023-03-19 17:51:52,807:INFO:Initializing Decision Tree Classifier
2023-03-19 17:51:52,807:INFO:Total runtime is 0.3752845724423726 minutes
2023-03-19 17:51:52,813:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:52,814:INFO:Initializing create_model()
2023-03-19 17:51:52,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:52,814:INFO:Checking exceptions
2023-03-19 17:51:52,815:INFO:Importing libraries
2023-03-19 17:51:52,815:INFO:Copying training dataset
2023-03-19 17:51:52,828:INFO:Defining folds
2023-03-19 17:51:52,828:INFO:Declaring metric variables
2023-03-19 17:51:52,832:INFO:Importing untrained model
2023-03-19 17:51:52,848:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:51:52,855:INFO:Starting cross validation
2023-03-19 17:51:52,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:51:58,727:INFO:Calculating mean and std
2023-03-19 17:51:58,741:INFO:Creating metrics dataframe
2023-03-19 17:51:59,623:INFO:Uploading results into container
2023-03-19 17:51:59,623:INFO:Uploading model into container now
2023-03-19 17:51:59,623:INFO:_master_model_container: 4
2023-03-19 17:51:59,623:INFO:_display_container: 2
2023-03-19 17:51:59,623:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3509, splitter='best')
2023-03-19 17:51:59,623:INFO:create_model() successfully completed......................................
2023-03-19 17:51:59,742:INFO:SubProcess create_model() end ==================================
2023-03-19 17:51:59,742:INFO:Creating metrics dataframe
2023-03-19 17:51:59,776:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:51:59,776:INFO:Total runtime is 0.49143170515696205 minutes
2023-03-19 17:51:59,793:INFO:SubProcess create_model() called ==================================
2023-03-19 17:51:59,793:INFO:Initializing create_model()
2023-03-19 17:51:59,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:51:59,793:INFO:Checking exceptions
2023-03-19 17:51:59,793:INFO:Importing libraries
2023-03-19 17:51:59,793:INFO:Copying training dataset
2023-03-19 17:51:59,793:INFO:Defining folds
2023-03-19 17:51:59,807:INFO:Declaring metric variables
2023-03-19 17:51:59,813:INFO:Importing untrained model
2023-03-19 17:51:59,817:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:51:59,826:INFO:Starting cross validation
2023-03-19 17:51:59,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:52:01,742:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:01,756:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:01,812:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:01,919:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:01,919:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:01,934:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:01,950:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:02,098:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:03,956:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:03,972:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:52:06,542:INFO:Calculating mean and std
2023-03-19 17:52:06,542:INFO:Creating metrics dataframe
2023-03-19 17:52:07,145:INFO:Uploading results into container
2023-03-19 17:52:07,145:INFO:Uploading model into container now
2023-03-19 17:52:07,145:INFO:_master_model_container: 5
2023-03-19 17:52:07,145:INFO:_display_container: 2
2023-03-19 17:52:07,145:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3509, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:52:07,145:INFO:create_model() successfully completed......................................
2023-03-19 17:52:07,272:INFO:SubProcess create_model() end ==================================
2023-03-19 17:52:07,272:INFO:Creating metrics dataframe
2023-03-19 17:52:07,303:INFO:Initializing Ridge Classifier
2023-03-19 17:52:07,303:INFO:Total runtime is 0.6168903509775797 minutes
2023-03-19 17:52:07,319:INFO:SubProcess create_model() called ==================================
2023-03-19 17:52:07,319:INFO:Initializing create_model()
2023-03-19 17:52:07,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:52:07,319:INFO:Checking exceptions
2023-03-19 17:52:07,319:INFO:Importing libraries
2023-03-19 17:52:07,319:INFO:Copying training dataset
2023-03-19 17:52:07,352:INFO:Defining folds
2023-03-19 17:52:07,352:INFO:Declaring metric variables
2023-03-19 17:52:07,368:INFO:Importing untrained model
2023-03-19 17:52:07,372:INFO:Ridge Classifier Imported successfully
2023-03-19 17:52:07,385:INFO:Starting cross validation
2023-03-19 17:52:07,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:52:08,600:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,774:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,774:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,774:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,774:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,801:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,810:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:08,960:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:10,370:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:10,408:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:52:13,340:INFO:Calculating mean and std
2023-03-19 17:52:13,340:INFO:Creating metrics dataframe
2023-03-19 17:52:14,116:INFO:Uploading results into container
2023-03-19 17:52:14,116:INFO:Uploading model into container now
2023-03-19 17:52:14,116:INFO:_master_model_container: 6
2023-03-19 17:52:14,116:INFO:_display_container: 2
2023-03-19 17:52:14,116:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3509, solver='auto',
                tol=0.0001)
2023-03-19 17:52:14,116:INFO:create_model() successfully completed......................................
2023-03-19 17:52:14,243:INFO:SubProcess create_model() end ==================================
2023-03-19 17:52:14,243:INFO:Creating metrics dataframe
2023-03-19 17:52:14,259:INFO:Initializing Random Forest Classifier
2023-03-19 17:52:14,259:INFO:Total runtime is 0.7328178604443868 minutes
2023-03-19 17:52:14,259:INFO:SubProcess create_model() called ==================================
2023-03-19 17:52:14,259:INFO:Initializing create_model()
2023-03-19 17:52:14,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:52:14,259:INFO:Checking exceptions
2023-03-19 17:52:14,259:INFO:Importing libraries
2023-03-19 17:52:14,259:INFO:Copying training dataset
2023-03-19 17:52:14,280:INFO:Defining folds
2023-03-19 17:52:14,280:INFO:Declaring metric variables
2023-03-19 17:52:14,291:INFO:Importing untrained model
2023-03-19 17:52:14,291:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:52:14,306:INFO:Starting cross validation
2023-03-19 17:52:14,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:52:15,505:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:52:16,318:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-19 17:52:17,321:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:52:17,631:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:52:17,692:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:52:17,866:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:52:18,409:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:52:18,411:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:52:18,552:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:52:18,730:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:52:26,139:INFO:Calculating mean and std
2023-03-19 17:52:26,144:INFO:Creating metrics dataframe
2023-03-19 17:52:26,916:INFO:Uploading results into container
2023-03-19 17:52:26,916:INFO:Uploading model into container now
2023-03-19 17:52:26,916:INFO:_master_model_container: 7
2023-03-19 17:52:26,916:INFO:_display_container: 2
2023-03-19 17:52:26,916:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3509, verbose=0, warm_start=False)
2023-03-19 17:52:26,916:INFO:create_model() successfully completed......................................
2023-03-19 17:52:27,034:INFO:SubProcess create_model() end ==================================
2023-03-19 17:52:27,034:INFO:Creating metrics dataframe
2023-03-19 17:52:27,065:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:52:27,066:INFO:Total runtime is 0.9462738513946534 minutes
2023-03-19 17:52:27,074:INFO:SubProcess create_model() called ==================================
2023-03-19 17:52:27,074:INFO:Initializing create_model()
2023-03-19 17:52:27,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:52:27,074:INFO:Checking exceptions
2023-03-19 17:52:27,074:INFO:Importing libraries
2023-03-19 17:52:27,074:INFO:Copying training dataset
2023-03-19 17:52:27,096:INFO:Defining folds
2023-03-19 17:52:27,096:INFO:Declaring metric variables
2023-03-19 17:52:27,105:INFO:Importing untrained model
2023-03-19 17:52:27,112:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:52:27,132:INFO:Starting cross validation
2023-03-19 17:52:27,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:52:28,145:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,271:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,344:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,359:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,364:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,374:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,428:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:28,684:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:30,896:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:30,912:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:52:34,571:INFO:Calculating mean and std
2023-03-19 17:52:34,571:INFO:Creating metrics dataframe
2023-03-19 17:52:35,386:INFO:Uploading results into container
2023-03-19 17:52:35,386:INFO:Uploading model into container now
2023-03-19 17:52:35,386:INFO:_master_model_container: 8
2023-03-19 17:52:35,386:INFO:_display_container: 2
2023-03-19 17:52:35,386:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:52:35,386:INFO:create_model() successfully completed......................................
2023-03-19 17:52:35,497:INFO:SubProcess create_model() end ==================================
2023-03-19 17:52:35,497:INFO:Creating metrics dataframe
2023-03-19 17:52:35,517:INFO:Initializing Ada Boost Classifier
2023-03-19 17:52:35,517:INFO:Total runtime is 1.087129275004069 minutes
2023-03-19 17:52:35,525:INFO:SubProcess create_model() called ==================================
2023-03-19 17:52:35,526:INFO:Initializing create_model()
2023-03-19 17:52:35,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:52:35,526:INFO:Checking exceptions
2023-03-19 17:52:35,526:INFO:Importing libraries
2023-03-19 17:52:35,526:INFO:Copying training dataset
2023-03-19 17:52:35,540:INFO:Defining folds
2023-03-19 17:52:35,540:INFO:Declaring metric variables
2023-03-19 17:52:35,540:INFO:Importing untrained model
2023-03-19 17:52:35,557:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:52:35,572:INFO:Starting cross validation
2023-03-19 17:52:35,572:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:52:44,402:INFO:Calculating mean and std
2023-03-19 17:52:44,403:INFO:Creating metrics dataframe
2023-03-19 17:52:44,804:INFO:Uploading results into container
2023-03-19 17:52:44,805:INFO:Uploading model into container now
2023-03-19 17:52:44,805:INFO:_master_model_container: 9
2023-03-19 17:52:44,805:INFO:_display_container: 2
2023-03-19 17:52:44,806:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3509)
2023-03-19 17:52:44,806:INFO:create_model() successfully completed......................................
2023-03-19 17:52:44,893:INFO:SubProcess create_model() end ==================================
2023-03-19 17:52:44,893:INFO:Creating metrics dataframe
2023-03-19 17:52:44,910:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:52:44,910:INFO:Total runtime is 1.2436671058336894 minutes
2023-03-19 17:52:44,914:INFO:SubProcess create_model() called ==================================
2023-03-19 17:52:44,914:INFO:Initializing create_model()
2023-03-19 17:52:44,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017160675D80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000171603935E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:52:44,915:INFO:Checking exceptions
2023-03-19 17:52:44,915:INFO:Importing libraries
2023-03-19 17:52:44,915:INFO:Copying training dataset
2023-03-19 17:52:44,926:INFO:Defining folds
2023-03-19 17:52:44,926:INFO:Declaring metric variables
2023-03-19 17:52:44,930:INFO:Importing untrained model
2023-03-19 17:52:44,935:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:52:44,942:INFO:Starting cross validation
2023-03-19 17:52:44,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:52:55,176:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:53:14,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:53:14,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:53:14,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:53:14,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:53:15,426:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-19 17:53:18,681:INFO:PyCaret ClassificationExperiment
2023-03-19 17:53:18,681:INFO:Logging name: adult
2023-03-19 17:53:18,681:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:53:18,681:INFO:version 3.0.0
2023-03-19 17:53:18,681:INFO:Initializing setup()
2023-03-19 17:53:18,681:INFO:self.USI: 7030
2023-03-19 17:53:18,681:INFO:self._variable_keys: {'gpu_param', 'gpu_n_jobs_param', 'fold_generator', 'y_train', 'seed', 'logging_param', 'X', 'exp_id', 'exp_name_log', '_ml_usecase', 'fold_groups_param', 'y_test', 'n_jobs_param', '_available_plots', 'X_train', 'memory', 'fold_shuffle_param', 'target_param', 'is_multiclass', 'y', 'html_param', 'log_plots_param', 'pipeline', 'USI', 'X_test', 'data', 'fix_imbalance', 'idx'}
2023-03-19 17:53:18,681:INFO:Checking environment
2023-03-19 17:53:18,681:INFO:python_version: 3.10.0
2023-03-19 17:53:18,681:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:53:18,681:INFO:machine: AMD64
2023-03-19 17:53:18,681:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:53:18,689:INFO:Memory: svmem(total=16969424896, available=5672620032, percent=66.6, used=11296804864, free=5672620032)
2023-03-19 17:53:18,689:INFO:Physical Core: 4
2023-03-19 17:53:18,689:INFO:Logical Core: 8
2023-03-19 17:53:18,689:INFO:Checking libraries
2023-03-19 17:53:18,689:INFO:System:
2023-03-19 17:53:18,689:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:53:18,689:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:53:18,689:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:53:18,689:INFO:PyCaret required dependencies:
2023-03-19 17:53:18,689:INFO:                 pip: 23.0.1
2023-03-19 17:53:18,689:INFO:          setuptools: 65.6.3
2023-03-19 17:53:18,689:INFO:             pycaret: 3.0.0
2023-03-19 17:53:18,689:INFO:             IPython: 8.11.0
2023-03-19 17:53:18,689:INFO:          ipywidgets: 8.0.4
2023-03-19 17:53:18,689:INFO:                tqdm: 4.65.0
2023-03-19 17:53:18,689:INFO:               numpy: 1.23.5
2023-03-19 17:53:18,689:INFO:              pandas: 1.5.3
2023-03-19 17:53:18,689:INFO:              jinja2: 3.1.2
2023-03-19 17:53:18,689:INFO:               scipy: 1.10.1
2023-03-19 17:53:18,689:INFO:              joblib: 1.2.0
2023-03-19 17:53:18,690:INFO:             sklearn: 1.2.2
2023-03-19 17:53:18,690:INFO:                pyod: 1.0.8
2023-03-19 17:53:18,690:INFO:            imblearn: 0.10.1
2023-03-19 17:53:18,690:INFO:   category_encoders: 2.6.0
2023-03-19 17:53:18,690:INFO:            lightgbm: 3.3.5
2023-03-19 17:53:18,690:INFO:               numba: 0.56.4
2023-03-19 17:53:18,690:INFO:            requests: 2.28.2
2023-03-19 17:53:18,690:INFO:          matplotlib: 3.7.1
2023-03-19 17:53:18,690:INFO:          scikitplot: 0.3.7
2023-03-19 17:53:18,690:INFO:         yellowbrick: 1.5
2023-03-19 17:53:18,690:INFO:              plotly: 5.13.1
2023-03-19 17:53:18,690:INFO:             kaleido: 0.2.1
2023-03-19 17:53:18,690:INFO:         statsmodels: 0.13.5
2023-03-19 17:53:18,690:INFO:              sktime: 0.16.1
2023-03-19 17:53:18,690:INFO:               tbats: 1.1.2
2023-03-19 17:53:18,690:INFO:            pmdarima: 2.0.3
2023-03-19 17:53:18,690:INFO:              psutil: 5.9.4
2023-03-19 17:53:18,690:INFO:PyCaret optional dependencies:
2023-03-19 17:53:18,701:INFO:                shap: 0.41.0
2023-03-19 17:53:18,701:INFO:           interpret: Not installed
2023-03-19 17:53:18,701:INFO:                umap: Not installed
2023-03-19 17:53:18,701:INFO:    pandas_profiling: Not installed
2023-03-19 17:53:18,701:INFO:  explainerdashboard: Not installed
2023-03-19 17:53:18,702:INFO:             autoviz: Not installed
2023-03-19 17:53:18,702:INFO:           fairlearn: Not installed
2023-03-19 17:53:18,702:INFO:             xgboost: Not installed
2023-03-19 17:53:18,702:INFO:            catboost: Not installed
2023-03-19 17:53:18,702:INFO:              kmodes: Not installed
2023-03-19 17:53:18,702:INFO:             mlxtend: Not installed
2023-03-19 17:53:18,702:INFO:       statsforecast: Not installed
2023-03-19 17:53:18,702:INFO:        tune_sklearn: Not installed
2023-03-19 17:53:18,702:INFO:                 ray: Not installed
2023-03-19 17:53:18,702:INFO:            hyperopt: Not installed
2023-03-19 17:53:18,702:INFO:              optuna: Not installed
2023-03-19 17:53:18,702:INFO:               skopt: Not installed
2023-03-19 17:53:18,702:INFO:              mlflow: 2.2.2
2023-03-19 17:53:18,702:INFO:              gradio: Not installed
2023-03-19 17:53:18,702:INFO:             fastapi: Not installed
2023-03-19 17:53:18,702:INFO:             uvicorn: Not installed
2023-03-19 17:53:18,702:INFO:              m2cgen: Not installed
2023-03-19 17:53:18,702:INFO:           evidently: Not installed
2023-03-19 17:53:18,702:INFO:               fugue: Not installed
2023-03-19 17:53:18,702:INFO:           streamlit: Not installed
2023-03-19 17:53:18,702:INFO:             prophet: Not installed
2023-03-19 17:53:18,702:INFO:None
2023-03-19 17:53:18,702:INFO:Set up data.
2023-03-19 17:53:18,738:INFO:Set up train/test split.
2023-03-19 17:53:18,752:INFO:Set up index.
2023-03-19 17:53:18,752:INFO:Set up folding strategy.
2023-03-19 17:53:18,752:INFO:Assigning column types.
2023-03-19 17:53:18,756:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:53:18,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:53:18,807:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:53:18,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:18,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:18,905:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:53:18,905:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:53:18,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:18,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:18,932:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:53:18,973:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:53:18,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:18,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:53:19,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,062:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:53:19,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:19,190:INFO:Preparing preprocessing pipeline...
2023-03-19 17:53:19,191:INFO:Set up simple imputation.
2023-03-19 17:53:19,196:INFO:Set up encoding of ordinal features.
2023-03-19 17:53:19,196:INFO:Set up encoding of categorical features.
2023-03-19 17:53:19,198:INFO:Set up column name cleaning.
2023-03-19 17:53:19,805:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:53:19,826:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=3738,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:53:19,826:INFO:Creating final display dataframe.
2023-03-19 17:53:20,352:INFO:Setup _display_container:                     Description            Value
0                    Session id             3738
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name            adult
23                          USI             7030
2023-03-19 17:53:20,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:20,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:20,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:20,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:53:20,499:INFO:Logging experiment in loggers
2023-03-19 17:53:20,806:INFO:SubProcess save_model() called ==================================
2023-03-19 17:53:20,839:INFO:Initializing save_model()
2023-03-19 17:53:20,839:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=3738,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmp9vy4c0fc\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=3738,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:53:20,839:INFO:Adding model into prep_pipe
2023-03-19 17:53:20,841:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:53:20,852:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmp9vy4c0fc\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:53:20,872:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=3738,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:53:20,872:INFO:save_model() successfully completed......................................
2023-03-19 17:53:21,246:INFO:SubProcess save_model() end ==================================
2023-03-19 17:53:21,294:INFO:setup() successfully completed in 2.18s...............
2023-03-19 17:53:21,330:INFO:Initializing compare_models()
2023-03-19 17:53:21,330:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:53:21,331:INFO:Checking exceptions
2023-03-19 17:53:21,339:INFO:Preparing display monitor
2023-03-19 17:53:21,372:INFO:Initializing Logistic Regression
2023-03-19 17:53:21,372:INFO:Total runtime is 1.665353775024414e-05 minutes
2023-03-19 17:53:21,375:INFO:SubProcess create_model() called ==================================
2023-03-19 17:53:21,376:INFO:Initializing create_model()
2023-03-19 17:53:21,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:53:21,376:INFO:Checking exceptions
2023-03-19 17:53:21,376:INFO:Importing libraries
2023-03-19 17:53:21,376:INFO:Copying training dataset
2023-03-19 17:53:21,390:INFO:Defining folds
2023-03-19 17:53:21,390:INFO:Declaring metric variables
2023-03-19 17:53:21,396:INFO:Importing untrained model
2023-03-19 17:53:21,400:INFO:Logistic Regression Imported successfully
2023-03-19 17:53:21,409:INFO:Starting cross validation
2023-03-19 17:53:21,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:53:34,359:INFO:Calculating mean and std
2023-03-19 17:53:34,360:INFO:Creating metrics dataframe
2023-03-19 17:53:34,751:INFO:Uploading results into container
2023-03-19 17:53:34,752:INFO:Uploading model into container now
2023-03-19 17:53:34,752:INFO:_master_model_container: 1
2023-03-19 17:53:34,752:INFO:_display_container: 2
2023-03-19 17:53:34,753:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3738, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:53:34,753:INFO:create_model() successfully completed......................................
2023-03-19 17:53:34,823:INFO:SubProcess create_model() end ==================================
2023-03-19 17:53:34,824:INFO:Creating metrics dataframe
2023-03-19 17:53:34,833:INFO:Initializing K Neighbors Classifier
2023-03-19 17:53:34,833:INFO:Total runtime is 0.22437501748402913 minutes
2023-03-19 17:53:34,838:INFO:SubProcess create_model() called ==================================
2023-03-19 17:53:34,838:INFO:Initializing create_model()
2023-03-19 17:53:34,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:53:34,839:INFO:Checking exceptions
2023-03-19 17:53:34,839:INFO:Importing libraries
2023-03-19 17:53:34,839:INFO:Copying training dataset
2023-03-19 17:53:34,848:INFO:Defining folds
2023-03-19 17:53:34,848:INFO:Declaring metric variables
2023-03-19 17:53:34,851:INFO:Importing untrained model
2023-03-19 17:53:34,855:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:53:34,863:INFO:Starting cross validation
2023-03-19 17:53:34,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:53:42,375:INFO:Calculating mean and std
2023-03-19 17:53:42,375:INFO:Creating metrics dataframe
2023-03-19 17:53:42,768:INFO:Uploading results into container
2023-03-19 17:53:42,769:INFO:Uploading model into container now
2023-03-19 17:53:42,770:INFO:_master_model_container: 2
2023-03-19 17:53:42,770:INFO:_display_container: 2
2023-03-19 17:53:42,770:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:53:42,770:INFO:create_model() successfully completed......................................
2023-03-19 17:53:42,846:INFO:SubProcess create_model() end ==================================
2023-03-19 17:53:42,846:INFO:Creating metrics dataframe
2023-03-19 17:53:42,854:INFO:Initializing Naive Bayes
2023-03-19 17:53:42,854:INFO:Total runtime is 0.3580556035041809 minutes
2023-03-19 17:53:42,860:INFO:SubProcess create_model() called ==================================
2023-03-19 17:53:42,861:INFO:Initializing create_model()
2023-03-19 17:53:42,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:53:42,861:INFO:Checking exceptions
2023-03-19 17:53:42,861:INFO:Importing libraries
2023-03-19 17:53:42,862:INFO:Copying training dataset
2023-03-19 17:53:42,870:INFO:Defining folds
2023-03-19 17:53:42,870:INFO:Declaring metric variables
2023-03-19 17:53:42,874:INFO:Importing untrained model
2023-03-19 17:53:42,879:INFO:Naive Bayes Imported successfully
2023-03-19 17:53:42,887:INFO:Starting cross validation
2023-03-19 17:53:42,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:53:48,767:INFO:Calculating mean and std
2023-03-19 17:53:48,769:INFO:Creating metrics dataframe
2023-03-19 17:53:49,200:INFO:Uploading results into container
2023-03-19 17:53:49,201:INFO:Uploading model into container now
2023-03-19 17:53:49,202:INFO:_master_model_container: 3
2023-03-19 17:53:49,202:INFO:_display_container: 2
2023-03-19 17:53:49,202:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:53:49,202:INFO:create_model() successfully completed......................................
2023-03-19 17:53:49,304:INFO:SubProcess create_model() end ==================================
2023-03-19 17:53:49,304:INFO:Creating metrics dataframe
2023-03-19 17:53:49,321:INFO:Initializing Decision Tree Classifier
2023-03-19 17:53:49,321:INFO:Total runtime is 0.46583348512649536 minutes
2023-03-19 17:53:49,327:INFO:SubProcess create_model() called ==================================
2023-03-19 17:53:49,327:INFO:Initializing create_model()
2023-03-19 17:53:49,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:53:49,327:INFO:Checking exceptions
2023-03-19 17:53:49,327:INFO:Importing libraries
2023-03-19 17:53:49,328:INFO:Copying training dataset
2023-03-19 17:53:49,346:INFO:Defining folds
2023-03-19 17:53:49,346:INFO:Declaring metric variables
2023-03-19 17:53:49,350:INFO:Importing untrained model
2023-03-19 17:53:49,359:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:53:49,368:INFO:Starting cross validation
2023-03-19 17:53:49,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:53:57,217:INFO:Calculating mean and std
2023-03-19 17:53:57,218:INFO:Creating metrics dataframe
2023-03-19 17:53:57,982:INFO:Uploading results into container
2023-03-19 17:53:57,983:INFO:Uploading model into container now
2023-03-19 17:53:57,983:INFO:_master_model_container: 4
2023-03-19 17:53:57,983:INFO:_display_container: 2
2023-03-19 17:53:57,983:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3738, splitter='best')
2023-03-19 17:53:57,983:INFO:create_model() successfully completed......................................
2023-03-19 17:53:58,080:INFO:SubProcess create_model() end ==================================
2023-03-19 17:53:58,081:INFO:Creating metrics dataframe
2023-03-19 17:53:58,104:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:53:58,104:INFO:Total runtime is 0.6122188846270243 minutes
2023-03-19 17:53:58,112:INFO:SubProcess create_model() called ==================================
2023-03-19 17:53:58,112:INFO:Initializing create_model()
2023-03-19 17:53:58,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:53:58,113:INFO:Checking exceptions
2023-03-19 17:53:58,113:INFO:Importing libraries
2023-03-19 17:53:58,113:INFO:Copying training dataset
2023-03-19 17:53:58,131:INFO:Defining folds
2023-03-19 17:53:58,131:INFO:Declaring metric variables
2023-03-19 17:53:58,137:INFO:Importing untrained model
2023-03-19 17:53:58,141:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:53:58,153:INFO:Starting cross validation
2023-03-19 17:53:58,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:54:01,391:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:01,452:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:01,497:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:01,653:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:01,797:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:01,797:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:02,191:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:02,355:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:04,389:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:05,008:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:54:07,748:INFO:Calculating mean and std
2023-03-19 17:54:07,748:INFO:Creating metrics dataframe
2023-03-19 17:54:08,543:INFO:Uploading results into container
2023-03-19 17:54:08,543:INFO:Uploading model into container now
2023-03-19 17:54:08,543:INFO:_master_model_container: 5
2023-03-19 17:54:08,543:INFO:_display_container: 2
2023-03-19 17:54:08,543:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3738, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:54:08,543:INFO:create_model() successfully completed......................................
2023-03-19 17:54:08,638:INFO:SubProcess create_model() end ==================================
2023-03-19 17:54:08,638:INFO:Creating metrics dataframe
2023-03-19 17:54:08,653:INFO:Initializing Ridge Classifier
2023-03-19 17:54:08,653:INFO:Total runtime is 0.7880421876907349 minutes
2023-03-19 17:54:08,674:INFO:SubProcess create_model() called ==================================
2023-03-19 17:54:08,674:INFO:Initializing create_model()
2023-03-19 17:54:08,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:54:08,674:INFO:Checking exceptions
2023-03-19 17:54:08,674:INFO:Importing libraries
2023-03-19 17:54:08,674:INFO:Copying training dataset
2023-03-19 17:54:08,685:INFO:Defining folds
2023-03-19 17:54:08,685:INFO:Declaring metric variables
2023-03-19 17:54:08,685:INFO:Importing untrained model
2023-03-19 17:54:08,708:INFO:Ridge Classifier Imported successfully
2023-03-19 17:54:08,717:INFO:Starting cross validation
2023-03-19 17:54:08,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:54:09,645:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,660:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,677:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,692:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,708:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,729:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,730:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:09,752:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:11,352:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:11,408:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:54:15,008:INFO:Calculating mean and std
2023-03-19 17:54:15,008:INFO:Creating metrics dataframe
2023-03-19 17:54:15,972:INFO:Uploading results into container
2023-03-19 17:54:15,972:INFO:Uploading model into container now
2023-03-19 17:54:15,972:INFO:_master_model_container: 6
2023-03-19 17:54:15,972:INFO:_display_container: 2
2023-03-19 17:54:15,972:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3738, solver='auto',
                tol=0.0001)
2023-03-19 17:54:15,972:INFO:create_model() successfully completed......................................
2023-03-19 17:54:16,067:INFO:SubProcess create_model() end ==================================
2023-03-19 17:54:16,081:INFO:Creating metrics dataframe
2023-03-19 17:54:16,099:INFO:Initializing Random Forest Classifier
2023-03-19 17:54:16,099:INFO:Total runtime is 0.9121327241261801 minutes
2023-03-19 17:54:16,114:INFO:SubProcess create_model() called ==================================
2023-03-19 17:54:16,114:INFO:Initializing create_model()
2023-03-19 17:54:16,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:54:16,114:INFO:Checking exceptions
2023-03-19 17:54:16,114:INFO:Importing libraries
2023-03-19 17:54:16,114:INFO:Copying training dataset
2023-03-19 17:54:16,130:INFO:Defining folds
2023-03-19 17:54:16,130:INFO:Declaring metric variables
2023-03-19 17:54:16,146:INFO:Importing untrained model
2023-03-19 17:54:16,146:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:54:16,161:INFO:Starting cross validation
2023-03-19 17:54:16,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:54:19,609:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:54:19,611:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:54:19,780:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:54:20,345:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:54:20,346:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:54:20,467:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:54:26,868:INFO:Calculating mean and std
2023-03-19 17:54:26,870:INFO:Creating metrics dataframe
2023-03-19 17:54:27,351:INFO:Uploading results into container
2023-03-19 17:54:27,352:INFO:Uploading model into container now
2023-03-19 17:54:27,352:INFO:_master_model_container: 7
2023-03-19 17:54:27,352:INFO:_display_container: 2
2023-03-19 17:54:27,352:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3738, verbose=0, warm_start=False)
2023-03-19 17:54:27,352:INFO:create_model() successfully completed......................................
2023-03-19 17:54:27,434:INFO:SubProcess create_model() end ==================================
2023-03-19 17:54:27,435:INFO:Creating metrics dataframe
2023-03-19 17:54:27,457:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:54:27,457:INFO:Total runtime is 1.101429573694865 minutes
2023-03-19 17:54:27,462:INFO:SubProcess create_model() called ==================================
2023-03-19 17:54:27,463:INFO:Initializing create_model()
2023-03-19 17:54:27,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:54:27,463:INFO:Checking exceptions
2023-03-19 17:54:27,464:INFO:Importing libraries
2023-03-19 17:54:27,464:INFO:Copying training dataset
2023-03-19 17:54:27,477:INFO:Defining folds
2023-03-19 17:54:27,477:INFO:Declaring metric variables
2023-03-19 17:54:27,483:INFO:Importing untrained model
2023-03-19 17:54:27,487:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:54:27,498:INFO:Starting cross validation
2023-03-19 17:54:27,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:54:28,287:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:28,384:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:28,585:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:28,608:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:28,682:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:28,708:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:28,749:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:29,091:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:31,385:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:31,485:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:54:34,365:INFO:Calculating mean and std
2023-03-19 17:54:34,367:INFO:Creating metrics dataframe
2023-03-19 17:54:34,901:INFO:Uploading results into container
2023-03-19 17:54:34,902:INFO:Uploading model into container now
2023-03-19 17:54:34,902:INFO:_master_model_container: 8
2023-03-19 17:54:34,902:INFO:_display_container: 2
2023-03-19 17:54:34,902:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:54:34,903:INFO:create_model() successfully completed......................................
2023-03-19 17:54:34,978:INFO:SubProcess create_model() end ==================================
2023-03-19 17:54:34,978:INFO:Creating metrics dataframe
2023-03-19 17:54:34,989:INFO:Initializing Ada Boost Classifier
2023-03-19 17:54:34,990:INFO:Total runtime is 1.2269793947537742 minutes
2023-03-19 17:54:34,996:INFO:SubProcess create_model() called ==================================
2023-03-19 17:54:34,996:INFO:Initializing create_model()
2023-03-19 17:54:34,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:54:34,996:INFO:Checking exceptions
2023-03-19 17:54:34,996:INFO:Importing libraries
2023-03-19 17:54:34,996:INFO:Copying training dataset
2023-03-19 17:54:35,006:INFO:Defining folds
2023-03-19 17:54:35,007:INFO:Declaring metric variables
2023-03-19 17:54:35,012:INFO:Importing untrained model
2023-03-19 17:54:35,016:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:54:35,028:INFO:Starting cross validation
2023-03-19 17:54:35,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:54:44,427:INFO:Calculating mean and std
2023-03-19 17:54:44,428:INFO:Creating metrics dataframe
2023-03-19 17:54:44,968:INFO:Uploading results into container
2023-03-19 17:54:44,969:INFO:Uploading model into container now
2023-03-19 17:54:44,969:INFO:_master_model_container: 9
2023-03-19 17:54:44,969:INFO:_display_container: 2
2023-03-19 17:54:44,969:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3738)
2023-03-19 17:54:44,969:INFO:create_model() successfully completed......................................
2023-03-19 17:54:45,054:INFO:SubProcess create_model() end ==================================
2023-03-19 17:54:45,054:INFO:Creating metrics dataframe
2023-03-19 17:54:45,068:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:54:45,068:INFO:Total runtime is 1.394958277543386 minutes
2023-03-19 17:54:45,072:INFO:SubProcess create_model() called ==================================
2023-03-19 17:54:45,072:INFO:Initializing create_model()
2023-03-19 17:54:45,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:54:45,073:INFO:Checking exceptions
2023-03-19 17:54:45,073:INFO:Importing libraries
2023-03-19 17:54:45,073:INFO:Copying training dataset
2023-03-19 17:54:45,084:INFO:Defining folds
2023-03-19 17:54:45,084:INFO:Declaring metric variables
2023-03-19 17:54:45,088:INFO:Importing untrained model
2023-03-19 17:54:45,091:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:54:45,101:INFO:Starting cross validation
2023-03-19 17:54:45,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:55:01,232:INFO:Calculating mean and std
2023-03-19 17:55:01,235:INFO:Creating metrics dataframe
2023-03-19 17:55:01,748:INFO:Uploading results into container
2023-03-19 17:55:01,749:INFO:Uploading model into container now
2023-03-19 17:55:01,749:INFO:_master_model_container: 10
2023-03-19 17:55:01,749:INFO:_display_container: 2
2023-03-19 17:55:01,750:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3738, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:55:01,750:INFO:create_model() successfully completed......................................
2023-03-19 17:55:01,821:INFO:SubProcess create_model() end ==================================
2023-03-19 17:55:01,821:INFO:Creating metrics dataframe
2023-03-19 17:55:01,834:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:55:01,835:INFO:Total runtime is 1.6744025389353436 minutes
2023-03-19 17:55:01,839:INFO:SubProcess create_model() called ==================================
2023-03-19 17:55:01,839:INFO:Initializing create_model()
2023-03-19 17:55:01,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:55:01,839:INFO:Checking exceptions
2023-03-19 17:55:01,839:INFO:Importing libraries
2023-03-19 17:55:01,839:INFO:Copying training dataset
2023-03-19 17:55:01,850:INFO:Defining folds
2023-03-19 17:55:01,850:INFO:Declaring metric variables
2023-03-19 17:55:01,854:INFO:Importing untrained model
2023-03-19 17:55:01,858:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:55:01,866:INFO:Starting cross validation
2023-03-19 17:55:01,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:55:03,525:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:55:11,366:INFO:Calculating mean and std
2023-03-19 17:55:11,366:INFO:Creating metrics dataframe
2023-03-19 17:55:12,304:INFO:Uploading results into container
2023-03-19 17:55:12,304:INFO:Uploading model into container now
2023-03-19 17:55:12,304:INFO:_master_model_container: 11
2023-03-19 17:55:12,304:INFO:_display_container: 2
2023-03-19 17:55:12,304:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:55:12,304:INFO:create_model() successfully completed......................................
2023-03-19 17:55:12,421:INFO:SubProcess create_model() end ==================================
2023-03-19 17:55:12,421:INFO:Creating metrics dataframe
2023-03-19 17:55:12,439:INFO:Initializing Extra Trees Classifier
2023-03-19 17:55:12,439:INFO:Total runtime is 1.8511388699213667 minutes
2023-03-19 17:55:12,441:INFO:SubProcess create_model() called ==================================
2023-03-19 17:55:12,441:INFO:Initializing create_model()
2023-03-19 17:55:12,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:55:12,441:INFO:Checking exceptions
2023-03-19 17:55:12,441:INFO:Importing libraries
2023-03-19 17:55:12,441:INFO:Copying training dataset
2023-03-19 17:55:12,458:INFO:Defining folds
2023-03-19 17:55:12,458:INFO:Declaring metric variables
2023-03-19 17:55:12,472:INFO:Importing untrained model
2023-03-19 17:55:12,472:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:55:12,500:INFO:Starting cross validation
2023-03-19 17:55:12,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:55:16,856:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:55:17,176:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:55:18,130:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:55:19,017:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:55:19,035:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:55:19,159:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:55:27,712:INFO:Calculating mean and std
2023-03-19 17:55:27,712:INFO:Creating metrics dataframe
2023-03-19 17:55:28,746:INFO:Uploading results into container
2023-03-19 17:55:28,746:INFO:Uploading model into container now
2023-03-19 17:55:28,746:INFO:_master_model_container: 12
2023-03-19 17:55:28,746:INFO:_display_container: 2
2023-03-19 17:55:28,746:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3738, verbose=0, warm_start=False)
2023-03-19 17:55:28,746:INFO:create_model() successfully completed......................................
2023-03-19 17:55:28,859:INFO:SubProcess create_model() end ==================================
2023-03-19 17:55:28,860:INFO:Creating metrics dataframe
2023-03-19 17:55:28,874:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:55:28,874:INFO:Total runtime is 2.125047930081686 minutes
2023-03-19 17:55:28,874:INFO:SubProcess create_model() called ==================================
2023-03-19 17:55:28,874:INFO:Initializing create_model()
2023-03-19 17:55:28,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:55:28,874:INFO:Checking exceptions
2023-03-19 17:55:28,874:INFO:Importing libraries
2023-03-19 17:55:28,874:INFO:Copying training dataset
2023-03-19 17:55:28,889:INFO:Defining folds
2023-03-19 17:55:28,889:INFO:Declaring metric variables
2023-03-19 17:55:28,904:INFO:Importing untrained model
2023-03-19 17:55:28,904:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:55:28,930:INFO:Starting cross validation
2023-03-19 17:55:28,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:55:37,006:INFO:Calculating mean and std
2023-03-19 17:55:37,010:INFO:Creating metrics dataframe
2023-03-19 17:55:38,139:INFO:Uploading results into container
2023-03-19 17:55:38,139:INFO:Uploading model into container now
2023-03-19 17:55:38,139:INFO:_master_model_container: 13
2023-03-19 17:55:38,139:INFO:_display_container: 2
2023-03-19 17:55:38,139:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3738, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:55:38,139:INFO:create_model() successfully completed......................................
2023-03-19 17:55:38,298:INFO:SubProcess create_model() end ==================================
2023-03-19 17:55:38,298:INFO:Creating metrics dataframe
2023-03-19 17:55:38,330:INFO:Initializing Dummy Classifier
2023-03-19 17:55:38,330:INFO:Total runtime is 2.2826562047004706 minutes
2023-03-19 17:55:38,331:INFO:SubProcess create_model() called ==================================
2023-03-19 17:55:38,331:INFO:Initializing create_model()
2023-03-19 17:55:38,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDC504C0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:55:38,331:INFO:Checking exceptions
2023-03-19 17:55:38,331:INFO:Importing libraries
2023-03-19 17:55:38,331:INFO:Copying training dataset
2023-03-19 17:55:38,352:INFO:Defining folds
2023-03-19 17:55:38,352:INFO:Declaring metric variables
2023-03-19 17:55:38,365:INFO:Importing untrained model
2023-03-19 17:55:38,374:INFO:Dummy Classifier Imported successfully
2023-03-19 17:55:38,391:INFO:Starting cross validation
2023-03-19 17:55:38,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:55:39,370:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,427:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,463:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,495:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,522:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,583:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,631:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:39,647:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:41,413:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:41,433:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:55:43,961:INFO:Calculating mean and std
2023-03-19 17:55:43,962:INFO:Creating metrics dataframe
2023-03-19 17:55:44,543:INFO:Uploading results into container
2023-03-19 17:55:44,543:INFO:Uploading model into container now
2023-03-19 17:55:44,544:INFO:_master_model_container: 14
2023-03-19 17:55:44,544:INFO:_display_container: 2
2023-03-19 17:55:44,544:INFO:DummyClassifier(constant=None, random_state=3738, strategy='prior')
2023-03-19 17:55:44,544:INFO:create_model() successfully completed......................................
2023-03-19 17:55:44,617:INFO:SubProcess create_model() end ==================================
2023-03-19 17:55:44,617:INFO:Creating metrics dataframe
2023-03-19 17:55:44,641:INFO:Initializing create_model()
2023-03-19 17:55:44,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:55:44,641:INFO:Checking exceptions
2023-03-19 17:55:44,642:INFO:Importing libraries
2023-03-19 17:55:44,642:INFO:Copying training dataset
2023-03-19 17:55:44,651:INFO:Defining folds
2023-03-19 17:55:44,651:INFO:Declaring metric variables
2023-03-19 17:55:44,652:INFO:Importing untrained model
2023-03-19 17:55:44,652:INFO:Declaring custom model
2023-03-19 17:55:44,652:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:55:44,654:INFO:Cross validation set to False
2023-03-19 17:55:44,654:INFO:Fitting Model
2023-03-19 17:55:45,581:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:55:45,581:INFO:create_model() successfully completed......................................
2023-03-19 17:55:45,650:INFO:Creating Dashboard logs
2023-03-19 17:55:45,657:INFO:Model: Linear Discriminant Analysis
2023-03-19 17:55:45,709:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:55:45,796:INFO:Initializing predict_model()
2023-03-19 17:55:45,796:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BEDC03430>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000029BEE28D120>)
2023-03-19 17:55:45,796:INFO:Checking exceptions
2023-03-19 17:55:45,796:INFO:Preloading libraries
2023-03-19 17:55:45,969:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-03-19 17:55:46,478:INFO:Creating Dashboard logs
2023-03-19 17:55:46,481:INFO:Model: Ridge Classifier
2023-03-19 17:55:46,546:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 3738, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 17:55:47,189:INFO:Creating Dashboard logs
2023-03-19 17:55:47,193:INFO:Model: Extra Trees Classifier
2023-03-19 17:55:47,247:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3738, 'verbose': 0, 'warm_start': False}
2023-03-19 17:55:47,857:INFO:Creating Dashboard logs
2023-03-19 17:55:47,860:INFO:Model: Logistic Regression
2023-03-19 17:55:47,912:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 3738, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 17:55:48,525:INFO:Creating Dashboard logs
2023-03-19 17:55:48,529:INFO:Model: Naive Bayes
2023-03-19 17:55:48,592:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 17:55:49,192:INFO:Creating Dashboard logs
2023-03-19 17:55:49,195:INFO:Model: SVM - Linear Kernel
2023-03-19 17:55:49,254:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 3738, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:55:49,894:INFO:Creating Dashboard logs
2023-03-19 17:55:49,898:INFO:Model: Random Forest Classifier
2023-03-19 17:55:49,948:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 3738, 'verbose': 0, 'warm_start': False}
2023-03-19 17:55:50,629:INFO:Creating Dashboard logs
2023-03-19 17:55:50,633:INFO:Model: K Neighbors Classifier
2023-03-19 17:55:50,689:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 17:55:51,327:INFO:Creating Dashboard logs
2023-03-19 17:55:51,331:INFO:Model: str
2023-03-19 17:55:51,383:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 3738}
2023-03-19 17:55:51,970:INFO:Creating Dashboard logs
2023-03-19 17:55:51,974:INFO:Model: Gradient Boosting Classifier
2023-03-19 17:55:52,027:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 3738, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 17:55:52,686:INFO:Creating Dashboard logs
2023-03-19 17:55:52,689:INFO:Model: Dummy Classifier
2023-03-19 17:55:52,740:INFO:Logged params: {'constant': None, 'random_state': 3738, 'strategy': 'prior'}
2023-03-19 17:55:53,300:INFO:Creating Dashboard logs
2023-03-19 17:55:53,303:INFO:Model: Decision Tree Classifier
2023-03-19 17:55:53,357:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 3738, 'splitter': 'best'}
2023-03-19 17:55:53,921:INFO:Creating Dashboard logs
2023-03-19 17:55:53,924:INFO:Model: Light Gradient Boosting Machine
2023-03-19 17:55:53,975:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3738, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 17:55:54,604:INFO:Creating Dashboard logs
2023-03-19 17:55:54,607:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 17:55:54,658:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:55:55,275:INFO:_master_model_container: 14
2023-03-19 17:55:55,275:INFO:_display_container: 2
2023-03-19 17:55:55,275:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:55:55,275:INFO:compare_models() successfully completed......................................
2023-03-19 17:55:55,700:INFO:PyCaret ClassificationExperiment
2023-03-19 17:55:55,700:INFO:Logging name: adult
2023-03-19 17:55:55,700:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:55:55,700:INFO:version 3.0.0
2023-03-19 17:55:55,700:INFO:Initializing setup()
2023-03-19 17:55:55,700:INFO:self.USI: 0cb0
2023-03-19 17:55:55,700:INFO:self._variable_keys: {'gpu_param', 'gpu_n_jobs_param', 'fold_generator', 'y_train', 'seed', 'logging_param', 'X', 'exp_id', 'exp_name_log', '_ml_usecase', 'fold_groups_param', 'y_test', 'n_jobs_param', '_available_plots', 'X_train', 'memory', 'fold_shuffle_param', 'target_param', 'is_multiclass', 'y', 'html_param', 'log_plots_param', 'pipeline', 'USI', 'X_test', 'data', 'fix_imbalance', 'idx'}
2023-03-19 17:55:55,700:INFO:Checking environment
2023-03-19 17:55:55,700:INFO:python_version: 3.10.0
2023-03-19 17:55:55,700:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:55:55,700:INFO:machine: AMD64
2023-03-19 17:55:55,700:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:55:55,707:INFO:Memory: svmem(total=16969424896, available=4543913984, percent=73.2, used=12425510912, free=4543913984)
2023-03-19 17:55:55,707:INFO:Physical Core: 4
2023-03-19 17:55:55,707:INFO:Logical Core: 8
2023-03-19 17:55:55,707:INFO:Checking libraries
2023-03-19 17:55:55,707:INFO:System:
2023-03-19 17:55:55,707:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:55:55,707:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:55:55,707:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:55:55,707:INFO:PyCaret required dependencies:
2023-03-19 17:55:55,707:INFO:                 pip: 23.0.1
2023-03-19 17:55:55,707:INFO:          setuptools: 65.6.3
2023-03-19 17:55:55,707:INFO:             pycaret: 3.0.0
2023-03-19 17:55:55,707:INFO:             IPython: 8.11.0
2023-03-19 17:55:55,707:INFO:          ipywidgets: 8.0.4
2023-03-19 17:55:55,707:INFO:                tqdm: 4.65.0
2023-03-19 17:55:55,707:INFO:               numpy: 1.23.5
2023-03-19 17:55:55,707:INFO:              pandas: 1.5.3
2023-03-19 17:55:55,707:INFO:              jinja2: 3.1.2
2023-03-19 17:55:55,707:INFO:               scipy: 1.10.1
2023-03-19 17:55:55,707:INFO:              joblib: 1.2.0
2023-03-19 17:55:55,707:INFO:             sklearn: 1.2.2
2023-03-19 17:55:55,708:INFO:                pyod: 1.0.8
2023-03-19 17:55:55,708:INFO:            imblearn: 0.10.1
2023-03-19 17:55:55,708:INFO:   category_encoders: 2.6.0
2023-03-19 17:55:55,708:INFO:            lightgbm: 3.3.5
2023-03-19 17:55:55,708:INFO:               numba: 0.56.4
2023-03-19 17:55:55,708:INFO:            requests: 2.28.2
2023-03-19 17:55:55,708:INFO:          matplotlib: 3.7.1
2023-03-19 17:55:55,708:INFO:          scikitplot: 0.3.7
2023-03-19 17:55:55,708:INFO:         yellowbrick: 1.5
2023-03-19 17:55:55,708:INFO:              plotly: 5.13.1
2023-03-19 17:55:55,708:INFO:             kaleido: 0.2.1
2023-03-19 17:55:55,708:INFO:         statsmodels: 0.13.5
2023-03-19 17:55:55,708:INFO:              sktime: 0.16.1
2023-03-19 17:55:55,708:INFO:               tbats: 1.1.2
2023-03-19 17:55:55,708:INFO:            pmdarima: 2.0.3
2023-03-19 17:55:55,708:INFO:              psutil: 5.9.4
2023-03-19 17:55:55,708:INFO:PyCaret optional dependencies:
2023-03-19 17:55:55,708:INFO:                shap: 0.41.0
2023-03-19 17:55:55,708:INFO:           interpret: Not installed
2023-03-19 17:55:55,708:INFO:                umap: Not installed
2023-03-19 17:55:55,708:INFO:    pandas_profiling: Not installed
2023-03-19 17:55:55,708:INFO:  explainerdashboard: Not installed
2023-03-19 17:55:55,708:INFO:             autoviz: Not installed
2023-03-19 17:55:55,708:INFO:           fairlearn: Not installed
2023-03-19 17:55:55,708:INFO:             xgboost: Not installed
2023-03-19 17:55:55,708:INFO:            catboost: Not installed
2023-03-19 17:55:55,708:INFO:              kmodes: Not installed
2023-03-19 17:55:55,708:INFO:             mlxtend: Not installed
2023-03-19 17:55:55,708:INFO:       statsforecast: Not installed
2023-03-19 17:55:55,708:INFO:        tune_sklearn: Not installed
2023-03-19 17:55:55,708:INFO:                 ray: Not installed
2023-03-19 17:55:55,709:INFO:            hyperopt: Not installed
2023-03-19 17:55:55,709:INFO:              optuna: Not installed
2023-03-19 17:55:55,709:INFO:               skopt: Not installed
2023-03-19 17:55:55,709:INFO:              mlflow: 2.2.2
2023-03-19 17:55:55,709:INFO:              gradio: Not installed
2023-03-19 17:55:55,709:INFO:             fastapi: Not installed
2023-03-19 17:55:55,709:INFO:             uvicorn: Not installed
2023-03-19 17:55:55,709:INFO:              m2cgen: Not installed
2023-03-19 17:55:55,709:INFO:           evidently: Not installed
2023-03-19 17:55:55,709:INFO:               fugue: Not installed
2023-03-19 17:55:55,709:INFO:           streamlit: Not installed
2023-03-19 17:55:55,709:INFO:             prophet: Not installed
2023-03-19 17:55:55,709:INFO:None
2023-03-19 17:55:55,709:INFO:Set up data.
2023-03-19 17:55:55,734:INFO:Set up train/test split.
2023-03-19 17:55:55,745:INFO:Set up index.
2023-03-19 17:55:55,746:INFO:Set up folding strategy.
2023-03-19 17:55:55,746:INFO:Assigning column types.
2023-03-19 17:55:55,749:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:55:55,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:55:55,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:55:55,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:55,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:55,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:55:55,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:55:55,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:55,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:55,872:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:55:55,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:55:55,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:55,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:55,976:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:55:56,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:56,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:56,001:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:55:56,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:56,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:56,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:56,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:56,126:INFO:Preparing preprocessing pipeline...
2023-03-19 17:55:56,127:INFO:Set up simple imputation.
2023-03-19 17:55:56,133:INFO:Set up encoding of ordinal features.
2023-03-19 17:55:56,135:INFO:Set up encoding of categorical features.
2023-03-19 17:55:56,135:INFO:Set up feature normalization.
2023-03-19 17:55:56,136:INFO:Set up column name cleaning.
2023-03-19 17:55:56,647:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:55:56,663:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6011,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:55:56,664:INFO:Creating final display dataframe.
2023-03-19 17:55:57,279:INFO:Setup _display_container:                     Description            Value
0                    Session id             6011
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment     MlflowLogger
24              Experiment Name            adult
25                          USI             0cb0
2023-03-19 17:55:57,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:57,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:57,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:57,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:55:57,418:INFO:Logging experiment in loggers
2023-03-19 17:55:57,516:INFO:SubProcess save_model() called ==================================
2023-03-19 17:55:57,551:INFO:Initializing save_model()
2023-03-19 17:55:57,551:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6011,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmp6ha7tcnw\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6011,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:55:57,551:INFO:Adding model into prep_pipe
2023-03-19 17:55:57,553:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:55:57,564:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmp6ha7tcnw\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:55:57,580:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6011,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:55:57,580:INFO:save_model() successfully completed......................................
2023-03-19 17:55:57,994:INFO:SubProcess save_model() end ==================================
2023-03-19 17:55:58,033:INFO:setup() successfully completed in 2.08s...............
2023-03-19 17:55:58,077:INFO:Initializing compare_models()
2023-03-19 17:55:58,077:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:55:58,077:INFO:Checking exceptions
2023-03-19 17:55:58,084:INFO:Preparing display monitor
2023-03-19 17:55:58,110:INFO:Initializing Logistic Regression
2023-03-19 17:55:58,111:INFO:Total runtime is 1.6490618387858074e-05 minutes
2023-03-19 17:55:58,114:INFO:SubProcess create_model() called ==================================
2023-03-19 17:55:58,115:INFO:Initializing create_model()
2023-03-19 17:55:58,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:55:58,115:INFO:Checking exceptions
2023-03-19 17:55:58,115:INFO:Importing libraries
2023-03-19 17:55:58,115:INFO:Copying training dataset
2023-03-19 17:55:58,127:INFO:Defining folds
2023-03-19 17:55:58,127:INFO:Declaring metric variables
2023-03-19 17:55:58,129:INFO:Importing untrained model
2023-03-19 17:55:58,133:INFO:Logistic Regression Imported successfully
2023-03-19 17:55:58,140:INFO:Starting cross validation
2023-03-19 17:55:58,144:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:06,163:INFO:Calculating mean and std
2023-03-19 17:56:06,164:INFO:Creating metrics dataframe
2023-03-19 17:56:06,720:INFO:Uploading results into container
2023-03-19 17:56:06,720:INFO:Uploading model into container now
2023-03-19 17:56:06,721:INFO:_master_model_container: 1
2023-03-19 17:56:06,721:INFO:_display_container: 2
2023-03-19 17:56:06,721:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6011, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:56:06,721:INFO:create_model() successfully completed......................................
2023-03-19 17:56:06,789:INFO:SubProcess create_model() end ==================================
2023-03-19 17:56:06,789:INFO:Creating metrics dataframe
2023-03-19 17:56:06,799:INFO:Initializing K Neighbors Classifier
2023-03-19 17:56:06,800:INFO:Total runtime is 0.14480548699696857 minutes
2023-03-19 17:56:06,804:INFO:SubProcess create_model() called ==================================
2023-03-19 17:56:06,804:INFO:Initializing create_model()
2023-03-19 17:56:06,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:56:06,804:INFO:Checking exceptions
2023-03-19 17:56:06,805:INFO:Importing libraries
2023-03-19 17:56:06,805:INFO:Copying training dataset
2023-03-19 17:56:06,812:INFO:Defining folds
2023-03-19 17:56:06,812:INFO:Declaring metric variables
2023-03-19 17:56:06,816:INFO:Importing untrained model
2023-03-19 17:56:06,821:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:56:06,829:INFO:Starting cross validation
2023-03-19 17:56:06,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:15,530:INFO:Calculating mean and std
2023-03-19 17:56:15,531:INFO:Creating metrics dataframe
2023-03-19 17:56:16,114:INFO:Uploading results into container
2023-03-19 17:56:16,115:INFO:Uploading model into container now
2023-03-19 17:56:16,115:INFO:_master_model_container: 2
2023-03-19 17:56:16,115:INFO:_display_container: 2
2023-03-19 17:56:16,115:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:56:16,115:INFO:create_model() successfully completed......................................
2023-03-19 17:56:16,190:INFO:SubProcess create_model() end ==================================
2023-03-19 17:56:16,190:INFO:Creating metrics dataframe
2023-03-19 17:56:16,201:INFO:Initializing Naive Bayes
2023-03-19 17:56:16,202:INFO:Total runtime is 0.3015273094177246 minutes
2023-03-19 17:56:16,205:INFO:SubProcess create_model() called ==================================
2023-03-19 17:56:16,205:INFO:Initializing create_model()
2023-03-19 17:56:16,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:56:16,205:INFO:Checking exceptions
2023-03-19 17:56:16,205:INFO:Importing libraries
2023-03-19 17:56:16,205:INFO:Copying training dataset
2023-03-19 17:56:16,217:INFO:Defining folds
2023-03-19 17:56:16,217:INFO:Declaring metric variables
2023-03-19 17:56:16,221:INFO:Importing untrained model
2023-03-19 17:56:16,226:INFO:Naive Bayes Imported successfully
2023-03-19 17:56:16,233:INFO:Starting cross validation
2023-03-19 17:56:16,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:22,743:INFO:Calculating mean and std
2023-03-19 17:56:22,744:INFO:Creating metrics dataframe
2023-03-19 17:56:23,266:INFO:Uploading results into container
2023-03-19 17:56:23,266:INFO:Uploading model into container now
2023-03-19 17:56:23,266:INFO:_master_model_container: 3
2023-03-19 17:56:23,266:INFO:_display_container: 2
2023-03-19 17:56:23,268:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:56:23,268:INFO:create_model() successfully completed......................................
2023-03-19 17:56:23,334:INFO:SubProcess create_model() end ==================================
2023-03-19 17:56:23,334:INFO:Creating metrics dataframe
2023-03-19 17:56:23,344:INFO:Initializing Decision Tree Classifier
2023-03-19 17:56:23,344:INFO:Total runtime is 0.4205628434816996 minutes
2023-03-19 17:56:23,348:INFO:SubProcess create_model() called ==================================
2023-03-19 17:56:23,349:INFO:Initializing create_model()
2023-03-19 17:56:23,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:56:23,349:INFO:Checking exceptions
2023-03-19 17:56:23,349:INFO:Importing libraries
2023-03-19 17:56:23,349:INFO:Copying training dataset
2023-03-19 17:56:23,357:INFO:Defining folds
2023-03-19 17:56:23,357:INFO:Declaring metric variables
2023-03-19 17:56:23,361:INFO:Importing untrained model
2023-03-19 17:56:23,364:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:56:23,373:INFO:Starting cross validation
2023-03-19 17:56:23,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:30,243:INFO:Calculating mean and std
2023-03-19 17:56:30,246:INFO:Creating metrics dataframe
2023-03-19 17:56:30,846:INFO:Uploading results into container
2023-03-19 17:56:30,847:INFO:Uploading model into container now
2023-03-19 17:56:30,848:INFO:_master_model_container: 4
2023-03-19 17:56:30,848:INFO:_display_container: 2
2023-03-19 17:56:30,849:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6011, splitter='best')
2023-03-19 17:56:30,849:INFO:create_model() successfully completed......................................
2023-03-19 17:56:30,934:INFO:SubProcess create_model() end ==================================
2023-03-19 17:56:30,934:INFO:Creating metrics dataframe
2023-03-19 17:56:30,946:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:56:30,946:INFO:Total runtime is 0.5472673654556274 minutes
2023-03-19 17:56:30,950:INFO:SubProcess create_model() called ==================================
2023-03-19 17:56:30,950:INFO:Initializing create_model()
2023-03-19 17:56:30,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:56:30,950:INFO:Checking exceptions
2023-03-19 17:56:30,951:INFO:Importing libraries
2023-03-19 17:56:30,951:INFO:Copying training dataset
2023-03-19 17:56:30,961:INFO:Defining folds
2023-03-19 17:56:30,961:INFO:Declaring metric variables
2023-03-19 17:56:30,965:INFO:Importing untrained model
2023-03-19 17:56:30,970:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:56:30,978:INFO:Starting cross validation
2023-03-19 17:56:30,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:33,188:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,189:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,262:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,334:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,336:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,364:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,511:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:33,551:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:35,887:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:35,912:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:56:38,666:INFO:Calculating mean and std
2023-03-19 17:56:38,667:INFO:Creating metrics dataframe
2023-03-19 17:56:39,274:INFO:Uploading results into container
2023-03-19 17:56:39,274:INFO:Uploading model into container now
2023-03-19 17:56:39,274:INFO:_master_model_container: 5
2023-03-19 17:56:39,275:INFO:_display_container: 2
2023-03-19 17:56:39,275:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6011, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:56:39,275:INFO:create_model() successfully completed......................................
2023-03-19 17:56:39,342:INFO:SubProcess create_model() end ==================================
2023-03-19 17:56:39,342:INFO:Creating metrics dataframe
2023-03-19 17:56:39,353:INFO:Initializing Ridge Classifier
2023-03-19 17:56:39,353:INFO:Total runtime is 0.6873694737752278 minutes
2023-03-19 17:56:39,356:INFO:SubProcess create_model() called ==================================
2023-03-19 17:56:39,357:INFO:Initializing create_model()
2023-03-19 17:56:39,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:56:39,357:INFO:Checking exceptions
2023-03-19 17:56:39,358:INFO:Importing libraries
2023-03-19 17:56:39,358:INFO:Copying training dataset
2023-03-19 17:56:39,366:INFO:Defining folds
2023-03-19 17:56:39,366:INFO:Declaring metric variables
2023-03-19 17:56:39,369:INFO:Importing untrained model
2023-03-19 17:56:39,373:INFO:Ridge Classifier Imported successfully
2023-03-19 17:56:39,380:INFO:Starting cross validation
2023-03-19 17:56:39,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:40,545:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,558:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,585:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,586:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,591:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,620:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,625:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:40,645:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:42,812:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:42,834:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:56:45,661:INFO:Calculating mean and std
2023-03-19 17:56:45,663:INFO:Creating metrics dataframe
2023-03-19 17:56:46,237:INFO:Uploading results into container
2023-03-19 17:56:46,238:INFO:Uploading model into container now
2023-03-19 17:56:46,238:INFO:_master_model_container: 6
2023-03-19 17:56:46,238:INFO:_display_container: 2
2023-03-19 17:56:46,238:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6011, solver='auto',
                tol=0.0001)
2023-03-19 17:56:46,238:INFO:create_model() successfully completed......................................
2023-03-19 17:56:46,306:INFO:SubProcess create_model() end ==================================
2023-03-19 17:56:46,306:INFO:Creating metrics dataframe
2023-03-19 17:56:46,316:INFO:Initializing Random Forest Classifier
2023-03-19 17:56:46,316:INFO:Total runtime is 0.8034194151560465 minutes
2023-03-19 17:56:46,320:INFO:SubProcess create_model() called ==================================
2023-03-19 17:56:46,320:INFO:Initializing create_model()
2023-03-19 17:56:46,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029BC8045C00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029BEDEB9DE0>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:56:46,320:INFO:Checking exceptions
2023-03-19 17:56:46,320:INFO:Importing libraries
2023-03-19 17:56:46,320:INFO:Copying training dataset
2023-03-19 17:56:46,327:INFO:Defining folds
2023-03-19 17:56:46,327:INFO:Declaring metric variables
2023-03-19 17:56:46,329:INFO:Importing untrained model
2023-03-19 17:56:46,332:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:56:46,339:INFO:Starting cross validation
2023-03-19 17:56:46,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:56:50,379:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:56:50,388:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:56:50,513:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:57:13,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:57:13,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:57:13,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:57:13,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-19 17:57:14,038:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-19 17:57:15,385:INFO:PyCaret ClassificationExperiment
2023-03-19 17:57:15,385:INFO:Logging name: adult
2023-03-19 17:57:15,385:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 17:57:15,385:INFO:version 3.0.0
2023-03-19 17:57:15,385:INFO:Initializing setup()
2023-03-19 17:57:15,385:INFO:self.USI: 7ab5
2023-03-19 17:57:15,385:INFO:self._variable_keys: {'exp_name_log', 'y', 'logging_param', 'target_param', 'memory', 'X', 'is_multiclass', 'gpu_param', 'fold_groups_param', '_ml_usecase', 'X_train', 'idx', 'log_plots_param', 'fold_generator', 'fix_imbalance', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'html_param', '_available_plots', 'X_test', 'seed', 'y_train', 'fold_shuffle_param', 'data', 'n_jobs_param', 'USI'}
2023-03-19 17:57:15,386:INFO:Checking environment
2023-03-19 17:57:15,386:INFO:python_version: 3.10.0
2023-03-19 17:57:15,386:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 17:57:15,386:INFO:machine: AMD64
2023-03-19 17:57:15,386:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 17:57:15,392:INFO:Memory: svmem(total=16969424896, available=5858975744, percent=65.5, used=11110449152, free=5858975744)
2023-03-19 17:57:15,393:INFO:Physical Core: 4
2023-03-19 17:57:15,393:INFO:Logical Core: 8
2023-03-19 17:57:15,393:INFO:Checking libraries
2023-03-19 17:57:15,393:INFO:System:
2023-03-19 17:57:15,393:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 17:57:15,393:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 17:57:15,393:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 17:57:15,393:INFO:PyCaret required dependencies:
2023-03-19 17:57:15,393:INFO:                 pip: 23.0.1
2023-03-19 17:57:15,393:INFO:          setuptools: 65.6.3
2023-03-19 17:57:15,393:INFO:             pycaret: 3.0.0
2023-03-19 17:57:15,393:INFO:             IPython: 8.11.0
2023-03-19 17:57:15,393:INFO:          ipywidgets: 8.0.4
2023-03-19 17:57:15,393:INFO:                tqdm: 4.65.0
2023-03-19 17:57:15,393:INFO:               numpy: 1.23.5
2023-03-19 17:57:15,393:INFO:              pandas: 1.5.3
2023-03-19 17:57:15,393:INFO:              jinja2: 3.1.2
2023-03-19 17:57:15,393:INFO:               scipy: 1.10.1
2023-03-19 17:57:15,393:INFO:              joblib: 1.2.0
2023-03-19 17:57:15,394:INFO:             sklearn: 1.2.2
2023-03-19 17:57:15,394:INFO:                pyod: 1.0.8
2023-03-19 17:57:15,394:INFO:            imblearn: 0.10.1
2023-03-19 17:57:15,394:INFO:   category_encoders: 2.6.0
2023-03-19 17:57:15,394:INFO:            lightgbm: 3.3.5
2023-03-19 17:57:15,394:INFO:               numba: 0.56.4
2023-03-19 17:57:15,394:INFO:            requests: 2.28.2
2023-03-19 17:57:15,394:INFO:          matplotlib: 3.7.1
2023-03-19 17:57:15,394:INFO:          scikitplot: 0.3.7
2023-03-19 17:57:15,394:INFO:         yellowbrick: 1.5
2023-03-19 17:57:15,394:INFO:              plotly: 5.13.1
2023-03-19 17:57:15,394:INFO:             kaleido: 0.2.1
2023-03-19 17:57:15,394:INFO:         statsmodels: 0.13.5
2023-03-19 17:57:15,394:INFO:              sktime: 0.16.1
2023-03-19 17:57:15,394:INFO:               tbats: 1.1.2
2023-03-19 17:57:15,394:INFO:            pmdarima: 2.0.3
2023-03-19 17:57:15,394:INFO:              psutil: 5.9.4
2023-03-19 17:57:15,394:INFO:PyCaret optional dependencies:
2023-03-19 17:57:15,404:INFO:                shap: 0.41.0
2023-03-19 17:57:15,405:INFO:           interpret: Not installed
2023-03-19 17:57:15,405:INFO:                umap: Not installed
2023-03-19 17:57:15,405:INFO:    pandas_profiling: Not installed
2023-03-19 17:57:15,405:INFO:  explainerdashboard: Not installed
2023-03-19 17:57:15,405:INFO:             autoviz: Not installed
2023-03-19 17:57:15,405:INFO:           fairlearn: Not installed
2023-03-19 17:57:15,405:INFO:             xgboost: Not installed
2023-03-19 17:57:15,405:INFO:            catboost: Not installed
2023-03-19 17:57:15,405:INFO:              kmodes: Not installed
2023-03-19 17:57:15,405:INFO:             mlxtend: Not installed
2023-03-19 17:57:15,405:INFO:       statsforecast: Not installed
2023-03-19 17:57:15,405:INFO:        tune_sklearn: Not installed
2023-03-19 17:57:15,405:INFO:                 ray: Not installed
2023-03-19 17:57:15,405:INFO:            hyperopt: Not installed
2023-03-19 17:57:15,405:INFO:              optuna: Not installed
2023-03-19 17:57:15,405:INFO:               skopt: Not installed
2023-03-19 17:57:15,405:INFO:              mlflow: 2.2.2
2023-03-19 17:57:15,405:INFO:              gradio: Not installed
2023-03-19 17:57:15,405:INFO:             fastapi: Not installed
2023-03-19 17:57:15,405:INFO:             uvicorn: Not installed
2023-03-19 17:57:15,405:INFO:              m2cgen: Not installed
2023-03-19 17:57:15,405:INFO:           evidently: Not installed
2023-03-19 17:57:15,405:INFO:               fugue: Not installed
2023-03-19 17:57:15,405:INFO:           streamlit: Not installed
2023-03-19 17:57:15,405:INFO:             prophet: Not installed
2023-03-19 17:57:15,405:INFO:None
2023-03-19 17:57:15,405:INFO:Set up data.
2023-03-19 17:57:15,432:INFO:Set up train/test split.
2023-03-19 17:57:15,447:INFO:Set up index.
2023-03-19 17:57:15,447:INFO:Set up folding strategy.
2023-03-19 17:57:15,447:INFO:Assigning column types.
2023-03-19 17:57:15,452:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 17:57:15,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:57:15,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:57:15,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 17:57:15,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:57:15,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,606:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 17:57:15,645:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:57:15,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 17:57:15,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,732:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 17:57:15,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:15,860:INFO:Preparing preprocessing pipeline...
2023-03-19 17:57:15,861:INFO:Set up simple imputation.
2023-03-19 17:57:15,868:INFO:Set up encoding of ordinal features.
2023-03-19 17:57:15,869:INFO:Set up encoding of categorical features.
2023-03-19 17:57:15,870:INFO:Set up column name cleaning.
2023-03-19 17:57:16,427:INFO:Finished creating preprocessing pipeline.
2023-03-19 17:57:16,442:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=277,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:57:16,442:INFO:Creating final display dataframe.
2023-03-19 17:57:17,039:INFO:Setup _display_container:                     Description            Value
0                    Session id              277
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name            adult
23                          USI             7ab5
2023-03-19 17:57:17,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:17,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:17,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:17,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 17:57:17,185:INFO:Logging experiment in loggers
2023-03-19 17:57:17,451:INFO:SubProcess save_model() called ==================================
2023-03-19 17:57:17,487:INFO:Initializing save_model()
2023-03-19 17:57:17,487:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=277,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmp7bxk_kc2\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=277,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 17:57:17,487:INFO:Adding model into prep_pipe
2023-03-19 17:57:17,488:WARNING:Only Model saved as it was a pipeline.
2023-03-19 17:57:17,499:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmp7bxk_kc2\Transformation Pipeline.pkl saved in current working directory
2023-03-19 17:57:17,526:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=277,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 17:57:17,526:INFO:save_model() successfully completed......................................
2023-03-19 17:57:17,972:INFO:SubProcess save_model() end ==================================
2023-03-19 17:57:18,006:INFO:setup() successfully completed in 2.25s...............
2023-03-19 17:57:18,039:INFO:Initializing compare_models()
2023-03-19 17:57:18,039:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 17:57:18,039:INFO:Checking exceptions
2023-03-19 17:57:18,046:INFO:Preparing display monitor
2023-03-19 17:57:18,074:INFO:Initializing Logistic Regression
2023-03-19 17:57:18,074:INFO:Total runtime is 0.0 minutes
2023-03-19 17:57:18,077:INFO:SubProcess create_model() called ==================================
2023-03-19 17:57:18,078:INFO:Initializing create_model()
2023-03-19 17:57:18,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:57:18,078:INFO:Checking exceptions
2023-03-19 17:57:18,078:INFO:Importing libraries
2023-03-19 17:57:18,078:INFO:Copying training dataset
2023-03-19 17:57:18,088:INFO:Defining folds
2023-03-19 17:57:18,088:INFO:Declaring metric variables
2023-03-19 17:57:18,091:INFO:Importing untrained model
2023-03-19 17:57:18,095:INFO:Logistic Regression Imported successfully
2023-03-19 17:57:18,104:INFO:Starting cross validation
2023-03-19 17:57:18,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:57:31,324:INFO:Calculating mean and std
2023-03-19 17:57:31,326:INFO:Creating metrics dataframe
2023-03-19 17:57:31,863:INFO:Uploading results into container
2023-03-19 17:57:31,864:INFO:Uploading model into container now
2023-03-19 17:57:31,865:INFO:_master_model_container: 1
2023-03-19 17:57:31,865:INFO:_display_container: 2
2023-03-19 17:57:31,865:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=277, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 17:57:31,866:INFO:create_model() successfully completed......................................
2023-03-19 17:57:31,931:INFO:SubProcess create_model() end ==================================
2023-03-19 17:57:31,932:INFO:Creating metrics dataframe
2023-03-19 17:57:31,940:INFO:Initializing K Neighbors Classifier
2023-03-19 17:57:31,941:INFO:Total runtime is 0.2311240235964457 minutes
2023-03-19 17:57:31,944:INFO:SubProcess create_model() called ==================================
2023-03-19 17:57:31,945:INFO:Initializing create_model()
2023-03-19 17:57:31,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:57:31,945:INFO:Checking exceptions
2023-03-19 17:57:31,945:INFO:Importing libraries
2023-03-19 17:57:31,945:INFO:Copying training dataset
2023-03-19 17:57:31,954:INFO:Defining folds
2023-03-19 17:57:31,955:INFO:Declaring metric variables
2023-03-19 17:57:31,957:INFO:Importing untrained model
2023-03-19 17:57:31,962:INFO:K Neighbors Classifier Imported successfully
2023-03-19 17:57:31,969:INFO:Starting cross validation
2023-03-19 17:57:31,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:57:40,648:INFO:Calculating mean and std
2023-03-19 17:57:40,649:INFO:Creating metrics dataframe
2023-03-19 17:57:41,200:INFO:Uploading results into container
2023-03-19 17:57:41,201:INFO:Uploading model into container now
2023-03-19 17:57:41,201:INFO:_master_model_container: 2
2023-03-19 17:57:41,201:INFO:_display_container: 2
2023-03-19 17:57:41,201:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 17:57:41,201:INFO:create_model() successfully completed......................................
2023-03-19 17:57:41,272:INFO:SubProcess create_model() end ==================================
2023-03-19 17:57:41,272:INFO:Creating metrics dataframe
2023-03-19 17:57:41,286:INFO:Initializing Naive Bayes
2023-03-19 17:57:41,286:INFO:Total runtime is 0.38687258164087934 minutes
2023-03-19 17:57:41,292:INFO:SubProcess create_model() called ==================================
2023-03-19 17:57:41,292:INFO:Initializing create_model()
2023-03-19 17:57:41,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:57:41,293:INFO:Checking exceptions
2023-03-19 17:57:41,293:INFO:Importing libraries
2023-03-19 17:57:41,293:INFO:Copying training dataset
2023-03-19 17:57:41,303:INFO:Defining folds
2023-03-19 17:57:41,303:INFO:Declaring metric variables
2023-03-19 17:57:41,308:INFO:Importing untrained model
2023-03-19 17:57:41,313:INFO:Naive Bayes Imported successfully
2023-03-19 17:57:41,322:INFO:Starting cross validation
2023-03-19 17:57:41,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:57:47,760:INFO:Calculating mean and std
2023-03-19 17:57:47,761:INFO:Creating metrics dataframe
2023-03-19 17:57:48,303:INFO:Uploading results into container
2023-03-19 17:57:48,304:INFO:Uploading model into container now
2023-03-19 17:57:48,304:INFO:_master_model_container: 3
2023-03-19 17:57:48,304:INFO:_display_container: 2
2023-03-19 17:57:48,304:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 17:57:48,304:INFO:create_model() successfully completed......................................
2023-03-19 17:57:48,375:INFO:SubProcess create_model() end ==================================
2023-03-19 17:57:48,376:INFO:Creating metrics dataframe
2023-03-19 17:57:48,386:INFO:Initializing Decision Tree Classifier
2023-03-19 17:57:48,386:INFO:Total runtime is 0.5052038709322612 minutes
2023-03-19 17:57:48,394:INFO:SubProcess create_model() called ==================================
2023-03-19 17:57:48,394:INFO:Initializing create_model()
2023-03-19 17:57:48,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:57:48,395:INFO:Checking exceptions
2023-03-19 17:57:48,395:INFO:Importing libraries
2023-03-19 17:57:48,395:INFO:Copying training dataset
2023-03-19 17:57:48,409:INFO:Defining folds
2023-03-19 17:57:48,409:INFO:Declaring metric variables
2023-03-19 17:57:48,413:INFO:Importing untrained model
2023-03-19 17:57:48,419:INFO:Decision Tree Classifier Imported successfully
2023-03-19 17:57:48,425:INFO:Starting cross validation
2023-03-19 17:57:48,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:57:54,813:INFO:Calculating mean and std
2023-03-19 17:57:54,814:INFO:Creating metrics dataframe
2023-03-19 17:57:55,374:INFO:Uploading results into container
2023-03-19 17:57:55,375:INFO:Uploading model into container now
2023-03-19 17:57:55,375:INFO:_master_model_container: 4
2023-03-19 17:57:55,376:INFO:_display_container: 2
2023-03-19 17:57:55,376:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=277, splitter='best')
2023-03-19 17:57:55,376:INFO:create_model() successfully completed......................................
2023-03-19 17:57:55,449:INFO:SubProcess create_model() end ==================================
2023-03-19 17:57:55,449:INFO:Creating metrics dataframe
2023-03-19 17:57:55,459:INFO:Initializing SVM - Linear Kernel
2023-03-19 17:57:55,459:INFO:Total runtime is 0.6230922222137452 minutes
2023-03-19 17:57:55,465:INFO:SubProcess create_model() called ==================================
2023-03-19 17:57:55,465:INFO:Initializing create_model()
2023-03-19 17:57:55,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:57:55,466:INFO:Checking exceptions
2023-03-19 17:57:55,466:INFO:Importing libraries
2023-03-19 17:57:55,466:INFO:Copying training dataset
2023-03-19 17:57:55,479:INFO:Defining folds
2023-03-19 17:57:55,479:INFO:Declaring metric variables
2023-03-19 17:57:55,483:INFO:Importing untrained model
2023-03-19 17:57:55,489:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 17:57:55,498:INFO:Starting cross validation
2023-03-19 17:57:55,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:57:58,110:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:58,352:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:58,407:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:58,536:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:58,686:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:58,724:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:58,945:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:57:59,037:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:58:01,725:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:58:01,913:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 17:58:04,011:INFO:Calculating mean and std
2023-03-19 17:58:04,011:INFO:Creating metrics dataframe
2023-03-19 17:58:04,602:INFO:Uploading results into container
2023-03-19 17:58:04,603:INFO:Uploading model into container now
2023-03-19 17:58:04,603:INFO:_master_model_container: 5
2023-03-19 17:58:04,604:INFO:_display_container: 2
2023-03-19 17:58:04,604:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=277, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 17:58:04,604:INFO:create_model() successfully completed......................................
2023-03-19 17:58:04,674:INFO:SubProcess create_model() end ==================================
2023-03-19 17:58:04,674:INFO:Creating metrics dataframe
2023-03-19 17:58:04,684:INFO:Initializing Ridge Classifier
2023-03-19 17:58:04,685:INFO:Total runtime is 0.7768550992012024 minutes
2023-03-19 17:58:04,690:INFO:SubProcess create_model() called ==================================
2023-03-19 17:58:04,690:INFO:Initializing create_model()
2023-03-19 17:58:04,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:58:04,690:INFO:Checking exceptions
2023-03-19 17:58:04,690:INFO:Importing libraries
2023-03-19 17:58:04,690:INFO:Copying training dataset
2023-03-19 17:58:04,698:INFO:Defining folds
2023-03-19 17:58:04,698:INFO:Declaring metric variables
2023-03-19 17:58:04,701:INFO:Importing untrained model
2023-03-19 17:58:04,705:INFO:Ridge Classifier Imported successfully
2023-03-19 17:58:04,713:INFO:Starting cross validation
2023-03-19 17:58:04,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:58:05,711:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:05,726:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:05,779:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:05,812:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:05,825:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:05,833:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:05,871:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:06,165:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:07,978:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:08,085:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 17:58:11,497:INFO:Calculating mean and std
2023-03-19 17:58:11,503:INFO:Creating metrics dataframe
2023-03-19 17:58:12,709:INFO:Uploading results into container
2023-03-19 17:58:12,709:INFO:Uploading model into container now
2023-03-19 17:58:12,709:INFO:_master_model_container: 6
2023-03-19 17:58:12,709:INFO:_display_container: 2
2023-03-19 17:58:12,709:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=277, solver='auto',
                tol=0.0001)
2023-03-19 17:58:12,709:INFO:create_model() successfully completed......................................
2023-03-19 17:58:12,816:INFO:SubProcess create_model() end ==================================
2023-03-19 17:58:12,817:INFO:Creating metrics dataframe
2023-03-19 17:58:12,827:INFO:Initializing Random Forest Classifier
2023-03-19 17:58:12,827:INFO:Total runtime is 0.9125486175219218 minutes
2023-03-19 17:58:12,827:INFO:SubProcess create_model() called ==================================
2023-03-19 17:58:12,827:INFO:Initializing create_model()
2023-03-19 17:58:12,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:58:12,843:INFO:Checking exceptions
2023-03-19 17:58:12,843:INFO:Importing libraries
2023-03-19 17:58:12,843:INFO:Copying training dataset
2023-03-19 17:58:12,861:INFO:Defining folds
2023-03-19 17:58:12,861:INFO:Declaring metric variables
2023-03-19 17:58:12,869:INFO:Importing untrained model
2023-03-19 17:58:12,876:INFO:Random Forest Classifier Imported successfully
2023-03-19 17:58:12,883:INFO:Starting cross validation
2023-03-19 17:58:12,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:58:14,174:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:58:14,184:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:58:15,168:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:58:15,506:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 17:58:16,605:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:16,719:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:16,960:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:17,302:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:17,430:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:17,884:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:18,708:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:58:18,827:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:58:19,126:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:58:19,569:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:58:19,633:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 17:58:23,814:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:58:29,193:INFO:Calculating mean and std
2023-03-19 17:58:29,194:INFO:Creating metrics dataframe
2023-03-19 17:58:29,878:INFO:Uploading results into container
2023-03-19 17:58:29,880:INFO:Uploading model into container now
2023-03-19 17:58:29,881:INFO:_master_model_container: 7
2023-03-19 17:58:29,881:INFO:_display_container: 2
2023-03-19 17:58:29,882:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=277, verbose=0, warm_start=False)
2023-03-19 17:58:29,882:INFO:create_model() successfully completed......................................
2023-03-19 17:58:29,988:INFO:SubProcess create_model() end ==================================
2023-03-19 17:58:29,988:INFO:Creating metrics dataframe
2023-03-19 17:58:30,001:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 17:58:30,001:INFO:Total runtime is 1.1987855871518454 minutes
2023-03-19 17:58:30,005:INFO:SubProcess create_model() called ==================================
2023-03-19 17:58:30,005:INFO:Initializing create_model()
2023-03-19 17:58:30,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:58:30,005:INFO:Checking exceptions
2023-03-19 17:58:30,005:INFO:Importing libraries
2023-03-19 17:58:30,006:INFO:Copying training dataset
2023-03-19 17:58:30,018:INFO:Defining folds
2023-03-19 17:58:30,019:INFO:Declaring metric variables
2023-03-19 17:58:30,022:INFO:Importing untrained model
2023-03-19 17:58:30,026:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 17:58:30,035:INFO:Starting cross validation
2023-03-19 17:58:30,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:58:30,991:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:30,993:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:31,055:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:31,132:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:31,136:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:31,268:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:31,358:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:31,439:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:34,513:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:34,560:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 17:58:40,057:INFO:Calculating mean and std
2023-03-19 17:58:40,057:INFO:Creating metrics dataframe
2023-03-19 17:58:41,313:INFO:Uploading results into container
2023-03-19 17:58:41,313:INFO:Uploading model into container now
2023-03-19 17:58:41,313:INFO:_master_model_container: 8
2023-03-19 17:58:41,313:INFO:_display_container: 2
2023-03-19 17:58:41,328:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 17:58:41,328:INFO:create_model() successfully completed......................................
2023-03-19 17:58:41,423:INFO:SubProcess create_model() end ==================================
2023-03-19 17:58:41,423:INFO:Creating metrics dataframe
2023-03-19 17:58:41,454:INFO:Initializing Ada Boost Classifier
2023-03-19 17:58:41,454:INFO:Total runtime is 1.389673356215159 minutes
2023-03-19 17:58:41,454:INFO:SubProcess create_model() called ==================================
2023-03-19 17:58:41,454:INFO:Initializing create_model()
2023-03-19 17:58:41,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:58:41,454:INFO:Checking exceptions
2023-03-19 17:58:41,454:INFO:Importing libraries
2023-03-19 17:58:41,454:INFO:Copying training dataset
2023-03-19 17:58:41,470:INFO:Defining folds
2023-03-19 17:58:41,470:INFO:Declaring metric variables
2023-03-19 17:58:41,486:INFO:Importing untrained model
2023-03-19 17:58:41,486:INFO:Ada Boost Classifier Imported successfully
2023-03-19 17:58:41,501:INFO:Starting cross validation
2023-03-19 17:58:41,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:58:53,689:INFO:Calculating mean and std
2023-03-19 17:58:53,704:INFO:Creating metrics dataframe
2023-03-19 17:58:54,991:INFO:Uploading results into container
2023-03-19 17:58:54,993:INFO:Uploading model into container now
2023-03-19 17:58:54,993:INFO:_master_model_container: 9
2023-03-19 17:58:54,993:INFO:_display_container: 2
2023-03-19 17:58:54,994:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=277)
2023-03-19 17:58:54,994:INFO:create_model() successfully completed......................................
2023-03-19 17:58:55,078:INFO:SubProcess create_model() end ==================================
2023-03-19 17:58:55,078:INFO:Creating metrics dataframe
2023-03-19 17:58:55,090:INFO:Initializing Gradient Boosting Classifier
2023-03-19 17:58:55,090:INFO:Total runtime is 1.6169309933980305 minutes
2023-03-19 17:58:55,096:INFO:SubProcess create_model() called ==================================
2023-03-19 17:58:55,096:INFO:Initializing create_model()
2023-03-19 17:58:55,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:58:55,096:INFO:Checking exceptions
2023-03-19 17:58:55,096:INFO:Importing libraries
2023-03-19 17:58:55,096:INFO:Copying training dataset
2023-03-19 17:58:55,113:INFO:Defining folds
2023-03-19 17:58:55,113:INFO:Declaring metric variables
2023-03-19 17:58:55,124:INFO:Importing untrained model
2023-03-19 17:58:55,128:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 17:58:55,144:INFO:Starting cross validation
2023-03-19 17:58:55,144:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:59:12,537:INFO:Calculating mean and std
2023-03-19 17:59:12,537:INFO:Creating metrics dataframe
2023-03-19 17:59:14,027:INFO:Uploading results into container
2023-03-19 17:59:14,027:INFO:Uploading model into container now
2023-03-19 17:59:14,027:INFO:_master_model_container: 10
2023-03-19 17:59:14,027:INFO:_display_container: 2
2023-03-19 17:59:14,039:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=277, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 17:59:14,039:INFO:create_model() successfully completed......................................
2023-03-19 17:59:14,132:INFO:SubProcess create_model() end ==================================
2023-03-19 17:59:14,132:INFO:Creating metrics dataframe
2023-03-19 17:59:14,139:INFO:Initializing Linear Discriminant Analysis
2023-03-19 17:59:14,139:INFO:Total runtime is 1.934415570894877 minutes
2023-03-19 17:59:14,160:INFO:SubProcess create_model() called ==================================
2023-03-19 17:59:14,160:INFO:Initializing create_model()
2023-03-19 17:59:14,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:59:14,165:INFO:Checking exceptions
2023-03-19 17:59:14,165:INFO:Importing libraries
2023-03-19 17:59:14,166:INFO:Copying training dataset
2023-03-19 17:59:14,186:INFO:Defining folds
2023-03-19 17:59:14,186:INFO:Declaring metric variables
2023-03-19 17:59:14,194:INFO:Importing untrained model
2023-03-19 17:59:14,205:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:59:14,218:INFO:Starting cross validation
2023-03-19 17:59:14,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:59:23,084:INFO:Calculating mean and std
2023-03-19 17:59:23,086:INFO:Creating metrics dataframe
2023-03-19 17:59:23,724:INFO:Uploading results into container
2023-03-19 17:59:23,725:INFO:Uploading model into container now
2023-03-19 17:59:23,726:INFO:_master_model_container: 11
2023-03-19 17:59:23,726:INFO:_display_container: 2
2023-03-19 17:59:23,726:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:59:23,726:INFO:create_model() successfully completed......................................
2023-03-19 17:59:23,800:INFO:SubProcess create_model() end ==================================
2023-03-19 17:59:23,800:INFO:Creating metrics dataframe
2023-03-19 17:59:23,814:INFO:Initializing Extra Trees Classifier
2023-03-19 17:59:23,814:INFO:Total runtime is 2.095672885576884 minutes
2023-03-19 17:59:23,819:INFO:SubProcess create_model() called ==================================
2023-03-19 17:59:23,819:INFO:Initializing create_model()
2023-03-19 17:59:23,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:59:23,819:INFO:Checking exceptions
2023-03-19 17:59:23,820:INFO:Importing libraries
2023-03-19 17:59:23,820:INFO:Copying training dataset
2023-03-19 17:59:23,832:INFO:Defining folds
2023-03-19 17:59:23,832:INFO:Declaring metric variables
2023-03-19 17:59:23,836:INFO:Importing untrained model
2023-03-19 17:59:23,842:INFO:Extra Trees Classifier Imported successfully
2023-03-19 17:59:23,848:INFO:Starting cross validation
2023-03-19 17:59:23,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:59:29,802:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:59:30,003:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 17:59:38,864:INFO:Calculating mean and std
2023-03-19 17:59:38,865:INFO:Creating metrics dataframe
2023-03-19 17:59:39,506:INFO:Uploading results into container
2023-03-19 17:59:39,507:INFO:Uploading model into container now
2023-03-19 17:59:39,508:INFO:_master_model_container: 12
2023-03-19 17:59:39,508:INFO:_display_container: 2
2023-03-19 17:59:39,508:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=277, verbose=0, warm_start=False)
2023-03-19 17:59:39,508:INFO:create_model() successfully completed......................................
2023-03-19 17:59:39,582:INFO:SubProcess create_model() end ==================================
2023-03-19 17:59:39,582:INFO:Creating metrics dataframe
2023-03-19 17:59:39,602:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 17:59:39,602:INFO:Total runtime is 2.358793306350708 minutes
2023-03-19 17:59:39,605:INFO:SubProcess create_model() called ==================================
2023-03-19 17:59:39,606:INFO:Initializing create_model()
2023-03-19 17:59:39,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:59:39,606:INFO:Checking exceptions
2023-03-19 17:59:39,606:INFO:Importing libraries
2023-03-19 17:59:39,606:INFO:Copying training dataset
2023-03-19 17:59:39,616:INFO:Defining folds
2023-03-19 17:59:39,617:INFO:Declaring metric variables
2023-03-19 17:59:39,620:INFO:Importing untrained model
2023-03-19 17:59:39,626:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 17:59:39,633:INFO:Starting cross validation
2023-03-19 17:59:39,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:59:47,602:INFO:Calculating mean and std
2023-03-19 17:59:47,603:INFO:Creating metrics dataframe
2023-03-19 17:59:48,302:INFO:Uploading results into container
2023-03-19 17:59:48,303:INFO:Uploading model into container now
2023-03-19 17:59:48,304:INFO:_master_model_container: 13
2023-03-19 17:59:48,304:INFO:_display_container: 2
2023-03-19 17:59:48,305:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=277, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 17:59:48,305:INFO:create_model() successfully completed......................................
2023-03-19 17:59:48,387:INFO:SubProcess create_model() end ==================================
2023-03-19 17:59:48,387:INFO:Creating metrics dataframe
2023-03-19 17:59:48,402:INFO:Initializing Dummy Classifier
2023-03-19 17:59:48,402:INFO:Total runtime is 2.505470085144043 minutes
2023-03-19 17:59:48,405:INFO:SubProcess create_model() called ==================================
2023-03-19 17:59:48,406:INFO:Initializing create_model()
2023-03-19 17:59:48,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573ADFC820>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:59:48,406:INFO:Checking exceptions
2023-03-19 17:59:48,406:INFO:Importing libraries
2023-03-19 17:59:48,406:INFO:Copying training dataset
2023-03-19 17:59:48,415:INFO:Defining folds
2023-03-19 17:59:48,415:INFO:Declaring metric variables
2023-03-19 17:59:48,420:INFO:Importing untrained model
2023-03-19 17:59:48,426:INFO:Dummy Classifier Imported successfully
2023-03-19 17:59:48,437:INFO:Starting cross validation
2023-03-19 17:59:48,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 17:59:49,372:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,386:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,467:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,480:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,486:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,557:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,571:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:49,572:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:52,158:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:52,172:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 17:59:56,050:INFO:Calculating mean and std
2023-03-19 17:59:56,052:INFO:Creating metrics dataframe
2023-03-19 17:59:56,690:INFO:Uploading results into container
2023-03-19 17:59:56,690:INFO:Uploading model into container now
2023-03-19 17:59:56,692:INFO:_master_model_container: 14
2023-03-19 17:59:56,692:INFO:_display_container: 2
2023-03-19 17:59:56,692:INFO:DummyClassifier(constant=None, random_state=277, strategy='prior')
2023-03-19 17:59:56,692:INFO:create_model() successfully completed......................................
2023-03-19 17:59:56,769:INFO:SubProcess create_model() end ==================================
2023-03-19 17:59:56,769:INFO:Creating metrics dataframe
2023-03-19 17:59:56,800:INFO:Initializing create_model()
2023-03-19 17:59:56,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 17:59:56,800:INFO:Checking exceptions
2023-03-19 17:59:56,803:INFO:Importing libraries
2023-03-19 17:59:56,803:INFO:Copying training dataset
2023-03-19 17:59:56,815:INFO:Defining folds
2023-03-19 17:59:56,816:INFO:Declaring metric variables
2023-03-19 17:59:56,816:INFO:Importing untrained model
2023-03-19 17:59:56,816:INFO:Declaring custom model
2023-03-19 17:59:56,817:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 17:59:56,818:INFO:Cross validation set to False
2023-03-19 17:59:56,819:INFO:Fitting Model
2023-03-19 17:59:57,902:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 17:59:57,902:INFO:create_model() successfully completed......................................
2023-03-19 17:59:57,979:INFO:Creating Dashboard logs
2023-03-19 17:59:57,983:INFO:Model: Linear Discriminant Analysis
2023-03-19 17:59:58,033:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 17:59:58,121:INFO:Initializing predict_model()
2023-03-19 17:59:58,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC2E0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002573B27C1F0>)
2023-03-19 17:59:58,121:INFO:Checking exceptions
2023-03-19 17:59:58,121:INFO:Preloading libraries
2023-03-19 17:59:58,290:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-03-19 17:59:58,922:INFO:Creating Dashboard logs
2023-03-19 17:59:58,928:INFO:Model: Ridge Classifier
2023-03-19 17:59:58,981:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 277, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 17:59:59,684:INFO:Creating Dashboard logs
2023-03-19 17:59:59,688:INFO:Model: Extra Trees Classifier
2023-03-19 17:59:59,733:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 277, 'verbose': 0, 'warm_start': False}
2023-03-19 18:00:00,427:INFO:Creating Dashboard logs
2023-03-19 18:00:00,430:INFO:Model: Logistic Regression
2023-03-19 18:00:00,456:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 277, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 18:00:01,183:INFO:Creating Dashboard logs
2023-03-19 18:00:01,186:INFO:Model: Naive Bayes
2023-03-19 18:00:01,238:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 18:00:02,022:INFO:Creating Dashboard logs
2023-03-19 18:00:02,025:INFO:Model: Random Forest Classifier
2023-03-19 18:00:02,081:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 277, 'verbose': 0, 'warm_start': False}
2023-03-19 18:00:02,867:INFO:Creating Dashboard logs
2023-03-19 18:00:02,871:INFO:Model: K Neighbors Classifier
2023-03-19 18:00:02,924:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 18:00:03,732:INFO:Creating Dashboard logs
2023-03-19 18:00:03,737:INFO:Model: str
2023-03-19 18:00:03,783:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 277}
2023-03-19 18:00:04,485:INFO:Creating Dashboard logs
2023-03-19 18:00:04,489:INFO:Model: Dummy Classifier
2023-03-19 18:00:04,534:INFO:Logged params: {'constant': None, 'random_state': 277, 'strategy': 'prior'}
2023-03-19 18:00:05,281:INFO:Creating Dashboard logs
2023-03-19 18:00:05,285:INFO:Model: Gradient Boosting Classifier
2023-03-19 18:00:05,332:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 277, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:00:06,094:INFO:Creating Dashboard logs
2023-03-19 18:00:06,096:INFO:Model: Light Gradient Boosting Machine
2023-03-19 18:00:06,141:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 277, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 18:00:06,833:INFO:Creating Dashboard logs
2023-03-19 18:00:06,841:INFO:Model: Decision Tree Classifier
2023-03-19 18:00:06,910:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 277, 'splitter': 'best'}
2023-03-19 18:00:07,607:INFO:Creating Dashboard logs
2023-03-19 18:00:07,610:INFO:Model: SVM - Linear Kernel
2023-03-19 18:00:07,655:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 277, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:00:08,391:INFO:Creating Dashboard logs
2023-03-19 18:00:08,394:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 18:00:08,441:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:00:09,193:INFO:_master_model_container: 14
2023-03-19 18:00:09,193:INFO:_display_container: 2
2023-03-19 18:00:09,193:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 18:00:09,193:INFO:compare_models() successfully completed......................................
2023-03-19 18:00:09,788:INFO:PyCaret ClassificationExperiment
2023-03-19 18:00:09,788:INFO:Logging name: adult
2023-03-19 18:00:09,788:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 18:00:09,788:INFO:version 3.0.0
2023-03-19 18:00:09,788:INFO:Initializing setup()
2023-03-19 18:00:09,788:INFO:self.USI: 41e6
2023-03-19 18:00:09,788:INFO:self._variable_keys: {'exp_name_log', 'y', 'logging_param', 'target_param', 'memory', 'X', 'is_multiclass', 'gpu_param', 'fold_groups_param', '_ml_usecase', 'X_train', 'idx', 'log_plots_param', 'fold_generator', 'fix_imbalance', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'html_param', '_available_plots', 'X_test', 'seed', 'y_train', 'fold_shuffle_param', 'data', 'n_jobs_param', 'USI'}
2023-03-19 18:00:09,788:INFO:Checking environment
2023-03-19 18:00:09,788:INFO:python_version: 3.10.0
2023-03-19 18:00:09,788:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 18:00:09,788:INFO:machine: AMD64
2023-03-19 18:00:09,788:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 18:00:09,795:INFO:Memory: svmem(total=16969424896, available=4908822528, percent=71.1, used=12060602368, free=4908822528)
2023-03-19 18:00:09,795:INFO:Physical Core: 4
2023-03-19 18:00:09,795:INFO:Logical Core: 8
2023-03-19 18:00:09,795:INFO:Checking libraries
2023-03-19 18:00:09,795:INFO:System:
2023-03-19 18:00:09,795:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 18:00:09,795:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 18:00:09,795:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 18:00:09,796:INFO:PyCaret required dependencies:
2023-03-19 18:00:09,796:INFO:                 pip: 23.0.1
2023-03-19 18:00:09,796:INFO:          setuptools: 65.6.3
2023-03-19 18:00:09,796:INFO:             pycaret: 3.0.0
2023-03-19 18:00:09,796:INFO:             IPython: 8.11.0
2023-03-19 18:00:09,796:INFO:          ipywidgets: 8.0.4
2023-03-19 18:00:09,796:INFO:                tqdm: 4.65.0
2023-03-19 18:00:09,796:INFO:               numpy: 1.23.5
2023-03-19 18:00:09,796:INFO:              pandas: 1.5.3
2023-03-19 18:00:09,796:INFO:              jinja2: 3.1.2
2023-03-19 18:00:09,796:INFO:               scipy: 1.10.1
2023-03-19 18:00:09,796:INFO:              joblib: 1.2.0
2023-03-19 18:00:09,796:INFO:             sklearn: 1.2.2
2023-03-19 18:00:09,796:INFO:                pyod: 1.0.8
2023-03-19 18:00:09,796:INFO:            imblearn: 0.10.1
2023-03-19 18:00:09,796:INFO:   category_encoders: 2.6.0
2023-03-19 18:00:09,796:INFO:            lightgbm: 3.3.5
2023-03-19 18:00:09,796:INFO:               numba: 0.56.4
2023-03-19 18:00:09,796:INFO:            requests: 2.28.2
2023-03-19 18:00:09,796:INFO:          matplotlib: 3.7.1
2023-03-19 18:00:09,796:INFO:          scikitplot: 0.3.7
2023-03-19 18:00:09,796:INFO:         yellowbrick: 1.5
2023-03-19 18:00:09,796:INFO:              plotly: 5.13.1
2023-03-19 18:00:09,796:INFO:             kaleido: 0.2.1
2023-03-19 18:00:09,796:INFO:         statsmodels: 0.13.5
2023-03-19 18:00:09,796:INFO:              sktime: 0.16.1
2023-03-19 18:00:09,796:INFO:               tbats: 1.1.2
2023-03-19 18:00:09,797:INFO:            pmdarima: 2.0.3
2023-03-19 18:00:09,797:INFO:              psutil: 5.9.4
2023-03-19 18:00:09,797:INFO:PyCaret optional dependencies:
2023-03-19 18:00:09,797:INFO:                shap: 0.41.0
2023-03-19 18:00:09,797:INFO:           interpret: Not installed
2023-03-19 18:00:09,797:INFO:                umap: Not installed
2023-03-19 18:00:09,797:INFO:    pandas_profiling: Not installed
2023-03-19 18:00:09,797:INFO:  explainerdashboard: Not installed
2023-03-19 18:00:09,797:INFO:             autoviz: Not installed
2023-03-19 18:00:09,797:INFO:           fairlearn: Not installed
2023-03-19 18:00:09,797:INFO:             xgboost: Not installed
2023-03-19 18:00:09,797:INFO:            catboost: Not installed
2023-03-19 18:00:09,797:INFO:              kmodes: Not installed
2023-03-19 18:00:09,797:INFO:             mlxtend: Not installed
2023-03-19 18:00:09,797:INFO:       statsforecast: Not installed
2023-03-19 18:00:09,797:INFO:        tune_sklearn: Not installed
2023-03-19 18:00:09,797:INFO:                 ray: Not installed
2023-03-19 18:00:09,797:INFO:            hyperopt: Not installed
2023-03-19 18:00:09,797:INFO:              optuna: Not installed
2023-03-19 18:00:09,797:INFO:               skopt: Not installed
2023-03-19 18:00:09,797:INFO:              mlflow: 2.2.2
2023-03-19 18:00:09,798:INFO:              gradio: Not installed
2023-03-19 18:00:09,798:INFO:             fastapi: Not installed
2023-03-19 18:00:09,798:INFO:             uvicorn: Not installed
2023-03-19 18:00:09,798:INFO:              m2cgen: Not installed
2023-03-19 18:00:09,798:INFO:           evidently: Not installed
2023-03-19 18:00:09,798:INFO:               fugue: Not installed
2023-03-19 18:00:09,798:INFO:           streamlit: Not installed
2023-03-19 18:00:09,798:INFO:             prophet: Not installed
2023-03-19 18:00:09,798:INFO:None
2023-03-19 18:00:09,798:INFO:Set up data.
2023-03-19 18:00:09,829:INFO:Set up train/test split.
2023-03-19 18:00:09,843:INFO:Set up index.
2023-03-19 18:00:09,843:INFO:Set up folding strategy.
2023-03-19 18:00:09,843:INFO:Assigning column types.
2023-03-19 18:00:09,850:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 18:00:09,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:00:09,892:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:00:09,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:09,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:09,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:00:09,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:00:09,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:09,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:09,999:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 18:00:10,039:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:00:10,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:00:10,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,125:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 18:00:10,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:10,254:INFO:Preparing preprocessing pipeline...
2023-03-19 18:00:10,255:INFO:Set up simple imputation.
2023-03-19 18:00:10,261:INFO:Set up encoding of ordinal features.
2023-03-19 18:00:10,263:INFO:Set up encoding of categorical features.
2023-03-19 18:00:10,263:INFO:Set up feature normalization.
2023-03-19 18:00:10,264:INFO:Set up column name cleaning.
2023-03-19 18:00:10,769:INFO:Finished creating preprocessing pipeline.
2023-03-19 18:00:10,791:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6421,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 18:00:10,791:INFO:Creating final display dataframe.
2023-03-19 18:00:11,465:INFO:Setup _display_container:                     Description            Value
0                    Session id             6421
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment     MlflowLogger
24              Experiment Name            adult
25                          USI             41e6
2023-03-19 18:00:11,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:11,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:11,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:11,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:00:11,652:INFO:Logging experiment in loggers
2023-03-19 18:00:11,745:INFO:SubProcess save_model() called ==================================
2023-03-19 18:00:11,784:INFO:Initializing save_model()
2023-03-19 18:00:11,785:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6421,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmpitinkjp6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6421,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 18:00:11,785:INFO:Adding model into prep_pipe
2023-03-19 18:00:11,788:WARNING:Only Model saved as it was a pipeline.
2023-03-19 18:00:11,805:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmpitinkjp6\Transformation Pipeline.pkl saved in current working directory
2023-03-19 18:00:11,827:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   handle_unknown='value',
                                                                   random_state=6421,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 18:00:11,827:INFO:save_model() successfully completed......................................
2023-03-19 18:00:12,758:INFO:SubProcess save_model() end ==================================
2023-03-19 18:00:12,821:INFO:setup() successfully completed in 2.37s...............
2023-03-19 18:00:12,868:INFO:Initializing compare_models()
2023-03-19 18:00:12,868:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 18:00:12,868:INFO:Checking exceptions
2023-03-19 18:00:12,868:INFO:Preparing display monitor
2023-03-19 18:00:12,916:INFO:Initializing Logistic Regression
2023-03-19 18:00:12,916:INFO:Total runtime is 0.0 minutes
2023-03-19 18:00:12,916:INFO:SubProcess create_model() called ==================================
2023-03-19 18:00:12,916:INFO:Initializing create_model()
2023-03-19 18:00:12,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:00:12,916:INFO:Checking exceptions
2023-03-19 18:00:12,916:INFO:Importing libraries
2023-03-19 18:00:12,916:INFO:Copying training dataset
2023-03-19 18:00:12,931:INFO:Defining folds
2023-03-19 18:00:12,931:INFO:Declaring metric variables
2023-03-19 18:00:12,931:INFO:Importing untrained model
2023-03-19 18:00:12,947:INFO:Logistic Regression Imported successfully
2023-03-19 18:00:12,963:INFO:Starting cross validation
2023-03-19 18:00:12,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:00:24,476:INFO:Calculating mean and std
2023-03-19 18:00:24,476:INFO:Creating metrics dataframe
2023-03-19 18:00:25,882:INFO:Uploading results into container
2023-03-19 18:00:25,882:INFO:Uploading model into container now
2023-03-19 18:00:25,893:INFO:_master_model_container: 1
2023-03-19 18:00:25,893:INFO:_display_container: 2
2023-03-19 18:00:25,893:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6421, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 18:00:25,893:INFO:create_model() successfully completed......................................
2023-03-19 18:00:26,004:INFO:SubProcess create_model() end ==================================
2023-03-19 18:00:26,004:INFO:Creating metrics dataframe
2023-03-19 18:00:26,020:INFO:Initializing K Neighbors Classifier
2023-03-19 18:00:26,020:INFO:Total runtime is 0.2184038241704305 minutes
2023-03-19 18:00:26,035:INFO:SubProcess create_model() called ==================================
2023-03-19 18:00:26,035:INFO:Initializing create_model()
2023-03-19 18:00:26,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:00:26,035:INFO:Checking exceptions
2023-03-19 18:00:26,035:INFO:Importing libraries
2023-03-19 18:00:26,035:INFO:Copying training dataset
2023-03-19 18:00:26,051:INFO:Defining folds
2023-03-19 18:00:26,051:INFO:Declaring metric variables
2023-03-19 18:00:26,051:INFO:Importing untrained model
2023-03-19 18:00:26,067:INFO:K Neighbors Classifier Imported successfully
2023-03-19 18:00:26,082:INFO:Starting cross validation
2023-03-19 18:00:26,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:00:35,477:INFO:Calculating mean and std
2023-03-19 18:00:35,478:INFO:Creating metrics dataframe
2023-03-19 18:00:36,168:INFO:Uploading results into container
2023-03-19 18:00:36,171:INFO:Uploading model into container now
2023-03-19 18:00:36,171:INFO:_master_model_container: 2
2023-03-19 18:00:36,171:INFO:_display_container: 2
2023-03-19 18:00:36,172:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 18:00:36,172:INFO:create_model() successfully completed......................................
2023-03-19 18:00:36,239:INFO:SubProcess create_model() end ==================================
2023-03-19 18:00:36,240:INFO:Creating metrics dataframe
2023-03-19 18:00:36,248:INFO:Initializing Naive Bayes
2023-03-19 18:00:36,248:INFO:Total runtime is 0.3888815561930339 minutes
2023-03-19 18:00:36,252:INFO:SubProcess create_model() called ==================================
2023-03-19 18:00:36,252:INFO:Initializing create_model()
2023-03-19 18:00:36,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:00:36,253:INFO:Checking exceptions
2023-03-19 18:00:36,253:INFO:Importing libraries
2023-03-19 18:00:36,254:INFO:Copying training dataset
2023-03-19 18:00:36,261:INFO:Defining folds
2023-03-19 18:00:36,261:INFO:Declaring metric variables
2023-03-19 18:00:36,264:INFO:Importing untrained model
2023-03-19 18:00:36,267:INFO:Naive Bayes Imported successfully
2023-03-19 18:00:36,278:INFO:Starting cross validation
2023-03-19 18:00:36,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:00:44,123:INFO:Calculating mean and std
2023-03-19 18:00:44,125:INFO:Creating metrics dataframe
2023-03-19 18:00:44,808:INFO:Uploading results into container
2023-03-19 18:00:44,808:INFO:Uploading model into container now
2023-03-19 18:00:44,809:INFO:_master_model_container: 3
2023-03-19 18:00:44,809:INFO:_display_container: 2
2023-03-19 18:00:44,809:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 18:00:44,809:INFO:create_model() successfully completed......................................
2023-03-19 18:00:44,885:INFO:SubProcess create_model() end ==================================
2023-03-19 18:00:44,885:INFO:Creating metrics dataframe
2023-03-19 18:00:44,894:INFO:Initializing Decision Tree Classifier
2023-03-19 18:00:44,894:INFO:Total runtime is 0.5329773585001628 minutes
2023-03-19 18:00:44,899:INFO:SubProcess create_model() called ==================================
2023-03-19 18:00:44,899:INFO:Initializing create_model()
2023-03-19 18:00:44,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:00:44,900:INFO:Checking exceptions
2023-03-19 18:00:44,900:INFO:Importing libraries
2023-03-19 18:00:44,900:INFO:Copying training dataset
2023-03-19 18:00:44,910:INFO:Defining folds
2023-03-19 18:00:44,910:INFO:Declaring metric variables
2023-03-19 18:00:44,914:INFO:Importing untrained model
2023-03-19 18:00:44,918:INFO:Decision Tree Classifier Imported successfully
2023-03-19 18:00:44,928:INFO:Starting cross validation
2023-03-19 18:00:44,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:00:53,095:INFO:Calculating mean and std
2023-03-19 18:00:53,097:INFO:Creating metrics dataframe
2023-03-19 18:00:53,759:INFO:Uploading results into container
2023-03-19 18:00:53,760:INFO:Uploading model into container now
2023-03-19 18:00:53,760:INFO:_master_model_container: 4
2023-03-19 18:00:53,760:INFO:_display_container: 2
2023-03-19 18:00:53,761:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6421, splitter='best')
2023-03-19 18:00:53,761:INFO:create_model() successfully completed......................................
2023-03-19 18:00:53,828:INFO:SubProcess create_model() end ==================================
2023-03-19 18:00:53,828:INFO:Creating metrics dataframe
2023-03-19 18:00:53,838:INFO:Initializing SVM - Linear Kernel
2023-03-19 18:00:53,838:INFO:Total runtime is 0.6820384740829468 minutes
2023-03-19 18:00:53,842:INFO:SubProcess create_model() called ==================================
2023-03-19 18:00:53,842:INFO:Initializing create_model()
2023-03-19 18:00:53,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:00:53,843:INFO:Checking exceptions
2023-03-19 18:00:53,843:INFO:Importing libraries
2023-03-19 18:00:53,843:INFO:Copying training dataset
2023-03-19 18:00:53,850:INFO:Defining folds
2023-03-19 18:00:53,850:INFO:Declaring metric variables
2023-03-19 18:00:53,854:INFO:Importing untrained model
2023-03-19 18:00:53,858:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 18:00:53,867:INFO:Starting cross validation
2023-03-19 18:00:53,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:00:55,772:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:55,898:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:55,921:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:55,924:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:55,985:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:56,011:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:56,014:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:56,057:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:58,926:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:00:58,986:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:01:02,398:INFO:Calculating mean and std
2023-03-19 18:01:02,399:INFO:Creating metrics dataframe
2023-03-19 18:01:03,078:INFO:Uploading results into container
2023-03-19 18:01:03,079:INFO:Uploading model into container now
2023-03-19 18:01:03,079:INFO:_master_model_container: 5
2023-03-19 18:01:03,079:INFO:_display_container: 2
2023-03-19 18:01:03,080:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6421, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 18:01:03,080:INFO:create_model() successfully completed......................................
2023-03-19 18:01:03,157:INFO:SubProcess create_model() end ==================================
2023-03-19 18:01:03,157:INFO:Creating metrics dataframe
2023-03-19 18:01:03,168:INFO:Initializing Ridge Classifier
2023-03-19 18:01:03,168:INFO:Total runtime is 0.8375410755475363 minutes
2023-03-19 18:01:03,172:INFO:SubProcess create_model() called ==================================
2023-03-19 18:01:03,172:INFO:Initializing create_model()
2023-03-19 18:01:03,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:01:03,172:INFO:Checking exceptions
2023-03-19 18:01:03,172:INFO:Importing libraries
2023-03-19 18:01:03,173:INFO:Copying training dataset
2023-03-19 18:01:03,184:INFO:Defining folds
2023-03-19 18:01:03,184:INFO:Declaring metric variables
2023-03-19 18:01:03,188:INFO:Importing untrained model
2023-03-19 18:01:03,193:INFO:Ridge Classifier Imported successfully
2023-03-19 18:01:03,203:INFO:Starting cross validation
2023-03-19 18:01:03,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:01:04,373:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,401:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,430:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,432:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,497:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,513:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,531:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:04,546:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:07,111:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:07,138:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:01:11,013:INFO:Calculating mean and std
2023-03-19 18:01:11,014:INFO:Creating metrics dataframe
2023-03-19 18:01:11,704:INFO:Uploading results into container
2023-03-19 18:01:11,705:INFO:Uploading model into container now
2023-03-19 18:01:11,705:INFO:_master_model_container: 6
2023-03-19 18:01:11,705:INFO:_display_container: 2
2023-03-19 18:01:11,706:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6421, solver='auto',
                tol=0.0001)
2023-03-19 18:01:11,706:INFO:create_model() successfully completed......................................
2023-03-19 18:01:11,777:INFO:SubProcess create_model() end ==================================
2023-03-19 18:01:11,777:INFO:Creating metrics dataframe
2023-03-19 18:01:11,790:INFO:Initializing Random Forest Classifier
2023-03-19 18:01:11,790:INFO:Total runtime is 0.9812425454457602 minutes
2023-03-19 18:01:11,795:INFO:SubProcess create_model() called ==================================
2023-03-19 18:01:11,795:INFO:Initializing create_model()
2023-03-19 18:01:11,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:01:11,796:INFO:Checking exceptions
2023-03-19 18:01:11,796:INFO:Importing libraries
2023-03-19 18:01:11,796:INFO:Copying training dataset
2023-03-19 18:01:11,810:INFO:Defining folds
2023-03-19 18:01:11,810:INFO:Declaring metric variables
2023-03-19 18:01:11,813:INFO:Importing untrained model
2023-03-19 18:01:11,817:INFO:Random Forest Classifier Imported successfully
2023-03-19 18:01:11,825:INFO:Starting cross validation
2023-03-19 18:01:11,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:01:15,602:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:15,659:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:16,565:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:16,595:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:16,632:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:16,682:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:16,704:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:01:25,576:INFO:Calculating mean and std
2023-03-19 18:01:25,577:INFO:Creating metrics dataframe
2023-03-19 18:01:26,331:INFO:Uploading results into container
2023-03-19 18:01:26,332:INFO:Uploading model into container now
2023-03-19 18:01:26,333:INFO:_master_model_container: 7
2023-03-19 18:01:26,333:INFO:_display_container: 2
2023-03-19 18:01:26,333:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6421, verbose=0, warm_start=False)
2023-03-19 18:01:26,333:INFO:create_model() successfully completed......................................
2023-03-19 18:01:26,415:INFO:SubProcess create_model() end ==================================
2023-03-19 18:01:26,415:INFO:Creating metrics dataframe
2023-03-19 18:01:26,430:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 18:01:26,430:INFO:Total runtime is 1.2252451539039613 minutes
2023-03-19 18:01:26,434:INFO:SubProcess create_model() called ==================================
2023-03-19 18:01:26,434:INFO:Initializing create_model()
2023-03-19 18:01:26,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:01:26,435:INFO:Checking exceptions
2023-03-19 18:01:26,435:INFO:Importing libraries
2023-03-19 18:01:26,435:INFO:Copying training dataset
2023-03-19 18:01:26,446:INFO:Defining folds
2023-03-19 18:01:26,446:INFO:Declaring metric variables
2023-03-19 18:01:26,450:INFO:Importing untrained model
2023-03-19 18:01:26,456:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 18:01:26,465:INFO:Starting cross validation
2023-03-19 18:01:26,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:01:27,516:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:27,575:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:27,580:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:27,754:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:27,948:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:28,005:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:28,032:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:28,180:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:31,467:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:31,542:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:01:36,217:INFO:Calculating mean and std
2023-03-19 18:01:36,218:INFO:Creating metrics dataframe
2023-03-19 18:01:37,180:INFO:Uploading results into container
2023-03-19 18:01:37,181:INFO:Uploading model into container now
2023-03-19 18:01:37,181:INFO:_master_model_container: 8
2023-03-19 18:01:37,181:INFO:_display_container: 2
2023-03-19 18:01:37,182:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 18:01:37,182:INFO:create_model() successfully completed......................................
2023-03-19 18:01:37,254:INFO:SubProcess create_model() end ==================================
2023-03-19 18:01:37,254:INFO:Creating metrics dataframe
2023-03-19 18:01:37,267:INFO:Initializing Ada Boost Classifier
2023-03-19 18:01:37,268:INFO:Total runtime is 1.4058738589286806 minutes
2023-03-19 18:01:37,271:INFO:SubProcess create_model() called ==================================
2023-03-19 18:01:37,272:INFO:Initializing create_model()
2023-03-19 18:01:37,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:01:37,272:INFO:Checking exceptions
2023-03-19 18:01:37,272:INFO:Importing libraries
2023-03-19 18:01:37,272:INFO:Copying training dataset
2023-03-19 18:01:37,282:INFO:Defining folds
2023-03-19 18:01:37,282:INFO:Declaring metric variables
2023-03-19 18:01:37,285:INFO:Importing untrained model
2023-03-19 18:01:37,290:INFO:Ada Boost Classifier Imported successfully
2023-03-19 18:01:37,299:INFO:Starting cross validation
2023-03-19 18:01:37,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:01:51,820:INFO:Calculating mean and std
2023-03-19 18:01:51,820:INFO:Creating metrics dataframe
2023-03-19 18:01:53,286:INFO:Uploading results into container
2023-03-19 18:01:53,287:INFO:Uploading model into container now
2023-03-19 18:01:53,288:INFO:_master_model_container: 9
2023-03-19 18:01:53,288:INFO:_display_container: 2
2023-03-19 18:01:53,290:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6421)
2023-03-19 18:01:53,290:INFO:create_model() successfully completed......................................
2023-03-19 18:01:53,378:INFO:SubProcess create_model() end ==================================
2023-03-19 18:01:53,378:INFO:Creating metrics dataframe
2023-03-19 18:01:53,390:INFO:Initializing Gradient Boosting Classifier
2023-03-19 18:01:53,391:INFO:Total runtime is 1.6745848496754965 minutes
2023-03-19 18:01:53,397:INFO:SubProcess create_model() called ==================================
2023-03-19 18:01:53,397:INFO:Initializing create_model()
2023-03-19 18:01:53,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:01:53,398:INFO:Checking exceptions
2023-03-19 18:01:53,398:INFO:Importing libraries
2023-03-19 18:01:53,398:INFO:Copying training dataset
2023-03-19 18:01:53,407:INFO:Defining folds
2023-03-19 18:01:53,407:INFO:Declaring metric variables
2023-03-19 18:01:53,411:INFO:Importing untrained model
2023-03-19 18:01:53,420:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 18:01:53,429:INFO:Starting cross validation
2023-03-19 18:01:53,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:02:13,001:INFO:Calculating mean and std
2023-03-19 18:02:13,003:INFO:Creating metrics dataframe
2023-03-19 18:02:14,086:INFO:Uploading results into container
2023-03-19 18:02:14,086:INFO:Uploading model into container now
2023-03-19 18:02:14,087:INFO:_master_model_container: 10
2023-03-19 18:02:14,087:INFO:_display_container: 2
2023-03-19 18:02:14,087:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6421, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 18:02:14,087:INFO:create_model() successfully completed......................................
2023-03-19 18:02:14,184:INFO:SubProcess create_model() end ==================================
2023-03-19 18:02:14,184:INFO:Creating metrics dataframe
2023-03-19 18:02:14,205:INFO:Initializing Linear Discriminant Analysis
2023-03-19 18:02:14,205:INFO:Total runtime is 2.0214965383211774 minutes
2023-03-19 18:02:14,212:INFO:SubProcess create_model() called ==================================
2023-03-19 18:02:14,212:INFO:Initializing create_model()
2023-03-19 18:02:14,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:02:14,213:INFO:Checking exceptions
2023-03-19 18:02:14,213:INFO:Importing libraries
2023-03-19 18:02:14,213:INFO:Copying training dataset
2023-03-19 18:02:14,229:INFO:Defining folds
2023-03-19 18:02:14,229:INFO:Declaring metric variables
2023-03-19 18:02:14,232:INFO:Importing untrained model
2023-03-19 18:02:14,240:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 18:02:14,253:INFO:Starting cross validation
2023-03-19 18:02:14,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:02:24,648:INFO:Calculating mean and std
2023-03-19 18:02:24,652:INFO:Creating metrics dataframe
2023-03-19 18:02:25,447:INFO:Uploading results into container
2023-03-19 18:02:25,448:INFO:Uploading model into container now
2023-03-19 18:02:25,448:INFO:_master_model_container: 11
2023-03-19 18:02:25,448:INFO:_display_container: 2
2023-03-19 18:02:25,449:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 18:02:25,449:INFO:create_model() successfully completed......................................
2023-03-19 18:02:25,520:INFO:SubProcess create_model() end ==================================
2023-03-19 18:02:25,520:INFO:Creating metrics dataframe
2023-03-19 18:02:25,531:INFO:Initializing Extra Trees Classifier
2023-03-19 18:02:25,531:INFO:Total runtime is 2.2102622230847677 minutes
2023-03-19 18:02:25,534:INFO:SubProcess create_model() called ==================================
2023-03-19 18:02:25,535:INFO:Initializing create_model()
2023-03-19 18:02:25,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:02:25,535:INFO:Checking exceptions
2023-03-19 18:02:25,535:INFO:Importing libraries
2023-03-19 18:02:25,535:INFO:Copying training dataset
2023-03-19 18:02:25,544:INFO:Defining folds
2023-03-19 18:02:25,544:INFO:Declaring metric variables
2023-03-19 18:02:25,548:INFO:Importing untrained model
2023-03-19 18:02:25,552:INFO:Extra Trees Classifier Imported successfully
2023-03-19 18:02:25,560:INFO:Starting cross validation
2023-03-19 18:02:25,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:02:31,633:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:02:31,634:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:02:32,070:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:02:33,974:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:02:42,093:INFO:Calculating mean and std
2023-03-19 18:02:42,094:INFO:Creating metrics dataframe
2023-03-19 18:02:42,868:INFO:Uploading results into container
2023-03-19 18:02:42,868:INFO:Uploading model into container now
2023-03-19 18:02:42,869:INFO:_master_model_container: 12
2023-03-19 18:02:42,869:INFO:_display_container: 2
2023-03-19 18:02:42,869:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6421, verbose=0, warm_start=False)
2023-03-19 18:02:42,870:INFO:create_model() successfully completed......................................
2023-03-19 18:02:42,939:INFO:SubProcess create_model() end ==================================
2023-03-19 18:02:42,940:INFO:Creating metrics dataframe
2023-03-19 18:02:42,951:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 18:02:42,951:INFO:Total runtime is 2.500593701998393 minutes
2023-03-19 18:02:42,954:INFO:SubProcess create_model() called ==================================
2023-03-19 18:02:42,955:INFO:Initializing create_model()
2023-03-19 18:02:42,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:02:42,955:INFO:Checking exceptions
2023-03-19 18:02:42,955:INFO:Importing libraries
2023-03-19 18:02:42,956:INFO:Copying training dataset
2023-03-19 18:02:42,965:INFO:Defining folds
2023-03-19 18:02:42,965:INFO:Declaring metric variables
2023-03-19 18:02:42,968:INFO:Importing untrained model
2023-03-19 18:02:42,972:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 18:02:42,981:INFO:Starting cross validation
2023-03-19 18:02:42,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:02:52,380:INFO:Calculating mean and std
2023-03-19 18:02:52,381:INFO:Creating metrics dataframe
2023-03-19 18:02:53,445:INFO:Uploading results into container
2023-03-19 18:02:53,446:INFO:Uploading model into container now
2023-03-19 18:02:53,446:INFO:_master_model_container: 13
2023-03-19 18:02:53,447:INFO:_display_container: 2
2023-03-19 18:02:53,447:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6421, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 18:02:53,447:INFO:create_model() successfully completed......................................
2023-03-19 18:02:53,526:INFO:SubProcess create_model() end ==================================
2023-03-19 18:02:53,527:INFO:Creating metrics dataframe
2023-03-19 18:02:53,545:INFO:Initializing Dummy Classifier
2023-03-19 18:02:53,545:INFO:Total runtime is 2.677157862981161 minutes
2023-03-19 18:02:53,549:INFO:SubProcess create_model() called ==================================
2023-03-19 18:02:53,549:INFO:Initializing create_model()
2023-03-19 18:02:53,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573819BD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:02:53,550:INFO:Checking exceptions
2023-03-19 18:02:53,550:INFO:Importing libraries
2023-03-19 18:02:53,550:INFO:Copying training dataset
2023-03-19 18:02:53,561:INFO:Defining folds
2023-03-19 18:02:53,561:INFO:Declaring metric variables
2023-03-19 18:02:53,565:INFO:Importing untrained model
2023-03-19 18:02:53,573:INFO:Dummy Classifier Imported successfully
2023-03-19 18:02:53,581:INFO:Starting cross validation
2023-03-19 18:02:53,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:02:55,221:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:55,503:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:55,808:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:56,196:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:56,324:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:56,354:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:56,407:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:02:56,413:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:03:01,316:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:03:01,605:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:03:11,223:INFO:Calculating mean and std
2023-03-19 18:03:11,224:INFO:Creating metrics dataframe
2023-03-19 18:03:12,484:INFO:Uploading results into container
2023-03-19 18:03:12,485:INFO:Uploading model into container now
2023-03-19 18:03:12,486:INFO:_master_model_container: 14
2023-03-19 18:03:12,486:INFO:_display_container: 2
2023-03-19 18:03:12,486:INFO:DummyClassifier(constant=None, random_state=6421, strategy='prior')
2023-03-19 18:03:12,486:INFO:create_model() successfully completed......................................
2023-03-19 18:03:12,565:INFO:SubProcess create_model() end ==================================
2023-03-19 18:03:12,565:INFO:Creating metrics dataframe
2023-03-19 18:03:12,591:INFO:Initializing create_model()
2023-03-19 18:03:12,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6421, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:03:12,592:INFO:Checking exceptions
2023-03-19 18:03:12,594:INFO:Importing libraries
2023-03-19 18:03:12,594:INFO:Copying training dataset
2023-03-19 18:03:12,604:INFO:Defining folds
2023-03-19 18:03:12,604:INFO:Declaring metric variables
2023-03-19 18:03:12,604:INFO:Importing untrained model
2023-03-19 18:03:12,604:INFO:Declaring custom model
2023-03-19 18:03:12,604:INFO:Logistic Regression Imported successfully
2023-03-19 18:03:12,606:INFO:Cross validation set to False
2023-03-19 18:03:12,606:INFO:Fitting Model
2023-03-19 18:03:13,797:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6421, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 18:03:13,797:INFO:create_model() successfully completed......................................
2023-03-19 18:03:13,881:INFO:Creating Dashboard logs
2023-03-19 18:03:13,887:INFO:Model: Logistic Regression
2023-03-19 18:03:13,942:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 6421, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 18:03:14,055:INFO:Initializing predict_model()
2023-03-19 18:03:14,055:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573ADFC4C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6421, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002573B5C12D0>)
2023-03-19 18:03:14,055:INFO:Checking exceptions
2023-03-19 18:03:14,055:INFO:Preloading libraries
2023-03-19 18:03:15,051:INFO:Creating Dashboard logs
2023-03-19 18:03:15,056:INFO:Model: SVM - Linear Kernel
2023-03-19 18:03:15,105:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 6421, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:03:16,144:INFO:Creating Dashboard logs
2023-03-19 18:03:16,150:INFO:Model: Linear Discriminant Analysis
2023-03-19 18:03:16,208:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:03:17,111:INFO:Creating Dashboard logs
2023-03-19 18:03:17,119:INFO:Model: Ridge Classifier
2023-03-19 18:03:17,178:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 6421, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 18:03:18,190:INFO:Creating Dashboard logs
2023-03-19 18:03:18,198:INFO:Model: Extra Trees Classifier
2023-03-19 18:03:18,281:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6421, 'verbose': 0, 'warm_start': False}
2023-03-19 18:03:19,341:INFO:Creating Dashboard logs
2023-03-19 18:03:19,346:INFO:Model: K Neighbors Classifier
2023-03-19 18:03:19,391:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 18:03:20,275:INFO:Creating Dashboard logs
2023-03-19 18:03:20,279:INFO:Model: Random Forest Classifier
2023-03-19 18:03:20,344:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6421, 'verbose': 0, 'warm_start': False}
2023-03-19 18:03:21,218:INFO:Creating Dashboard logs
2023-03-19 18:03:21,223:INFO:Model: str
2023-03-19 18:03:21,280:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 6421}
2023-03-19 18:03:22,190:INFO:Creating Dashboard logs
2023-03-19 18:03:22,196:INFO:Model: Dummy Classifier
2023-03-19 18:03:22,251:INFO:Logged params: {'constant': None, 'random_state': 6421, 'strategy': 'prior'}
2023-03-19 18:03:23,138:INFO:Creating Dashboard logs
2023-03-19 18:03:23,147:INFO:Model: Light Gradient Boosting Machine
2023-03-19 18:03:23,204:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6421, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 18:03:24,099:INFO:Creating Dashboard logs
2023-03-19 18:03:24,103:INFO:Model: Decision Tree Classifier
2023-03-19 18:03:24,155:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 6421, 'splitter': 'best'}
2023-03-19 18:03:25,013:INFO:Creating Dashboard logs
2023-03-19 18:03:25,016:INFO:Model: Gradient Boosting Classifier
2023-03-19 18:03:25,072:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 6421, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:03:25,924:INFO:Creating Dashboard logs
2023-03-19 18:03:25,927:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 18:03:25,976:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:03:26,833:INFO:Creating Dashboard logs
2023-03-19 18:03:26,841:INFO:Model: Naive Bayes
2023-03-19 18:03:26,895:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 18:03:27,755:INFO:_master_model_container: 14
2023-03-19 18:03:27,755:INFO:_display_container: 2
2023-03-19 18:03:27,756:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6421, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 18:03:27,756:INFO:compare_models() successfully completed......................................
2023-03-19 18:03:28,458:INFO:PyCaret ClassificationExperiment
2023-03-19 18:03:28,458:INFO:Logging name: adult-dataset
2023-03-19 18:03:28,458:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 18:03:28,458:INFO:version 3.0.0
2023-03-19 18:03:28,458:INFO:Initializing setup()
2023-03-19 18:03:28,458:INFO:self.USI: 3335
2023-03-19 18:03:28,459:INFO:self._variable_keys: {'exp_name_log', 'y', 'logging_param', 'target_param', 'memory', 'X', 'is_multiclass', 'gpu_param', 'fold_groups_param', '_ml_usecase', 'X_train', 'idx', 'log_plots_param', 'fold_generator', 'fix_imbalance', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'html_param', '_available_plots', 'X_test', 'seed', 'y_train', 'fold_shuffle_param', 'data', 'n_jobs_param', 'USI'}
2023-03-19 18:03:28,459:INFO:Checking environment
2023-03-19 18:03:28,459:INFO:python_version: 3.10.0
2023-03-19 18:03:28,459:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 18:03:28,459:INFO:machine: AMD64
2023-03-19 18:03:28,459:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 18:03:28,465:INFO:Memory: svmem(total=16969424896, available=4919472128, percent=71.0, used=12049952768, free=4919472128)
2023-03-19 18:03:28,465:INFO:Physical Core: 4
2023-03-19 18:03:28,465:INFO:Logical Core: 8
2023-03-19 18:03:28,465:INFO:Checking libraries
2023-03-19 18:03:28,465:INFO:System:
2023-03-19 18:03:28,465:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 18:03:28,466:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 18:03:28,466:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 18:03:28,466:INFO:PyCaret required dependencies:
2023-03-19 18:03:28,466:INFO:                 pip: 23.0.1
2023-03-19 18:03:28,466:INFO:          setuptools: 65.6.3
2023-03-19 18:03:28,466:INFO:             pycaret: 3.0.0
2023-03-19 18:03:28,466:INFO:             IPython: 8.11.0
2023-03-19 18:03:28,466:INFO:          ipywidgets: 8.0.4
2023-03-19 18:03:28,466:INFO:                tqdm: 4.65.0
2023-03-19 18:03:28,466:INFO:               numpy: 1.23.5
2023-03-19 18:03:28,466:INFO:              pandas: 1.5.3
2023-03-19 18:03:28,466:INFO:              jinja2: 3.1.2
2023-03-19 18:03:28,466:INFO:               scipy: 1.10.1
2023-03-19 18:03:28,466:INFO:              joblib: 1.2.0
2023-03-19 18:03:28,466:INFO:             sklearn: 1.2.2
2023-03-19 18:03:28,466:INFO:                pyod: 1.0.8
2023-03-19 18:03:28,466:INFO:            imblearn: 0.10.1
2023-03-19 18:03:28,466:INFO:   category_encoders: 2.6.0
2023-03-19 18:03:28,466:INFO:            lightgbm: 3.3.5
2023-03-19 18:03:28,466:INFO:               numba: 0.56.4
2023-03-19 18:03:28,466:INFO:            requests: 2.28.2
2023-03-19 18:03:28,466:INFO:          matplotlib: 3.7.1
2023-03-19 18:03:28,466:INFO:          scikitplot: 0.3.7
2023-03-19 18:03:28,466:INFO:         yellowbrick: 1.5
2023-03-19 18:03:28,466:INFO:              plotly: 5.13.1
2023-03-19 18:03:28,467:INFO:             kaleido: 0.2.1
2023-03-19 18:03:28,467:INFO:         statsmodels: 0.13.5
2023-03-19 18:03:28,467:INFO:              sktime: 0.16.1
2023-03-19 18:03:28,467:INFO:               tbats: 1.1.2
2023-03-19 18:03:28,467:INFO:            pmdarima: 2.0.3
2023-03-19 18:03:28,467:INFO:              psutil: 5.9.4
2023-03-19 18:03:28,467:INFO:PyCaret optional dependencies:
2023-03-19 18:03:28,467:INFO:                shap: 0.41.0
2023-03-19 18:03:28,467:INFO:           interpret: Not installed
2023-03-19 18:03:28,467:INFO:                umap: Not installed
2023-03-19 18:03:28,467:INFO:    pandas_profiling: Not installed
2023-03-19 18:03:28,467:INFO:  explainerdashboard: Not installed
2023-03-19 18:03:28,467:INFO:             autoviz: Not installed
2023-03-19 18:03:28,467:INFO:           fairlearn: Not installed
2023-03-19 18:03:28,467:INFO:             xgboost: Not installed
2023-03-19 18:03:28,467:INFO:            catboost: Not installed
2023-03-19 18:03:28,467:INFO:              kmodes: Not installed
2023-03-19 18:03:28,467:INFO:             mlxtend: Not installed
2023-03-19 18:03:28,467:INFO:       statsforecast: Not installed
2023-03-19 18:03:28,467:INFO:        tune_sklearn: Not installed
2023-03-19 18:03:28,467:INFO:                 ray: Not installed
2023-03-19 18:03:28,467:INFO:            hyperopt: Not installed
2023-03-19 18:03:28,468:INFO:              optuna: Not installed
2023-03-19 18:03:28,468:INFO:               skopt: Not installed
2023-03-19 18:03:28,468:INFO:              mlflow: 2.2.2
2023-03-19 18:03:28,468:INFO:              gradio: Not installed
2023-03-19 18:03:28,468:INFO:             fastapi: Not installed
2023-03-19 18:03:28,468:INFO:             uvicorn: Not installed
2023-03-19 18:03:28,468:INFO:              m2cgen: Not installed
2023-03-19 18:03:28,468:INFO:           evidently: Not installed
2023-03-19 18:03:28,468:INFO:               fugue: Not installed
2023-03-19 18:03:28,468:INFO:           streamlit: Not installed
2023-03-19 18:03:28,468:INFO:             prophet: Not installed
2023-03-19 18:03:28,468:INFO:None
2023-03-19 18:03:28,468:INFO:Set up data.
2023-03-19 18:03:28,505:INFO:Set up train/test split.
2023-03-19 18:03:28,518:INFO:Set up index.
2023-03-19 18:03:28,518:INFO:Set up folding strategy.
2023-03-19 18:03:28,518:INFO:Assigning column types.
2023-03-19 18:03:28,525:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 18:03:28,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:03:28,588:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:03:28,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,674:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:03:28,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:03:28,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,731:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 18:03:28,783:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:03:28,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,860:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:03:28,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,892:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 18:03:28,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:28,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:29,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:29,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:29,045:INFO:Preparing preprocessing pipeline...
2023-03-19 18:03:29,047:INFO:Set up simple imputation.
2023-03-19 18:03:29,053:INFO:Set up encoding of ordinal features.
2023-03-19 18:03:29,055:INFO:Set up encoding of categorical features.
2023-03-19 18:03:29,055:INFO:Set up column name cleaning.
2023-03-19 18:03:29,606:INFO:Finished creating preprocessing pipeline.
2023-03-19 18:03:29,621:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8998,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 18:03:29,621:INFO:Creating final display dataframe.
2023-03-19 18:03:30,304:INFO:Setup _display_container:                     Description            Value
0                    Session id             8998
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (32561, 65)
5   Transformed train set shape      (22792, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17               Fold Generator  StratifiedKFold
18                  Fold Number               10
19                     CPU Jobs               -1
20                      Use GPU            False
21               Log Experiment     MlflowLogger
22              Experiment Name    adult-dataset
23                          USI             3335
2023-03-19 18:03:30,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:30,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:30,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:30,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:03:30,455:INFO:Logging experiment in loggers
2023-03-19 18:03:30,576:INFO:SubProcess save_model() called ==================================
2023-03-19 18:03:30,607:INFO:Initializing save_model()
2023-03-19 18:03:30,607:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8998,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmp7vk8x05b\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8998,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 18:03:30,607:INFO:Adding model into prep_pipe
2023-03-19 18:03:30,608:WARNING:Only Model saved as it was a pipeline.
2023-03-19 18:03:30,618:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmp7vk8x05b\Transformation Pipeline.pkl saved in current working directory
2023-03-19 18:03:30,635:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                 TransformerWrapper(exclude=None, include=['native-country'],
                                    transformer=LeaveOneOutEncoder(cols=['native-country'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8998,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 18:03:30,636:INFO:save_model() successfully completed......................................
2023-03-19 18:03:31,324:INFO:SubProcess save_model() end ==================================
2023-03-19 18:03:31,381:INFO:setup() successfully completed in 2.63s...............
2023-03-19 18:03:31,425:INFO:Initializing compare_models()
2023-03-19 18:03:31,425:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 18:03:31,426:INFO:Checking exceptions
2023-03-19 18:03:31,441:INFO:Preparing display monitor
2023-03-19 18:03:31,466:INFO:Initializing Logistic Regression
2023-03-19 18:03:31,467:INFO:Total runtime is 1.668532689412435e-05 minutes
2023-03-19 18:03:31,471:INFO:SubProcess create_model() called ==================================
2023-03-19 18:03:31,471:INFO:Initializing create_model()
2023-03-19 18:03:31,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:03:31,471:INFO:Checking exceptions
2023-03-19 18:03:31,472:INFO:Importing libraries
2023-03-19 18:03:31,472:INFO:Copying training dataset
2023-03-19 18:03:31,481:INFO:Defining folds
2023-03-19 18:03:31,481:INFO:Declaring metric variables
2023-03-19 18:03:31,485:INFO:Importing untrained model
2023-03-19 18:03:31,489:INFO:Logistic Regression Imported successfully
2023-03-19 18:03:31,501:INFO:Starting cross validation
2023-03-19 18:03:31,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:03:56,899:INFO:Calculating mean and std
2023-03-19 18:03:56,907:INFO:Creating metrics dataframe
2023-03-19 18:03:59,672:INFO:Uploading results into container
2023-03-19 18:03:59,680:INFO:Uploading model into container now
2023-03-19 18:03:59,680:INFO:_master_model_container: 1
2023-03-19 18:03:59,680:INFO:_display_container: 2
2023-03-19 18:03:59,680:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8998, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 18:03:59,680:INFO:create_model() successfully completed......................................
2023-03-19 18:03:59,842:INFO:SubProcess create_model() end ==================================
2023-03-19 18:03:59,842:INFO:Creating metrics dataframe
2023-03-19 18:03:59,875:INFO:Initializing K Neighbors Classifier
2023-03-19 18:03:59,875:INFO:Total runtime is 0.47349295218785603 minutes
2023-03-19 18:03:59,883:INFO:SubProcess create_model() called ==================================
2023-03-19 18:03:59,883:INFO:Initializing create_model()
2023-03-19 18:03:59,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:03:59,883:INFO:Checking exceptions
2023-03-19 18:03:59,883:INFO:Importing libraries
2023-03-19 18:03:59,883:INFO:Copying training dataset
2023-03-19 18:03:59,918:INFO:Defining folds
2023-03-19 18:03:59,924:INFO:Declaring metric variables
2023-03-19 18:03:59,937:INFO:Importing untrained model
2023-03-19 18:03:59,941:INFO:K Neighbors Classifier Imported successfully
2023-03-19 18:03:59,967:INFO:Starting cross validation
2023-03-19 18:03:59,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:04:12,359:INFO:Calculating mean and std
2023-03-19 18:04:12,359:INFO:Creating metrics dataframe
2023-03-19 18:04:13,358:INFO:Uploading results into container
2023-03-19 18:04:13,358:INFO:Uploading model into container now
2023-03-19 18:04:13,358:INFO:_master_model_container: 2
2023-03-19 18:04:13,358:INFO:_display_container: 2
2023-03-19 18:04:13,358:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 18:04:13,358:INFO:create_model() successfully completed......................................
2023-03-19 18:04:13,446:INFO:SubProcess create_model() end ==================================
2023-03-19 18:04:13,446:INFO:Creating metrics dataframe
2023-03-19 18:04:13,462:INFO:Initializing Naive Bayes
2023-03-19 18:04:13,462:INFO:Total runtime is 0.6999429623285929 minutes
2023-03-19 18:04:13,462:INFO:SubProcess create_model() called ==================================
2023-03-19 18:04:13,462:INFO:Initializing create_model()
2023-03-19 18:04:13,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:04:13,462:INFO:Checking exceptions
2023-03-19 18:04:13,462:INFO:Importing libraries
2023-03-19 18:04:13,462:INFO:Copying training dataset
2023-03-19 18:04:13,470:INFO:Defining folds
2023-03-19 18:04:13,470:INFO:Declaring metric variables
2023-03-19 18:04:13,483:INFO:Importing untrained model
2023-03-19 18:04:13,486:INFO:Naive Bayes Imported successfully
2023-03-19 18:04:13,494:INFO:Starting cross validation
2023-03-19 18:04:13,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:04:23,063:INFO:Calculating mean and std
2023-03-19 18:04:23,071:INFO:Creating metrics dataframe
2023-03-19 18:04:24,026:INFO:Uploading results into container
2023-03-19 18:04:24,026:INFO:Uploading model into container now
2023-03-19 18:04:24,040:INFO:_master_model_container: 3
2023-03-19 18:04:24,040:INFO:_display_container: 2
2023-03-19 18:04:24,041:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 18:04:24,041:INFO:create_model() successfully completed......................................
2023-03-19 18:04:24,137:INFO:SubProcess create_model() end ==================================
2023-03-19 18:04:24,137:INFO:Creating metrics dataframe
2023-03-19 18:04:24,146:INFO:Initializing Decision Tree Classifier
2023-03-19 18:04:24,146:INFO:Total runtime is 0.8780011534690857 minutes
2023-03-19 18:04:24,153:INFO:SubProcess create_model() called ==================================
2023-03-19 18:04:24,153:INFO:Initializing create_model()
2023-03-19 18:04:24,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:04:24,153:INFO:Checking exceptions
2023-03-19 18:04:24,153:INFO:Importing libraries
2023-03-19 18:04:24,153:INFO:Copying training dataset
2023-03-19 18:04:24,169:INFO:Defining folds
2023-03-19 18:04:24,169:INFO:Declaring metric variables
2023-03-19 18:04:24,169:INFO:Importing untrained model
2023-03-19 18:04:24,177:INFO:Decision Tree Classifier Imported successfully
2023-03-19 18:04:24,193:INFO:Starting cross validation
2023-03-19 18:04:24,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:04:33,982:INFO:Calculating mean and std
2023-03-19 18:04:33,982:INFO:Creating metrics dataframe
2023-03-19 18:04:34,915:INFO:Uploading results into container
2023-03-19 18:04:34,915:INFO:Uploading model into container now
2023-03-19 18:04:34,915:INFO:_master_model_container: 4
2023-03-19 18:04:34,915:INFO:_display_container: 2
2023-03-19 18:04:34,923:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8998, splitter='best')
2023-03-19 18:04:34,923:INFO:create_model() successfully completed......................................
2023-03-19 18:04:35,004:INFO:SubProcess create_model() end ==================================
2023-03-19 18:04:35,004:INFO:Creating metrics dataframe
2023-03-19 18:04:35,020:INFO:Initializing SVM - Linear Kernel
2023-03-19 18:04:35,020:INFO:Total runtime is 1.0592430353164672 minutes
2023-03-19 18:04:35,028:INFO:SubProcess create_model() called ==================================
2023-03-19 18:04:35,028:INFO:Initializing create_model()
2023-03-19 18:04:35,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:04:35,028:INFO:Checking exceptions
2023-03-19 18:04:35,028:INFO:Importing libraries
2023-03-19 18:04:35,028:INFO:Copying training dataset
2023-03-19 18:04:35,044:INFO:Defining folds
2023-03-19 18:04:35,044:INFO:Declaring metric variables
2023-03-19 18:04:35,052:INFO:Importing untrained model
2023-03-19 18:04:35,060:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 18:04:35,068:INFO:Starting cross validation
2023-03-19 18:04:35,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:04:38,078:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:38,319:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:38,335:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:38,449:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:38,628:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:38,749:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:38,919:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:39,142:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:41,649:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:41,843:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:04:47,133:INFO:Calculating mean and std
2023-03-19 18:04:47,133:INFO:Creating metrics dataframe
2023-03-19 18:04:48,080:INFO:Uploading results into container
2023-03-19 18:04:48,080:INFO:Uploading model into container now
2023-03-19 18:04:48,080:INFO:_master_model_container: 5
2023-03-19 18:04:48,080:INFO:_display_container: 2
2023-03-19 18:04:48,080:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8998, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 18:04:48,080:INFO:create_model() successfully completed......................................
2023-03-19 18:04:48,168:INFO:SubProcess create_model() end ==================================
2023-03-19 18:04:48,168:INFO:Creating metrics dataframe
2023-03-19 18:04:48,184:INFO:Initializing Ridge Classifier
2023-03-19 18:04:48,184:INFO:Total runtime is 1.2786409695943197 minutes
2023-03-19 18:04:48,184:INFO:SubProcess create_model() called ==================================
2023-03-19 18:04:48,184:INFO:Initializing create_model()
2023-03-19 18:04:48,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:04:48,184:INFO:Checking exceptions
2023-03-19 18:04:48,184:INFO:Importing libraries
2023-03-19 18:04:48,184:INFO:Copying training dataset
2023-03-19 18:04:48,200:INFO:Defining folds
2023-03-19 18:04:48,200:INFO:Declaring metric variables
2023-03-19 18:04:48,208:INFO:Importing untrained model
2023-03-19 18:04:48,212:INFO:Ridge Classifier Imported successfully
2023-03-19 18:04:48,224:INFO:Starting cross validation
2023-03-19 18:04:48,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:04:49,236:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,236:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,252:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,260:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,260:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,276:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,302:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:49,315:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:51,661:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:51,717:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:04:58,166:INFO:Calculating mean and std
2023-03-19 18:04:58,166:INFO:Creating metrics dataframe
2023-03-19 18:04:59,138:INFO:Uploading results into container
2023-03-19 18:04:59,138:INFO:Uploading model into container now
2023-03-19 18:04:59,138:INFO:_master_model_container: 6
2023-03-19 18:04:59,138:INFO:_display_container: 2
2023-03-19 18:04:59,146:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8998, solver='auto',
                tol=0.0001)
2023-03-19 18:04:59,146:INFO:create_model() successfully completed......................................
2023-03-19 18:04:59,226:INFO:SubProcess create_model() end ==================================
2023-03-19 18:04:59,226:INFO:Creating metrics dataframe
2023-03-19 18:04:59,244:INFO:Initializing Random Forest Classifier
2023-03-19 18:04:59,244:INFO:Total runtime is 1.4629703760147095 minutes
2023-03-19 18:04:59,245:INFO:SubProcess create_model() called ==================================
2023-03-19 18:04:59,245:INFO:Initializing create_model()
2023-03-19 18:04:59,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:04:59,245:INFO:Checking exceptions
2023-03-19 18:04:59,245:INFO:Importing libraries
2023-03-19 18:04:59,251:INFO:Copying training dataset
2023-03-19 18:04:59,259:INFO:Defining folds
2023-03-19 18:04:59,259:INFO:Declaring metric variables
2023-03-19 18:04:59,267:INFO:Importing untrained model
2023-03-19 18:04:59,267:INFO:Random Forest Classifier Imported successfully
2023-03-19 18:04:59,283:INFO:Starting cross validation
2023-03-19 18:04:59,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:05:02,961:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:05:03,060:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:05:14,097:INFO:Calculating mean and std
2023-03-19 18:05:14,105:INFO:Creating metrics dataframe
2023-03-19 18:05:15,060:INFO:Uploading results into container
2023-03-19 18:05:15,060:INFO:Uploading model into container now
2023-03-19 18:05:15,060:INFO:_master_model_container: 7
2023-03-19 18:05:15,060:INFO:_display_container: 2
2023-03-19 18:05:15,060:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8998, verbose=0, warm_start=False)
2023-03-19 18:05:15,060:INFO:create_model() successfully completed......................................
2023-03-19 18:05:15,148:INFO:SubProcess create_model() end ==================================
2023-03-19 18:05:15,148:INFO:Creating metrics dataframe
2023-03-19 18:05:15,164:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 18:05:15,164:INFO:Total runtime is 1.728311558564504 minutes
2023-03-19 18:05:15,172:INFO:SubProcess create_model() called ==================================
2023-03-19 18:05:15,172:INFO:Initializing create_model()
2023-03-19 18:05:15,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:05:15,172:INFO:Checking exceptions
2023-03-19 18:05:15,172:INFO:Importing libraries
2023-03-19 18:05:15,172:INFO:Copying training dataset
2023-03-19 18:05:15,180:INFO:Defining folds
2023-03-19 18:05:15,180:INFO:Declaring metric variables
2023-03-19 18:05:15,188:INFO:Importing untrained model
2023-03-19 18:05:15,196:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 18:05:15,204:INFO:Starting cross validation
2023-03-19 18:05:15,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:05:16,192:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,216:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,224:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,264:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,272:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,312:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,337:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:16,506:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:19,343:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:19,396:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:05:26,179:INFO:Calculating mean and std
2023-03-19 18:05:26,188:INFO:Creating metrics dataframe
2023-03-19 18:05:27,181:INFO:Uploading results into container
2023-03-19 18:05:27,181:INFO:Uploading model into container now
2023-03-19 18:05:27,181:INFO:_master_model_container: 8
2023-03-19 18:05:27,181:INFO:_display_container: 2
2023-03-19 18:05:27,181:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 18:05:27,181:INFO:create_model() successfully completed......................................
2023-03-19 18:05:27,271:INFO:SubProcess create_model() end ==================================
2023-03-19 18:05:27,271:INFO:Creating metrics dataframe
2023-03-19 18:05:27,287:INFO:Initializing Ada Boost Classifier
2023-03-19 18:05:27,287:INFO:Total runtime is 1.9303580999374388 minutes
2023-03-19 18:05:27,287:INFO:SubProcess create_model() called ==================================
2023-03-19 18:05:27,287:INFO:Initializing create_model()
2023-03-19 18:05:27,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:05:27,287:INFO:Checking exceptions
2023-03-19 18:05:27,287:INFO:Importing libraries
2023-03-19 18:05:27,287:INFO:Copying training dataset
2023-03-19 18:05:27,306:INFO:Defining folds
2023-03-19 18:05:27,306:INFO:Declaring metric variables
2023-03-19 18:05:27,312:INFO:Importing untrained model
2023-03-19 18:05:27,316:INFO:Ada Boost Classifier Imported successfully
2023-03-19 18:05:27,328:INFO:Starting cross validation
2023-03-19 18:05:27,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:05:39,779:INFO:Calculating mean and std
2023-03-19 18:05:39,779:INFO:Creating metrics dataframe
2023-03-19 18:05:40,774:INFO:Uploading results into container
2023-03-19 18:05:40,774:INFO:Uploading model into container now
2023-03-19 18:05:40,774:INFO:_master_model_container: 9
2023-03-19 18:05:40,774:INFO:_display_container: 2
2023-03-19 18:05:40,774:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8998)
2023-03-19 18:05:40,774:INFO:create_model() successfully completed......................................
2023-03-19 18:05:40,854:INFO:SubProcess create_model() end ==================================
2023-03-19 18:05:40,854:INFO:Creating metrics dataframe
2023-03-19 18:05:40,871:INFO:Initializing Gradient Boosting Classifier
2023-03-19 18:05:40,871:INFO:Total runtime is 2.1567550778388975 minutes
2023-03-19 18:05:40,878:INFO:SubProcess create_model() called ==================================
2023-03-19 18:05:40,878:INFO:Initializing create_model()
2023-03-19 18:05:40,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:05:40,878:INFO:Checking exceptions
2023-03-19 18:05:40,878:INFO:Importing libraries
2023-03-19 18:05:40,878:INFO:Copying training dataset
2023-03-19 18:05:40,895:INFO:Defining folds
2023-03-19 18:05:40,895:INFO:Declaring metric variables
2023-03-19 18:05:40,903:INFO:Importing untrained model
2023-03-19 18:05:40,919:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 18:05:40,927:INFO:Starting cross validation
2023-03-19 18:05:40,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:05:57,349:INFO:Calculating mean and std
2023-03-19 18:05:57,349:INFO:Creating metrics dataframe
2023-03-19 18:05:58,460:INFO:Uploading results into container
2023-03-19 18:05:58,468:INFO:Uploading model into container now
2023-03-19 18:05:58,468:INFO:_master_model_container: 10
2023-03-19 18:05:58,468:INFO:_display_container: 2
2023-03-19 18:05:58,470:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8998, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 18:05:58,470:INFO:create_model() successfully completed......................................
2023-03-19 18:05:58,556:INFO:SubProcess create_model() end ==================================
2023-03-19 18:05:58,556:INFO:Creating metrics dataframe
2023-03-19 18:05:58,588:INFO:Initializing Linear Discriminant Analysis
2023-03-19 18:05:58,588:INFO:Total runtime is 2.452035101254781 minutes
2023-03-19 18:05:58,588:INFO:SubProcess create_model() called ==================================
2023-03-19 18:05:58,588:INFO:Initializing create_model()
2023-03-19 18:05:58,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:05:58,596:INFO:Checking exceptions
2023-03-19 18:05:58,596:INFO:Importing libraries
2023-03-19 18:05:58,596:INFO:Copying training dataset
2023-03-19 18:05:58,612:INFO:Defining folds
2023-03-19 18:05:58,612:INFO:Declaring metric variables
2023-03-19 18:05:58,612:INFO:Importing untrained model
2023-03-19 18:05:58,620:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 18:05:58,636:INFO:Starting cross validation
2023-03-19 18:05:58,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:06:11,992:INFO:Calculating mean and std
2023-03-19 18:06:11,997:INFO:Creating metrics dataframe
2023-03-19 18:06:13,129:INFO:Uploading results into container
2023-03-19 18:06:13,129:INFO:Uploading model into container now
2023-03-19 18:06:13,129:INFO:_master_model_container: 11
2023-03-19 18:06:13,129:INFO:_display_container: 2
2023-03-19 18:06:13,129:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 18:06:13,129:INFO:create_model() successfully completed......................................
2023-03-19 18:06:13,233:INFO:SubProcess create_model() end ==================================
2023-03-19 18:06:13,233:INFO:Creating metrics dataframe
2023-03-19 18:06:13,257:INFO:Initializing Extra Trees Classifier
2023-03-19 18:06:13,257:INFO:Total runtime is 2.6965194940567017 minutes
2023-03-19 18:06:13,257:INFO:SubProcess create_model() called ==================================
2023-03-19 18:06:13,257:INFO:Initializing create_model()
2023-03-19 18:06:13,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:06:13,257:INFO:Checking exceptions
2023-03-19 18:06:13,265:INFO:Importing libraries
2023-03-19 18:06:13,265:INFO:Copying training dataset
2023-03-19 18:06:13,281:INFO:Defining folds
2023-03-19 18:06:13,281:INFO:Declaring metric variables
2023-03-19 18:06:13,289:INFO:Importing untrained model
2023-03-19 18:06:13,294:INFO:Extra Trees Classifier Imported successfully
2023-03-19 18:06:13,306:INFO:Starting cross validation
2023-03-19 18:06:13,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:06:14,924:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 18:06:18,586:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:19,184:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:19,192:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:19,234:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:19,273:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:19,415:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:19,634:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:06:31,870:INFO:Calculating mean and std
2023-03-19 18:06:31,870:INFO:Creating metrics dataframe
2023-03-19 18:06:32,840:INFO:Uploading results into container
2023-03-19 18:06:32,840:INFO:Uploading model into container now
2023-03-19 18:06:32,848:INFO:_master_model_container: 12
2023-03-19 18:06:32,848:INFO:_display_container: 2
2023-03-19 18:06:32,848:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8998, verbose=0, warm_start=False)
2023-03-19 18:06:32,848:INFO:create_model() successfully completed......................................
2023-03-19 18:06:32,936:INFO:SubProcess create_model() end ==================================
2023-03-19 18:06:32,936:INFO:Creating metrics dataframe
2023-03-19 18:06:32,960:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 18:06:32,960:INFO:Total runtime is 3.024911220868429 minutes
2023-03-19 18:06:32,960:INFO:SubProcess create_model() called ==================================
2023-03-19 18:06:32,960:INFO:Initializing create_model()
2023-03-19 18:06:32,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:06:32,960:INFO:Checking exceptions
2023-03-19 18:06:32,960:INFO:Importing libraries
2023-03-19 18:06:32,960:INFO:Copying training dataset
2023-03-19 18:06:32,976:INFO:Defining folds
2023-03-19 18:06:32,976:INFO:Declaring metric variables
2023-03-19 18:06:32,984:INFO:Importing untrained model
2023-03-19 18:06:32,988:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 18:06:33,001:INFO:Starting cross validation
2023-03-19 18:06:33,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:06:43,523:INFO:Calculating mean and std
2023-03-19 18:06:43,523:INFO:Creating metrics dataframe
2023-03-19 18:06:44,504:INFO:Uploading results into container
2023-03-19 18:06:44,504:INFO:Uploading model into container now
2023-03-19 18:06:44,504:INFO:_master_model_container: 13
2023-03-19 18:06:44,504:INFO:_display_container: 2
2023-03-19 18:06:44,504:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8998, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 18:06:44,504:INFO:create_model() successfully completed......................................
2023-03-19 18:06:44,592:INFO:SubProcess create_model() end ==================================
2023-03-19 18:06:44,592:INFO:Creating metrics dataframe
2023-03-19 18:06:44,608:INFO:Initializing Dummy Classifier
2023-03-19 18:06:44,608:INFO:Total runtime is 3.2190354665120444 minutes
2023-03-19 18:06:44,608:INFO:SubProcess create_model() called ==================================
2023-03-19 18:06:44,608:INFO:Initializing create_model()
2023-03-19 18:06:44,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B327B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:06:44,608:INFO:Checking exceptions
2023-03-19 18:06:44,608:INFO:Importing libraries
2023-03-19 18:06:44,608:INFO:Copying training dataset
2023-03-19 18:06:44,625:INFO:Defining folds
2023-03-19 18:06:44,625:INFO:Declaring metric variables
2023-03-19 18:06:44,632:INFO:Importing untrained model
2023-03-19 18:06:44,632:INFO:Dummy Classifier Imported successfully
2023-03-19 18:06:44,648:INFO:Starting cross validation
2023-03-19 18:06:44,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:06:45,558:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,558:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,614:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,614:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,647:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,664:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,707:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:45,714:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:48,143:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:48,175:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:06:54,855:INFO:Calculating mean and std
2023-03-19 18:06:54,863:INFO:Creating metrics dataframe
2023-03-19 18:06:55,853:INFO:Uploading results into container
2023-03-19 18:06:55,853:INFO:Uploading model into container now
2023-03-19 18:06:55,853:INFO:_master_model_container: 14
2023-03-19 18:06:55,853:INFO:_display_container: 2
2023-03-19 18:06:55,853:INFO:DummyClassifier(constant=None, random_state=8998, strategy='prior')
2023-03-19 18:06:55,853:INFO:create_model() successfully completed......................................
2023-03-19 18:06:55,950:INFO:SubProcess create_model() end ==================================
2023-03-19 18:06:55,950:INFO:Creating metrics dataframe
2023-03-19 18:06:55,974:INFO:Initializing create_model()
2023-03-19 18:06:55,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:06:55,974:INFO:Checking exceptions
2023-03-19 18:06:55,974:INFO:Importing libraries
2023-03-19 18:06:55,974:INFO:Copying training dataset
2023-03-19 18:06:55,990:INFO:Defining folds
2023-03-19 18:06:55,990:INFO:Declaring metric variables
2023-03-19 18:06:55,990:INFO:Importing untrained model
2023-03-19 18:06:55,990:INFO:Declaring custom model
2023-03-19 18:06:55,990:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 18:06:55,998:INFO:Cross validation set to False
2023-03-19 18:06:55,998:INFO:Fitting Model
2023-03-19 18:06:57,740:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 18:06:57,740:INFO:create_model() successfully completed......................................
2023-03-19 18:06:57,836:INFO:Creating Dashboard logs
2023-03-19 18:06:57,846:INFO:Model: Linear Discriminant Analysis
2023-03-19 18:06:57,909:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:06:58,033:INFO:Initializing predict_model()
2023-03-19 18:06:58,041:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B38B0D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002573B5C1090>)
2023-03-19 18:06:58,041:INFO:Checking exceptions
2023-03-19 18:06:58,041:INFO:Preloading libraries
2023-03-19 18:06:59,417:INFO:Creating Dashboard logs
2023-03-19 18:06:59,425:INFO:Model: Ridge Classifier
2023-03-19 18:06:59,490:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 8998, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 18:07:00,643:INFO:Creating Dashboard logs
2023-03-19 18:07:00,643:INFO:Model: Extra Trees Classifier
2023-03-19 18:07:00,711:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8998, 'verbose': 0, 'warm_start': False}
2023-03-19 18:07:01,887:INFO:Creating Dashboard logs
2023-03-19 18:07:01,887:INFO:Model: Logistic Regression
2023-03-19 18:07:01,968:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 8998, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 18:07:03,328:INFO:Creating Dashboard logs
2023-03-19 18:07:03,328:INFO:Model: Naive Bayes
2023-03-19 18:07:03,409:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 18:07:04,613:INFO:Creating Dashboard logs
2023-03-19 18:07:04,613:INFO:Model: Random Forest Classifier
2023-03-19 18:07:04,702:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 8998, 'verbose': 0, 'warm_start': False}
2023-03-19 18:07:06,176:INFO:Creating Dashboard logs
2023-03-19 18:07:06,188:INFO:Model: K Neighbors Classifier
2023-03-19 18:07:06,329:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 18:07:07,728:INFO:Creating Dashboard logs
2023-03-19 18:07:07,728:INFO:Model: str
2023-03-19 18:07:07,793:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 8998}
2023-03-19 18:07:09,108:INFO:Creating Dashboard logs
2023-03-19 18:07:09,118:INFO:Model: Decision Tree Classifier
2023-03-19 18:07:09,190:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 8998, 'splitter': 'best'}
2023-03-19 18:07:10,518:INFO:Creating Dashboard logs
2023-03-19 18:07:10,518:INFO:Model: Light Gradient Boosting Machine
2023-03-19 18:07:10,583:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8998, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 18:07:11,818:INFO:Creating Dashboard logs
2023-03-19 18:07:11,826:INFO:Model: Gradient Boosting Classifier
2023-03-19 18:07:11,901:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 8998, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:07:13,400:INFO:Creating Dashboard logs
2023-03-19 18:07:13,400:INFO:Model: Dummy Classifier
2023-03-19 18:07:13,488:INFO:Logged params: {'constant': None, 'random_state': 8998, 'strategy': 'prior'}
2023-03-19 18:07:15,097:INFO:Creating Dashboard logs
2023-03-19 18:07:15,105:INFO:Model: SVM - Linear Kernel
2023-03-19 18:07:15,177:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 8998, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:07:16,761:INFO:Creating Dashboard logs
2023-03-19 18:07:16,767:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 18:07:16,873:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:07:18,393:INFO:_master_model_container: 14
2023-03-19 18:07:18,393:INFO:_display_container: 2
2023-03-19 18:07:18,393:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 18:07:18,393:INFO:compare_models() successfully completed......................................
2023-03-19 18:07:19,462:INFO:PyCaret ClassificationExperiment
2023-03-19 18:07:19,462:INFO:Logging name: adult
2023-03-19 18:07:19,462:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 18:07:19,462:INFO:version 3.0.0
2023-03-19 18:07:19,462:INFO:Initializing setup()
2023-03-19 18:07:19,462:INFO:self.USI: 39b3
2023-03-19 18:07:19,462:INFO:self._variable_keys: {'exp_name_log', 'y', 'logging_param', 'target_param', 'memory', 'X', 'is_multiclass', 'gpu_param', 'fold_groups_param', '_ml_usecase', 'X_train', 'idx', 'log_plots_param', 'fold_generator', 'fix_imbalance', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'html_param', '_available_plots', 'X_test', 'seed', 'y_train', 'fold_shuffle_param', 'data', 'n_jobs_param', 'USI'}
2023-03-19 18:07:19,462:INFO:Checking environment
2023-03-19 18:07:19,462:INFO:python_version: 3.10.0
2023-03-19 18:07:19,462:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 18:07:19,462:INFO:machine: AMD64
2023-03-19 18:07:19,462:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 18:07:19,468:INFO:Memory: svmem(total=16969424896, available=4809846784, percent=71.7, used=12159578112, free=4809846784)
2023-03-19 18:07:19,468:INFO:Physical Core: 4
2023-03-19 18:07:19,468:INFO:Logical Core: 8
2023-03-19 18:07:19,468:INFO:Checking libraries
2023-03-19 18:07:19,468:INFO:System:
2023-03-19 18:07:19,468:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 18:07:19,468:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 18:07:19,468:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 18:07:19,468:INFO:PyCaret required dependencies:
2023-03-19 18:07:19,468:INFO:                 pip: 23.0.1
2023-03-19 18:07:19,468:INFO:          setuptools: 65.6.3
2023-03-19 18:07:19,468:INFO:             pycaret: 3.0.0
2023-03-19 18:07:19,472:INFO:             IPython: 8.11.0
2023-03-19 18:07:19,472:INFO:          ipywidgets: 8.0.4
2023-03-19 18:07:19,472:INFO:                tqdm: 4.65.0
2023-03-19 18:07:19,472:INFO:               numpy: 1.23.5
2023-03-19 18:07:19,472:INFO:              pandas: 1.5.3
2023-03-19 18:07:19,472:INFO:              jinja2: 3.1.2
2023-03-19 18:07:19,472:INFO:               scipy: 1.10.1
2023-03-19 18:07:19,472:INFO:              joblib: 1.2.0
2023-03-19 18:07:19,472:INFO:             sklearn: 1.2.2
2023-03-19 18:07:19,472:INFO:                pyod: 1.0.8
2023-03-19 18:07:19,472:INFO:            imblearn: 0.10.1
2023-03-19 18:07:19,472:INFO:   category_encoders: 2.6.0
2023-03-19 18:07:19,472:INFO:            lightgbm: 3.3.5
2023-03-19 18:07:19,472:INFO:               numba: 0.56.4
2023-03-19 18:07:19,472:INFO:            requests: 2.28.2
2023-03-19 18:07:19,472:INFO:          matplotlib: 3.7.1
2023-03-19 18:07:19,472:INFO:          scikitplot: 0.3.7
2023-03-19 18:07:19,472:INFO:         yellowbrick: 1.5
2023-03-19 18:07:19,472:INFO:              plotly: 5.13.1
2023-03-19 18:07:19,472:INFO:             kaleido: 0.2.1
2023-03-19 18:07:19,472:INFO:         statsmodels: 0.13.5
2023-03-19 18:07:19,472:INFO:              sktime: 0.16.1
2023-03-19 18:07:19,472:INFO:               tbats: 1.1.2
2023-03-19 18:07:19,472:INFO:            pmdarima: 2.0.3
2023-03-19 18:07:19,472:INFO:              psutil: 5.9.4
2023-03-19 18:07:19,472:INFO:PyCaret optional dependencies:
2023-03-19 18:07:19,472:INFO:                shap: 0.41.0
2023-03-19 18:07:19,472:INFO:           interpret: Not installed
2023-03-19 18:07:19,472:INFO:                umap: Not installed
2023-03-19 18:07:19,472:INFO:    pandas_profiling: Not installed
2023-03-19 18:07:19,472:INFO:  explainerdashboard: Not installed
2023-03-19 18:07:19,472:INFO:             autoviz: Not installed
2023-03-19 18:07:19,472:INFO:           fairlearn: Not installed
2023-03-19 18:07:19,472:INFO:             xgboost: Not installed
2023-03-19 18:07:19,472:INFO:            catboost: Not installed
2023-03-19 18:07:19,472:INFO:              kmodes: Not installed
2023-03-19 18:07:19,472:INFO:             mlxtend: Not installed
2023-03-19 18:07:19,472:INFO:       statsforecast: Not installed
2023-03-19 18:07:19,472:INFO:        tune_sklearn: Not installed
2023-03-19 18:07:19,472:INFO:                 ray: Not installed
2023-03-19 18:07:19,472:INFO:            hyperopt: Not installed
2023-03-19 18:07:19,472:INFO:              optuna: Not installed
2023-03-19 18:07:19,472:INFO:               skopt: Not installed
2023-03-19 18:07:19,472:INFO:              mlflow: 2.2.2
2023-03-19 18:07:19,472:INFO:              gradio: Not installed
2023-03-19 18:07:19,472:INFO:             fastapi: Not installed
2023-03-19 18:07:19,472:INFO:             uvicorn: Not installed
2023-03-19 18:07:19,472:INFO:              m2cgen: Not installed
2023-03-19 18:07:19,472:INFO:           evidently: Not installed
2023-03-19 18:07:19,472:INFO:               fugue: Not installed
2023-03-19 18:07:19,472:INFO:           streamlit: Not installed
2023-03-19 18:07:19,472:INFO:             prophet: Not installed
2023-03-19 18:07:19,472:INFO:None
2023-03-19 18:07:19,472:INFO:Set up data.
2023-03-19 18:07:19,501:INFO:Set up train/test split.
2023-03-19 18:07:19,522:INFO:Set up index.
2023-03-19 18:07:19,522:INFO:Set up folding strategy.
2023-03-19 18:07:19,522:INFO:Assigning column types.
2023-03-19 18:07:19,526:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 18:07:19,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:07:19,587:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:07:19,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:07:19,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:07:19,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,725:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 18:07:19,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:07:19,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,901:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:07:19,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:19,939:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 18:07:20,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:20,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:20,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:20,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:20,124:INFO:Preparing preprocessing pipeline...
2023-03-19 18:07:20,124:INFO:Set up simple imputation.
2023-03-19 18:07:20,133:INFO:Set up encoding of ordinal features.
2023-03-19 18:07:20,133:INFO:Set up encoding of categorical features.
2023-03-19 18:07:20,133:INFO:Set up removing outliers.
2023-03-19 18:07:20,133:INFO:Set up column name cleaning.
2023-03-19 18:07:21,202:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:23,567:INFO:Finished creating preprocessing pipeline.
2023-03-19 18:07:23,592:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   random_state=969,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=969,
                                                               threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 18:07:23,592:INFO:Creating final display dataframe.
2023-03-19 18:07:24,292:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:28,071:INFO:Setup _display_container:                     Description            Value
0                    Session id              969
1                        Target                y
2                   Target type           Binary
3           Original data shape      (32561, 15)
4        Transformed data shape      (31421, 65)
5   Transformed train set shape      (21652, 65)
6    Transformed test set shape       (9769, 65)
7              Ordinal features                1
8              Numeric features                6
9          Categorical features                8
10     Rows with missing values             7.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17              Remove outliers             True
18           Outliers threshold             0.05
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment     MlflowLogger
24              Experiment Name            adult
25                          USI             39b3
2023-03-19 18:07:28,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:28,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:28,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:28,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:07:28,291:INFO:Logging experiment in loggers
2023-03-19 18:07:28,407:INFO:SubProcess save_model() called ==================================
2023-03-19 18:07:28,456:INFO:Initializing save_model()
2023-03-19 18:07:28,456:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   random_state=969,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=969,
                                                               threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\FLP-13~1\AppData\Local\Temp\tmp0ks8cqvc\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   random_state=969,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=969,
                                                               threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-03-19 18:07:28,456:INFO:Adding model into prep_pipe
2023-03-19 18:07:28,471:WARNING:Only Model saved as it was a pipeline.
2023-03-19 18:07:28,533:INFO:C:\Users\FLP-13~1\AppData\Local\Temp\tmp0ks8cqvc\Transformation Pipeline.pkl saved in current working directory
2023-03-19 18:07:28,551:INFO:Pipeline(memory=FastMemory(location=C:\Users\FLP-13~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'fnlwgt', 'education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              stra...
                                                                   random_state=969,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=969,
                                                               threshold=0.05))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-03-19 18:07:28,551:INFO:save_model() successfully completed......................................
2023-03-19 18:07:29,677:INFO:SubProcess save_model() end ==================================
2023-03-19 18:07:29,782:INFO:setup() successfully completed in 9.84s...............
2023-03-19 18:07:29,823:INFO:Initializing compare_models()
2023-03-19 18:07:29,823:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-19 18:07:29,823:INFO:Checking exceptions
2023-03-19 18:07:29,832:INFO:Preparing display monitor
2023-03-19 18:07:29,873:INFO:Initializing Logistic Regression
2023-03-19 18:07:29,873:INFO:Total runtime is 0.0 minutes
2023-03-19 18:07:29,882:INFO:SubProcess create_model() called ==================================
2023-03-19 18:07:29,882:INFO:Initializing create_model()
2023-03-19 18:07:29,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:07:29,882:INFO:Checking exceptions
2023-03-19 18:07:29,882:INFO:Importing libraries
2023-03-19 18:07:29,882:INFO:Copying training dataset
2023-03-19 18:07:29,898:INFO:Defining folds
2023-03-19 18:07:29,898:INFO:Declaring metric variables
2023-03-19 18:07:29,901:INFO:Importing untrained model
2023-03-19 18:07:29,906:INFO:Logistic Regression Imported successfully
2023-03-19 18:07:29,914:INFO:Starting cross validation
2023-03-19 18:07:29,932:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:07:31,791:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:31,815:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:31,968:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:32,089:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:32,103:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:32,250:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:32,274:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:32,306:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:41,926:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:42,051:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-03-19 18:07:48,305:INFO:Calculating mean and std
2023-03-19 18:07:48,305:INFO:Creating metrics dataframe
2023-03-19 18:07:49,315:INFO:Uploading results into container
2023-03-19 18:07:49,315:INFO:Uploading model into container now
2023-03-19 18:07:49,315:INFO:_master_model_container: 1
2023-03-19 18:07:49,315:INFO:_display_container: 2
2023-03-19 18:07:49,315:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=969, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-19 18:07:49,315:INFO:create_model() successfully completed......................................
2023-03-19 18:07:49,403:INFO:SubProcess create_model() end ==================================
2023-03-19 18:07:49,403:INFO:Creating metrics dataframe
2023-03-19 18:07:49,411:INFO:Initializing K Neighbors Classifier
2023-03-19 18:07:49,420:INFO:Total runtime is 0.32578213612238566 minutes
2023-03-19 18:07:49,420:INFO:SubProcess create_model() called ==================================
2023-03-19 18:07:49,420:INFO:Initializing create_model()
2023-03-19 18:07:49,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:07:49,420:INFO:Checking exceptions
2023-03-19 18:07:49,420:INFO:Importing libraries
2023-03-19 18:07:49,420:INFO:Copying training dataset
2023-03-19 18:07:49,436:INFO:Defining folds
2023-03-19 18:07:49,436:INFO:Declaring metric variables
2023-03-19 18:07:49,436:INFO:Importing untrained model
2023-03-19 18:07:49,444:INFO:K Neighbors Classifier Imported successfully
2023-03-19 18:07:49,460:INFO:Starting cross validation
2023-03-19 18:07:49,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:08:01,425:INFO:Calculating mean and std
2023-03-19 18:08:01,425:INFO:Creating metrics dataframe
2023-03-19 18:08:02,711:INFO:Uploading results into container
2023-03-19 18:08:02,711:INFO:Uploading model into container now
2023-03-19 18:08:02,711:INFO:_master_model_container: 2
2023-03-19 18:08:02,711:INFO:_display_container: 2
2023-03-19 18:08:02,711:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-19 18:08:02,711:INFO:create_model() successfully completed......................................
2023-03-19 18:08:02,800:INFO:SubProcess create_model() end ==================================
2023-03-19 18:08:02,800:INFO:Creating metrics dataframe
2023-03-19 18:08:02,825:INFO:Initializing Naive Bayes
2023-03-19 18:08:02,825:INFO:Total runtime is 0.549198842048645 minutes
2023-03-19 18:08:02,833:INFO:SubProcess create_model() called ==================================
2023-03-19 18:08:02,833:INFO:Initializing create_model()
2023-03-19 18:08:02,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:08:02,833:INFO:Checking exceptions
2023-03-19 18:08:02,833:INFO:Importing libraries
2023-03-19 18:08:02,833:INFO:Copying training dataset
2023-03-19 18:08:02,857:INFO:Defining folds
2023-03-19 18:08:02,857:INFO:Declaring metric variables
2023-03-19 18:08:02,865:INFO:Importing untrained model
2023-03-19 18:08:02,873:INFO:Naive Bayes Imported successfully
2023-03-19 18:08:02,881:INFO:Starting cross validation
2023-03-19 18:08:02,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:08:13,461:INFO:Calculating mean and std
2023-03-19 18:08:13,469:INFO:Creating metrics dataframe
2023-03-19 18:08:14,528:INFO:Uploading results into container
2023-03-19 18:08:14,531:INFO:Uploading model into container now
2023-03-19 18:08:14,531:INFO:_master_model_container: 3
2023-03-19 18:08:14,531:INFO:_display_container: 2
2023-03-19 18:08:14,531:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-19 18:08:14,531:INFO:create_model() successfully completed......................................
2023-03-19 18:08:14,622:INFO:SubProcess create_model() end ==================================
2023-03-19 18:08:14,622:INFO:Creating metrics dataframe
2023-03-19 18:08:14,628:INFO:Initializing Decision Tree Classifier
2023-03-19 18:08:14,628:INFO:Total runtime is 0.7459178169568379 minutes
2023-03-19 18:08:14,636:INFO:SubProcess create_model() called ==================================
2023-03-19 18:08:14,636:INFO:Initializing create_model()
2023-03-19 18:08:14,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:08:14,636:INFO:Checking exceptions
2023-03-19 18:08:14,636:INFO:Importing libraries
2023-03-19 18:08:14,636:INFO:Copying training dataset
2023-03-19 18:08:14,644:INFO:Defining folds
2023-03-19 18:08:14,652:INFO:Declaring metric variables
2023-03-19 18:08:14,652:INFO:Importing untrained model
2023-03-19 18:08:14,660:INFO:Decision Tree Classifier Imported successfully
2023-03-19 18:08:14,670:INFO:Starting cross validation
2023-03-19 18:08:14,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:08:25,413:INFO:Calculating mean and std
2023-03-19 18:08:25,413:INFO:Creating metrics dataframe
2023-03-19 18:08:26,452:INFO:Uploading results into container
2023-03-19 18:08:26,452:INFO:Uploading model into container now
2023-03-19 18:08:26,452:INFO:_master_model_container: 4
2023-03-19 18:08:26,452:INFO:_display_container: 2
2023-03-19 18:08:26,452:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=969, splitter='best')
2023-03-19 18:08:26,452:INFO:create_model() successfully completed......................................
2023-03-19 18:08:26,542:INFO:SubProcess create_model() end ==================================
2023-03-19 18:08:26,542:INFO:Creating metrics dataframe
2023-03-19 18:08:26,549:INFO:Initializing SVM - Linear Kernel
2023-03-19 18:08:26,557:INFO:Total runtime is 0.9447420954704284 minutes
2023-03-19 18:08:26,560:INFO:SubProcess create_model() called ==================================
2023-03-19 18:08:26,560:INFO:Initializing create_model()
2023-03-19 18:08:26,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:08:26,560:INFO:Checking exceptions
2023-03-19 18:08:26,560:INFO:Importing libraries
2023-03-19 18:08:26,560:INFO:Copying training dataset
2023-03-19 18:08:26,574:INFO:Defining folds
2023-03-19 18:08:26,574:INFO:Declaring metric variables
2023-03-19 18:08:26,576:INFO:Importing untrained model
2023-03-19 18:08:26,582:INFO:SVM - Linear Kernel Imported successfully
2023-03-19 18:08:26,595:INFO:Starting cross validation
2023-03-19 18:08:26,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:08:29,304:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,464:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,506:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,578:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,812:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,893:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,942:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:29,950:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:32,870:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:33,410:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-19 18:08:38,811:INFO:Calculating mean and std
2023-03-19 18:08:38,812:INFO:Creating metrics dataframe
2023-03-19 18:08:40,041:INFO:Uploading results into container
2023-03-19 18:08:40,041:INFO:Uploading model into container now
2023-03-19 18:08:40,041:INFO:_master_model_container: 5
2023-03-19 18:08:40,041:INFO:_display_container: 2
2023-03-19 18:08:40,041:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=969, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-19 18:08:40,041:INFO:create_model() successfully completed......................................
2023-03-19 18:08:40,131:INFO:SubProcess create_model() end ==================================
2023-03-19 18:08:40,131:INFO:Creating metrics dataframe
2023-03-19 18:08:40,147:INFO:Initializing Ridge Classifier
2023-03-19 18:08:40,147:INFO:Total runtime is 1.1712365547815957 minutes
2023-03-19 18:08:40,155:INFO:SubProcess create_model() called ==================================
2023-03-19 18:08:40,155:INFO:Initializing create_model()
2023-03-19 18:08:40,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:08:40,155:INFO:Checking exceptions
2023-03-19 18:08:40,155:INFO:Importing libraries
2023-03-19 18:08:40,155:INFO:Copying training dataset
2023-03-19 18:08:40,171:INFO:Defining folds
2023-03-19 18:08:40,171:INFO:Declaring metric variables
2023-03-19 18:08:40,181:INFO:Importing untrained model
2023-03-19 18:08:40,181:INFO:Ridge Classifier Imported successfully
2023-03-19 18:08:40,196:INFO:Starting cross validation
2023-03-19 18:08:40,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:08:41,356:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,421:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,421:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,451:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,536:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,541:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,603:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:41,635:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:43,931:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:43,993:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-19 18:08:51,611:INFO:Calculating mean and std
2023-03-19 18:08:51,618:INFO:Creating metrics dataframe
2023-03-19 18:08:54,238:INFO:Uploading results into container
2023-03-19 18:08:54,238:INFO:Uploading model into container now
2023-03-19 18:08:54,238:INFO:_master_model_container: 6
2023-03-19 18:08:54,238:INFO:_display_container: 2
2023-03-19 18:08:54,246:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=969, solver='auto',
                tol=0.0001)
2023-03-19 18:08:54,246:INFO:create_model() successfully completed......................................
2023-03-19 18:08:54,406:INFO:SubProcess create_model() end ==================================
2023-03-19 18:08:54,406:INFO:Creating metrics dataframe
2023-03-19 18:08:54,439:INFO:Initializing Random Forest Classifier
2023-03-19 18:08:54,439:INFO:Total runtime is 1.4094404776891072 minutes
2023-03-19 18:08:54,447:INFO:SubProcess create_model() called ==================================
2023-03-19 18:08:54,447:INFO:Initializing create_model()
2023-03-19 18:08:54,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:08:54,447:INFO:Checking exceptions
2023-03-19 18:08:54,447:INFO:Importing libraries
2023-03-19 18:08:54,447:INFO:Copying training dataset
2023-03-19 18:08:54,482:INFO:Defining folds
2023-03-19 18:08:54,486:INFO:Declaring metric variables
2023-03-19 18:08:54,497:INFO:Importing untrained model
2023-03-19 18:08:54,514:INFO:Random Forest Classifier Imported successfully
2023-03-19 18:08:54,534:INFO:Starting cross validation
2023-03-19 18:08:54,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:08:56,801:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 18:08:59,430:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-19 18:09:01,248:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-19 18:09:02,012:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:02,481:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:02,619:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:02,716:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:02,842:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:02,923:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:03,643:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:04,289:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:04,324:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:04,597:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:04,665:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:04,792:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:04,890:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:04,949:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:05,669:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:05,991:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:09:13,671:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:09:26,634:INFO:Calculating mean and std
2023-03-19 18:09:26,634:INFO:Creating metrics dataframe
2023-03-19 18:09:27,709:INFO:Uploading results into container
2023-03-19 18:09:27,709:INFO:Uploading model into container now
2023-03-19 18:09:27,709:INFO:_master_model_container: 7
2023-03-19 18:09:27,709:INFO:_display_container: 2
2023-03-19 18:09:27,717:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=969, verbose=0, warm_start=False)
2023-03-19 18:09:27,717:INFO:create_model() successfully completed......................................
2023-03-19 18:09:27,806:INFO:SubProcess create_model() end ==================================
2023-03-19 18:09:27,806:INFO:Creating metrics dataframe
2023-03-19 18:09:27,822:INFO:Initializing Quadratic Discriminant Analysis
2023-03-19 18:09:27,822:INFO:Total runtime is 1.9658220529556274 minutes
2023-03-19 18:09:27,830:INFO:SubProcess create_model() called ==================================
2023-03-19 18:09:27,830:INFO:Initializing create_model()
2023-03-19 18:09:27,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:09:27,830:INFO:Checking exceptions
2023-03-19 18:09:27,830:INFO:Importing libraries
2023-03-19 18:09:27,830:INFO:Copying training dataset
2023-03-19 18:09:27,846:INFO:Defining folds
2023-03-19 18:09:27,846:INFO:Declaring metric variables
2023-03-19 18:09:27,854:INFO:Importing untrained model
2023-03-19 18:09:27,854:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-19 18:09:27,870:INFO:Starting cross validation
2023-03-19 18:09:27,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:09:28,923:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:28,923:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:28,971:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:29,004:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:29,031:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:29,052:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:29,060:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:29,148:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:32,374:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:32,406:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-19 18:09:40,301:INFO:Calculating mean and std
2023-03-19 18:09:40,309:INFO:Creating metrics dataframe
2023-03-19 18:09:41,397:INFO:Uploading results into container
2023-03-19 18:09:41,397:INFO:Uploading model into container now
2023-03-19 18:09:41,397:INFO:_master_model_container: 8
2023-03-19 18:09:41,397:INFO:_display_container: 2
2023-03-19 18:09:41,397:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-19 18:09:41,397:INFO:create_model() successfully completed......................................
2023-03-19 18:09:41,485:INFO:SubProcess create_model() end ==================================
2023-03-19 18:09:41,485:INFO:Creating metrics dataframe
2023-03-19 18:09:41,502:INFO:Initializing Ada Boost Classifier
2023-03-19 18:09:41,502:INFO:Total runtime is 2.1938151995340984 minutes
2023-03-19 18:09:41,510:INFO:SubProcess create_model() called ==================================
2023-03-19 18:09:41,510:INFO:Initializing create_model()
2023-03-19 18:09:41,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:09:41,510:INFO:Checking exceptions
2023-03-19 18:09:41,510:INFO:Importing libraries
2023-03-19 18:09:41,510:INFO:Copying training dataset
2023-03-19 18:09:41,530:INFO:Defining folds
2023-03-19 18:09:41,530:INFO:Declaring metric variables
2023-03-19 18:09:41,534:INFO:Importing untrained model
2023-03-19 18:09:41,542:INFO:Ada Boost Classifier Imported successfully
2023-03-19 18:09:41,550:INFO:Starting cross validation
2023-03-19 18:09:41,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:09:55,276:INFO:Calculating mean and std
2023-03-19 18:09:55,284:INFO:Creating metrics dataframe
2023-03-19 18:09:56,422:INFO:Uploading results into container
2023-03-19 18:09:56,422:INFO:Uploading model into container now
2023-03-19 18:09:56,422:INFO:_master_model_container: 9
2023-03-19 18:09:56,422:INFO:_display_container: 2
2023-03-19 18:09:56,422:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=969)
2023-03-19 18:09:56,429:INFO:create_model() successfully completed......................................
2023-03-19 18:09:56,518:INFO:SubProcess create_model() end ==================================
2023-03-19 18:09:56,518:INFO:Creating metrics dataframe
2023-03-19 18:09:56,534:INFO:Initializing Gradient Boosting Classifier
2023-03-19 18:09:56,534:INFO:Total runtime is 2.4443542122840882 minutes
2023-03-19 18:09:56,534:INFO:SubProcess create_model() called ==================================
2023-03-19 18:09:56,542:INFO:Initializing create_model()
2023-03-19 18:09:56,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:09:56,542:INFO:Checking exceptions
2023-03-19 18:09:56,542:INFO:Importing libraries
2023-03-19 18:09:56,542:INFO:Copying training dataset
2023-03-19 18:09:56,550:INFO:Defining folds
2023-03-19 18:09:56,550:INFO:Declaring metric variables
2023-03-19 18:09:56,558:INFO:Importing untrained model
2023-03-19 18:09:56,558:INFO:Gradient Boosting Classifier Imported successfully
2023-03-19 18:09:56,574:INFO:Starting cross validation
2023-03-19 18:09:56,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:10:13,987:INFO:Calculating mean and std
2023-03-19 18:10:13,987:INFO:Creating metrics dataframe
2023-03-19 18:10:15,031:INFO:Uploading results into container
2023-03-19 18:10:15,039:INFO:Uploading model into container now
2023-03-19 18:10:15,039:INFO:_master_model_container: 10
2023-03-19 18:10:15,039:INFO:_display_container: 2
2023-03-19 18:10:15,039:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=969, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-19 18:10:15,039:INFO:create_model() successfully completed......................................
2023-03-19 18:10:15,127:INFO:SubProcess create_model() end ==================================
2023-03-19 18:10:15,127:INFO:Creating metrics dataframe
2023-03-19 18:10:15,143:INFO:Initializing Linear Discriminant Analysis
2023-03-19 18:10:15,143:INFO:Total runtime is 2.7545075257619223 minutes
2023-03-19 18:10:15,151:INFO:SubProcess create_model() called ==================================
2023-03-19 18:10:15,151:INFO:Initializing create_model()
2023-03-19 18:10:15,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:10:15,155:INFO:Checking exceptions
2023-03-19 18:10:15,155:INFO:Importing libraries
2023-03-19 18:10:15,155:INFO:Copying training dataset
2023-03-19 18:10:15,167:INFO:Defining folds
2023-03-19 18:10:15,167:INFO:Declaring metric variables
2023-03-19 18:10:15,175:INFO:Importing untrained model
2023-03-19 18:10:15,175:INFO:Linear Discriminant Analysis Imported successfully
2023-03-19 18:10:15,192:INFO:Starting cross validation
2023-03-19 18:10:15,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:10:27,417:INFO:Calculating mean and std
2023-03-19 18:10:27,425:INFO:Creating metrics dataframe
2023-03-19 18:10:28,856:INFO:Uploading results into container
2023-03-19 18:10:28,859:INFO:Uploading model into container now
2023-03-19 18:10:28,859:INFO:_master_model_container: 11
2023-03-19 18:10:28,859:INFO:_display_container: 2
2023-03-19 18:10:28,859:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-19 18:10:28,859:INFO:create_model() successfully completed......................................
2023-03-19 18:10:28,950:INFO:SubProcess create_model() end ==================================
2023-03-19 18:10:28,950:INFO:Creating metrics dataframe
2023-03-19 18:10:28,967:INFO:Initializing Extra Trees Classifier
2023-03-19 18:10:28,967:INFO:Total runtime is 2.984902528921763 minutes
2023-03-19 18:10:28,975:INFO:SubProcess create_model() called ==================================
2023-03-19 18:10:28,975:INFO:Initializing create_model()
2023-03-19 18:10:28,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:10:28,975:INFO:Checking exceptions
2023-03-19 18:10:28,975:INFO:Importing libraries
2023-03-19 18:10:28,975:INFO:Copying training dataset
2023-03-19 18:10:28,991:INFO:Defining folds
2023-03-19 18:10:28,991:INFO:Declaring metric variables
2023-03-19 18:10:28,991:INFO:Importing untrained model
2023-03-19 18:10:28,999:INFO:Extra Trees Classifier Imported successfully
2023-03-19 18:10:29,016:INFO:Starting cross validation
2023-03-19 18:10:29,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:10:37,353:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:37,842:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:38,729:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:38,808:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:38,824:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:38,936:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:38,936:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:38,985:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:10:39,220:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:39,220:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:40,211:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:40,429:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:40,486:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:40,518:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:40,574:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-19 18:10:49,779:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-19 18:11:05,575:INFO:Calculating mean and std
2023-03-19 18:11:05,579:INFO:Creating metrics dataframe
2023-03-19 18:11:08,507:INFO:Uploading results into container
2023-03-19 18:11:08,507:INFO:Uploading model into container now
2023-03-19 18:11:08,507:INFO:_master_model_container: 12
2023-03-19 18:11:08,507:INFO:_display_container: 2
2023-03-19 18:11:08,507:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=969, verbose=0, warm_start=False)
2023-03-19 18:11:08,507:INFO:create_model() successfully completed......................................
2023-03-19 18:11:08,672:INFO:SubProcess create_model() end ==================================
2023-03-19 18:11:08,672:INFO:Creating metrics dataframe
2023-03-19 18:11:08,720:INFO:Initializing Light Gradient Boosting Machine
2023-03-19 18:11:08,720:INFO:Total runtime is 3.647450160980225 minutes
2023-03-19 18:11:08,720:INFO:SubProcess create_model() called ==================================
2023-03-19 18:11:08,736:INFO:Initializing create_model()
2023-03-19 18:11:08,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:11:08,736:INFO:Checking exceptions
2023-03-19 18:11:08,736:INFO:Importing libraries
2023-03-19 18:11:08,736:INFO:Copying training dataset
2023-03-19 18:11:08,763:INFO:Defining folds
2023-03-19 18:11:08,763:INFO:Declaring metric variables
2023-03-19 18:11:08,769:INFO:Importing untrained model
2023-03-19 18:11:08,791:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-19 18:11:08,815:INFO:Starting cross validation
2023-03-19 18:11:08,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:11:28,740:INFO:Calculating mean and std
2023-03-19 18:11:28,756:INFO:Creating metrics dataframe
2023-03-19 18:11:29,928:INFO:Uploading results into container
2023-03-19 18:11:29,928:INFO:Uploading model into container now
2023-03-19 18:11:29,928:INFO:_master_model_container: 13
2023-03-19 18:11:29,928:INFO:_display_container: 2
2023-03-19 18:11:29,928:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=969, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-19 18:11:29,928:INFO:create_model() successfully completed......................................
2023-03-19 18:11:30,028:INFO:SubProcess create_model() end ==================================
2023-03-19 18:11:30,028:INFO:Creating metrics dataframe
2023-03-19 18:11:30,052:INFO:Initializing Dummy Classifier
2023-03-19 18:11:30,052:INFO:Total runtime is 4.00298875172933 minutes
2023-03-19 18:11:30,052:INFO:SubProcess create_model() called ==================================
2023-03-19 18:11:30,052:INFO:Initializing create_model()
2023-03-19 18:11:30,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002573B350310>, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:11:30,052:INFO:Checking exceptions
2023-03-19 18:11:30,052:INFO:Importing libraries
2023-03-19 18:11:30,052:INFO:Copying training dataset
2023-03-19 18:11:30,068:INFO:Defining folds
2023-03-19 18:11:30,068:INFO:Declaring metric variables
2023-03-19 18:11:30,068:INFO:Importing untrained model
2023-03-19 18:11:30,079:INFO:Dummy Classifier Imported successfully
2023-03-19 18:11:30,084:INFO:Starting cross validation
2023-03-19 18:11:30,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-19 18:11:31,064:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,080:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,137:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,153:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,153:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,161:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,180:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:31,180:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:33,738:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:33,746:WARNING:c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-19 18:11:40,675:INFO:Calculating mean and std
2023-03-19 18:11:40,675:INFO:Creating metrics dataframe
2023-03-19 18:11:41,670:INFO:Uploading results into container
2023-03-19 18:11:41,670:INFO:Uploading model into container now
2023-03-19 18:11:41,670:INFO:_master_model_container: 14
2023-03-19 18:11:41,670:INFO:_display_container: 2
2023-03-19 18:11:41,670:INFO:DummyClassifier(constant=None, random_state=969, strategy='prior')
2023-03-19 18:11:41,670:INFO:create_model() successfully completed......................................
2023-03-19 18:11:41,759:INFO:SubProcess create_model() end ==================================
2023-03-19 18:11:41,759:INFO:Creating metrics dataframe
2023-03-19 18:11:41,791:INFO:Initializing create_model()
2023-03-19 18:11:41,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=969, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-19 18:11:41,791:INFO:Checking exceptions
2023-03-19 18:11:41,799:INFO:Importing libraries
2023-03-19 18:11:41,799:INFO:Copying training dataset
2023-03-19 18:11:41,807:INFO:Defining folds
2023-03-19 18:11:41,807:INFO:Declaring metric variables
2023-03-19 18:11:41,807:INFO:Importing untrained model
2023-03-19 18:11:41,807:INFO:Declaring custom model
2023-03-19 18:11:41,807:INFO:Ridge Classifier Imported successfully
2023-03-19 18:11:41,832:INFO:Cross validation set to False
2023-03-19 18:11:41,832:INFO:Fitting Model
2023-03-19 18:11:43,204:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=969, solver='auto',
                tol=0.0001)
2023-03-19 18:11:43,204:INFO:create_model() successfully completed......................................
2023-03-19 18:11:43,332:INFO:Creating Dashboard logs
2023-03-19 18:11:43,332:INFO:Model: Ridge Classifier
2023-03-19 18:11:43,405:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 969, 'solver': 'auto', 'tol': 0.0001}
2023-03-19 18:11:43,527:INFO:Initializing predict_model()
2023-03-19 18:11:43,536:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002573B22FE20>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=969, solver='auto',
                tol=0.0001), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002573B5C13F0>)
2023-03-19 18:11:43,536:INFO:Checking exceptions
2023-03-19 18:11:43,536:INFO:Preloading libraries
2023-03-19 18:11:45,105:INFO:Creating Dashboard logs
2023-03-19 18:11:45,105:INFO:Model: Linear Discriminant Analysis
2023-03-19 18:11:45,181:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:11:46,382:INFO:Creating Dashboard logs
2023-03-19 18:11:46,391:INFO:Model: Extra Trees Classifier
2023-03-19 18:11:46,472:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 969, 'verbose': 0, 'warm_start': False}
2023-03-19 18:11:47,842:INFO:Creating Dashboard logs
2023-03-19 18:11:47,850:INFO:Model: Logistic Regression
2023-03-19 18:11:47,932:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 969, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-03-19 18:11:49,277:INFO:Creating Dashboard logs
2023-03-19 18:11:49,284:INFO:Model: Naive Bayes
2023-03-19 18:11:49,372:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-03-19 18:11:50,521:INFO:Creating Dashboard logs
2023-03-19 18:11:50,521:INFO:Model: Random Forest Classifier
2023-03-19 18:11:50,585:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 969, 'verbose': 0, 'warm_start': False}
2023-03-19 18:11:51,782:INFO:Creating Dashboard logs
2023-03-19 18:11:51,782:INFO:Model: K Neighbors Classifier
2023-03-19 18:11:51,848:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-03-19 18:11:53,038:INFO:Creating Dashboard logs
2023-03-19 18:11:53,038:INFO:Model: str
2023-03-19 18:11:53,103:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 969}
2023-03-19 18:11:54,309:INFO:Creating Dashboard logs
2023-03-19 18:11:54,317:INFO:Model: Dummy Classifier
2023-03-19 18:11:54,397:INFO:Logged params: {'constant': None, 'random_state': 969, 'strategy': 'prior'}
2023-03-19 18:11:55,630:INFO:Creating Dashboard logs
2023-03-19 18:11:55,630:INFO:Model: Gradient Boosting Classifier
2023-03-19 18:11:55,695:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 969, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:11:56,896:INFO:Creating Dashboard logs
2023-03-19 18:11:56,912:INFO:Model: Light Gradient Boosting Machine
2023-03-19 18:11:56,993:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 969, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-03-19 18:11:58,314:INFO:Creating Dashboard logs
2023-03-19 18:11:58,314:INFO:Model: Decision Tree Classifier
2023-03-19 18:11:58,379:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 969, 'splitter': 'best'}
2023-03-19 18:11:59,582:INFO:Creating Dashboard logs
2023-03-19 18:11:59,582:INFO:Model: Quadratic Discriminant Analysis
2023-03-19 18:11:59,647:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-03-19 18:12:00,936:INFO:Creating Dashboard logs
2023-03-19 18:12:00,936:INFO:Model: SVM - Linear Kernel
2023-03-19 18:12:01,001:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 969, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-03-19 18:12:02,463:INFO:_master_model_container: 14
2023-03-19 18:12:02,463:INFO:_display_container: 2
2023-03-19 18:12:02,469:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=969, solver='auto',
                tol=0.0001)
2023-03-19 18:12:02,469:INFO:compare_models() successfully completed......................................
2023-03-19 18:12:03,335:INFO:PyCaret ClassificationExperiment
2023-03-19 18:12:03,335:INFO:Logging name: adult
2023-03-19 18:12:03,335:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-19 18:12:03,335:INFO:version 3.0.0
2023-03-19 18:12:03,335:INFO:Initializing setup()
2023-03-19 18:12:03,335:INFO:self.USI: 891c
2023-03-19 18:12:03,335:INFO:self._variable_keys: {'exp_name_log', 'y', 'logging_param', 'target_param', 'memory', 'X', 'is_multiclass', 'gpu_param', 'fold_groups_param', '_ml_usecase', 'X_train', 'idx', 'log_plots_param', 'fold_generator', 'fix_imbalance', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'html_param', '_available_plots', 'X_test', 'seed', 'y_train', 'fold_shuffle_param', 'data', 'n_jobs_param', 'USI'}
2023-03-19 18:12:03,335:INFO:Checking environment
2023-03-19 18:12:03,335:INFO:python_version: 3.10.0
2023-03-19 18:12:03,335:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-03-19 18:12:03,335:INFO:machine: AMD64
2023-03-19 18:12:03,335:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-19 18:12:03,343:INFO:Memory: svmem(total=16969424896, available=5070372864, percent=70.1, used=11899052032, free=5070372864)
2023-03-19 18:12:03,343:INFO:Physical Core: 4
2023-03-19 18:12:03,343:INFO:Logical Core: 8
2023-03-19 18:12:03,343:INFO:Checking libraries
2023-03-19 18:12:03,343:INFO:System:
2023-03-19 18:12:03,343:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-03-19 18:12:03,343:INFO:executable: c:\Users\FLP-13-Rimba\miniconda3\envs\mka-ds\python.exe
2023-03-19 18:12:03,343:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-19 18:12:03,343:INFO:PyCaret required dependencies:
2023-03-19 18:12:03,343:INFO:                 pip: 23.0.1
2023-03-19 18:12:03,343:INFO:          setuptools: 65.6.3
2023-03-19 18:12:03,343:INFO:             pycaret: 3.0.0
2023-03-19 18:12:03,343:INFO:             IPython: 8.11.0
2023-03-19 18:12:03,343:INFO:          ipywidgets: 8.0.4
2023-03-19 18:12:03,343:INFO:                tqdm: 4.65.0
2023-03-19 18:12:03,343:INFO:               numpy: 1.23.5
2023-03-19 18:12:03,343:INFO:              pandas: 1.5.3
2023-03-19 18:12:03,343:INFO:              jinja2: 3.1.2
2023-03-19 18:12:03,343:INFO:               scipy: 1.10.1
2023-03-19 18:12:03,343:INFO:              joblib: 1.2.0
2023-03-19 18:12:03,343:INFO:             sklearn: 1.2.2
2023-03-19 18:12:03,343:INFO:                pyod: 1.0.8
2023-03-19 18:12:03,343:INFO:            imblearn: 0.10.1
2023-03-19 18:12:03,343:INFO:   category_encoders: 2.6.0
2023-03-19 18:12:03,343:INFO:            lightgbm: 3.3.5
2023-03-19 18:12:03,343:INFO:               numba: 0.56.4
2023-03-19 18:12:03,343:INFO:            requests: 2.28.2
2023-03-19 18:12:03,343:INFO:          matplotlib: 3.7.1
2023-03-19 18:12:03,343:INFO:          scikitplot: 0.3.7
2023-03-19 18:12:03,343:INFO:         yellowbrick: 1.5
2023-03-19 18:12:03,343:INFO:              plotly: 5.13.1
2023-03-19 18:12:03,343:INFO:             kaleido: 0.2.1
2023-03-19 18:12:03,343:INFO:         statsmodels: 0.13.5
2023-03-19 18:12:03,343:INFO:              sktime: 0.16.1
2023-03-19 18:12:03,343:INFO:               tbats: 1.1.2
2023-03-19 18:12:03,343:INFO:            pmdarima: 2.0.3
2023-03-19 18:12:03,343:INFO:              psutil: 5.9.4
2023-03-19 18:12:03,343:INFO:PyCaret optional dependencies:
2023-03-19 18:12:03,343:INFO:                shap: 0.41.0
2023-03-19 18:12:03,343:INFO:           interpret: Not installed
2023-03-19 18:12:03,343:INFO:                umap: Not installed
2023-03-19 18:12:03,343:INFO:    pandas_profiling: Not installed
2023-03-19 18:12:03,343:INFO:  explainerdashboard: Not installed
2023-03-19 18:12:03,343:INFO:             autoviz: Not installed
2023-03-19 18:12:03,343:INFO:           fairlearn: Not installed
2023-03-19 18:12:03,343:INFO:             xgboost: Not installed
2023-03-19 18:12:03,343:INFO:            catboost: Not installed
2023-03-19 18:12:03,343:INFO:              kmodes: Not installed
2023-03-19 18:12:03,343:INFO:             mlxtend: Not installed
2023-03-19 18:12:03,343:INFO:       statsforecast: Not installed
2023-03-19 18:12:03,343:INFO:        tune_sklearn: Not installed
2023-03-19 18:12:03,343:INFO:                 ray: Not installed
2023-03-19 18:12:03,343:INFO:            hyperopt: Not installed
2023-03-19 18:12:03,343:INFO:              optuna: Not installed
2023-03-19 18:12:03,343:INFO:               skopt: Not installed
2023-03-19 18:12:03,343:INFO:              mlflow: 2.2.2
2023-03-19 18:12:03,343:INFO:              gradio: Not installed
2023-03-19 18:12:03,343:INFO:             fastapi: Not installed
2023-03-19 18:12:03,343:INFO:             uvicorn: Not installed
2023-03-19 18:12:03,343:INFO:              m2cgen: Not installed
2023-03-19 18:12:03,343:INFO:           evidently: Not installed
2023-03-19 18:12:03,343:INFO:               fugue: Not installed
2023-03-19 18:12:03,343:INFO:           streamlit: Not installed
2023-03-19 18:12:03,343:INFO:             prophet: Not installed
2023-03-19 18:12:03,343:INFO:None
2023-03-19 18:12:03,343:INFO:Set up data.
2023-03-19 18:12:03,375:INFO:Set up train/test split.
2023-03-19 18:12:03,392:INFO:Set up index.
2023-03-19 18:12:03,392:INFO:Set up folding strategy.
2023-03-19 18:12:03,392:INFO:Assigning column types.
2023-03-19 18:12:03,400:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-19 18:12:03,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:12:03,456:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:12:03,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-19 18:12:03,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:12:03,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,575:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-19 18:12:03,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:12:03,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-19 18:12:03,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,792:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-19 18:12:03,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-19 18:12:03,977:INFO:Preparing preprocessing pipeline...
2023-03-19 18:12:03,977:INFO:Set up simple imputation.
2023-03-19 18:12:03,992:INFO:Set up encoding of ordinal features.
2023-03-19 18:12:03,992:INFO:Set up encoding of categorical features.
2023-03-19 18:12:03,992:INFO:Set up removing outliers.
2023-03-19 18:12:03,992:INFO:Set up feature normalization.
2023-03-19 18:12:03,992:INFO:Set up column name cleaning.
